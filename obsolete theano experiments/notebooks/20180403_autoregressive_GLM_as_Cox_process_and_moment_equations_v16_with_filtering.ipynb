{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregressive Point-Processes as Latent State-Space Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Load scipy/numpy/matplotlib\n",
    "from   scipy.linalg import expm\n",
    "import matplotlib.pyplot as plt\n",
    "from   pylab import *\n",
    "\n",
    "# Configure figure resolution\n",
    "plt.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "plt.rcParams['savefig.dpi'   ] = 100\n",
    "\n",
    "from izh       import * # Routines for sampling Izhikevich neurons\n",
    "from plot      import * # Misc. plotting routines\n",
    "from glm       import * # GLM fitting\n",
    "from arppglm   import * # Sampling and integration\n",
    "from utilities import * # Other utilities\n",
    "from arguments import * # Argument verification\n",
    "\n",
    "figure_prefix = \"RuleSanguinetti2018_figure_\"\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurotools.nlab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case study: phasic bursting Izhikevich neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Izhikevich parameters\n",
    "izh = (0.02,0.25,-55,0.05) # a, b, c, d\n",
    "dt  = 1.0\n",
    "\n",
    "nplot = 1000   # time points for plotting\n",
    "\n",
    "# Generate constant drive with synaptic noise\n",
    "I = 0.6\n",
    "stimulus = randn(nplot)*sqrt(I)+I\n",
    "\n",
    "# Plot current input\n",
    "subplot(311); plot(stimulus)\n",
    "xlim(0,nplot); nox(); noaxis(); ylabel('pA')\n",
    "title('Current injected')\n",
    "\n",
    "# Solve Izh model\n",
    "state = sim_izh(*izh,stimulus)\n",
    "\n",
    "# Plot voltage and spikes\n",
    "subplot(312); plot(state[:,1],color=OCHRE);\n",
    "xlim(0,nplot); noaxis(); addspikes(state[:,-1]); ylabel('mV');\n",
    "title('Simulated voltage and spikes');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on pulses\n",
    "\n",
    "GLMs can emulate neural firing, but have limited ability to generalize outside of the dynamical regime in which they are trained (Weber & Pillow 2017). For this reason, we train with stimuli that elicit phasic bursting responses (tonic bursting seems to be possible at higher stimulation currents, but interferes with the GLMs ability to model the phasic bursting regime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pulse training stimuli\n",
    "'''\n",
    "offset     = -1     # Baseline current (picoamps)\n",
    "min_amp    = 0.3    # Smallest current step (picoamps)\n",
    "max_amp    = 0.7    # Largest  current step (picoamps)\n",
    "min_pulse  = 10     # Shortest pulse duration (ms)\n",
    "max_pulse  = 500    # Longest  pulse duration (ms)\n",
    "'''\n",
    "\n",
    "# More challenging\n",
    "offset     = -0.5     # Baseline current (picoamps)\n",
    "min_amp    = 0.05    # Smallest current step (picoamps)\n",
    "max_amp    = 3.0    # Largest  current step (picoamps)\n",
    "min_pulse  = 10     # Shortest pulse duration (ms)\n",
    "max_pulse  = 500    # Longest  pulse duration (ms)\n",
    "\n",
    "amplitudes = exp(linspace(log(min_amp),log(max_amp),10))\n",
    "durationms = int32(exp(linspace(log(min_pulse),log(max_pulse),10)))\n",
    "stimulus   = pulse_sequence(amplitudes,durationms,offset)\n",
    "\n",
    "# Define Ornsteinâ€“Uhlenbeck (OU) process training noise \n",
    "'''\n",
    "ssvar     = 0.005          # Noise steady-state viariance (ln(pA)^2)\n",
    "'''\n",
    "\n",
    "ssvar     = 0.05          # Noise steady-state viariance (ln(pA)^2)\n",
    "\n",
    "tau       = 200            # Noise correlation time constant (ms)\n",
    "noisevar  = 2*ssvar/tau    # Noise fluctuation variance\n",
    "sigma     = sqrt(noisevar) # Noise flucutation standard deviation\n",
    "stimulus  += sample_ou_process(0,sigma,tau,dt,len(stimulus),ntrial=1).ravel()\n",
    "\n",
    "ntrain     = len(stimulus)\n",
    "\n",
    "# Plot training stimulus\n",
    "subplot(311); plot(stimulus)\n",
    "nox(); noaxis(); xlim(0,ntrain); ylabel('pA')\n",
    "title('Training stimulus');\n",
    "\n",
    "# Solve Izh model and get voltage and spikes\n",
    "state = sim_izh(*izh,stimulus,dt=dt)\n",
    "v,Y   = state[:,1],state[:,2]\n",
    "\n",
    "# Plot voltage and spikes\n",
    "subplot(312); plot(v,color=OCHRE); addspikes(Y,lw=0.05);\n",
    "noaxis(); xlim(0,ntrain); ylabel('mV');\n",
    "title('Simulated voltage and spikes');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit GLM to Izhikevich model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define history basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define history basis functions\n",
    "N = 150   # Duration of history filter\n",
    "K = 8     # number of basis elements\n",
    "D = 5     # Duration of shortest basis element\n",
    "B = make_cosine_basis(K,N,D,normalize=False)\n",
    "\n",
    "# Plot history basis functions\n",
    "subplot(421)\n",
    "plot(B.T,color=BLACK,clip_on=False);\n",
    "xlim(0,N); ylim(0,0.5); simpleaxis()\n",
    "xlabel('Time lag (ms)')\n",
    "title('History basis functions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate stimulus and spiking history training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build stimulus filter (history trace of I)\n",
    "# These are needed to model subthreshold dynamics\n",
    "Bh = array([convolve(b,stimulus) for b in B]).T[:ntrain]\n",
    "Bp = concatenate([zeros((K,1)),B],axis=1)\n",
    "By = array([convolve(b,Y) for b in Bp]).T[:ntrain]\n",
    "\n",
    "# Plot stimulus history features\n",
    "subplot(311); plot(Bh); noxyaxes();\n",
    "title('Stimulus history features');\n",
    "\n",
    "# Plot spike history features\n",
    "subplot(312); plot(By);\n",
    "for t in find(Y>0): axvline(t,lw=0.1,color=BLACK)\n",
    "noaxis(); noy(); xlabel('ms');\n",
    "title('Spike history features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compose feature vector and fit GLM\n",
    "X = concatenate([By,Bh],axis=1)\n",
    "m,bhat = fitGLM(X,Y)\n",
    "\n",
    "bhat_spikehist = bhat[:K]\n",
    "bhat_stimulus  = bhat[K:]\n",
    "beta = bhat[:K].reshape(K,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulse stimulus for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define demo pulse\n",
    "duration = 150  # Pulse duration (ms)\n",
    "padding  = 50   # Pulse padding (ms)\n",
    "burnin   = 200  # Time for Izhikevich model to settle (ms)\n",
    "current  = 0.3  # Pulse current (pA)\n",
    "ndemo    = duration + 2*padding # total length of demo stimulus (ms)\n",
    "\n",
    "# Build demo stimulus\n",
    "demo_stimulus = zeros(ndemo+burnin) + offset\n",
    "demo_stimulus[burnin+padding:burnin+padding+duration] = current\n",
    "\n",
    "figure(figsize=(6,6))\n",
    "\n",
    "# Plot demo stimulus\n",
    "subplot(411); plot(demo_stimulus[burnin:])\n",
    "nox(); noaxis(); xlim(0,ndemo); ylabel('pA')\n",
    "title('Training stimulus');\n",
    "\n",
    "# Solve Izh model\n",
    "demo_state = sim_izh(*izh,demo_stimulus,dt=dt)\n",
    "demo_v = demo_state[burnin:,1]\n",
    "demo_Y = demo_state[burnin:,2]\n",
    "\n",
    "# Plot demo model spiking \n",
    "subplot(412); plot(demo_v,color=OCHRE);\n",
    "addspikes(demo_Y)\n",
    "nox(); noaxis(); xlim(0,ndemo); ylabel('mV');\n",
    "title('Simulated voltage and spikes');\n",
    "\n",
    "# Bulid GLM filter responses\n",
    "demo_Bh = array([convolve(b,demo_stimulus) for b in B ]).T[burnin-1:][:ndemo,:]\n",
    "demo_By = array([convolve(b,demo_Y       ) for b in Bp]).T[:ndemo,:]\n",
    "demo_X  = concatenate([demo_By,demo_Bh],axis=1)\n",
    "\n",
    "# Plot demo stimulus history features \n",
    "subplot(413); plot(demo_Bh);\n",
    "xlim(0,ndemo); nox(); noaxis(); ylabel('a.u.')\n",
    "title('Stimulus history features')\n",
    "\n",
    "# Plot demo spiking history features \n",
    "subplot(414); plot(demo_By);\n",
    "xlim(0,ndemo); noaxis(); xlabel('ms'); ylabel('a.u.')\n",
    "title('Spiking history features')\n",
    "subplots_adjust(hspace=0.5)\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(6,8))\n",
    "# Use dB for log-units\n",
    "dB    = log10(e)*10\n",
    "\n",
    "def labeltime():\n",
    "    text(xlim()[1],0+pixels_to_yunits(5),'%d ms'%N,\n",
    "        horizontalalignment='right',\n",
    "        verticalalignment='bottom',\n",
    "        fontsize=9)\n",
    "\n",
    "# Plot stimulus history filter\n",
    "stimyscale = 2\n",
    "a1=subplot2grid((5,2),(0,0),colspan=1)\n",
    "plot(bhat_stimulus.dot(B)*dB,color='k',lw=1,clip_on=False)\n",
    "axhline(0,color='k',lw=1)\n",
    "xlim(0,N); ylim(-stimyscale,stimyscale); nox(); nicey(); simpleraxis();\n",
    "ylabel('Gain (dB)',fontsize=9); fudgey(10); labeltime()\n",
    "title('Stimulus filter')\n",
    "subfigurelabel('A')\n",
    "\n",
    "# Plot spike history filter\n",
    "histyscale = 20\n",
    "a1=subplot2grid((5,2),(0,1),colspan=1)\n",
    "plot(bhat_spikehist.dot(B)*dB,color='k',lw=1)\n",
    "axhline(0,color='k',lw=1)\n",
    "xlim(0,N); ylim(-histyscale,histyscale); nox(); nicey(); simpleraxis(); labeltime()\n",
    "title('Post-spike filter')\n",
    "\n",
    "# Illustrate neuron stimulus and response\n",
    "a2=subplot2grid((5,2),(1,0),colspan=2)\n",
    "plot(demo_v,'k',lw=0.7)\n",
    "draw()\n",
    "yl = ylim()\n",
    "for t in find(demo_Y)-1:\n",
    "    plot([t,t],yl,color='k',lw=0.3)\n",
    "height = abs(diff(yl)*0.25)\n",
    "lower  = yl[0]-height*1.5\n",
    "ii     = demo_stimulus[burnin:][:ndemo]\n",
    "ii     = (ii-min(ii))/(max(ii)-min(ii))\n",
    "plot(ii*height+lower,color='k',lw=0.5,clip_on=False)\n",
    "yscalebar(yl[1]-35,50,'50 mV'); \n",
    "yscalebar(height*0.5+lower,height,'%0.1f pA'%current)\n",
    "xlim(0,ndemo); ylim(lower,yl[1]); noxyaxes()\n",
    "title('Izhikevich neuron response')\n",
    "subfigurelabel('B')\n",
    "\n",
    "# Spike history contribution\n",
    "a3=subplot2grid((5,2),(2,0),colspan=2)\n",
    "plot(bhat_spikehist.dot(demo_By.T),color='k',lw=0.7)\n",
    "xlim(0,ndemo); yscalebar(mean(ylim()),10,'10 dB'); noxyaxes()\n",
    "title('Post-spike contribution to log-intensity')\n",
    "subfigurelabel('C')\n",
    "\n",
    "# Stimulus contribution\n",
    "a4=subplot2grid((5,2),(3,0),colspan=2)\n",
    "plot(bhat_stimulus.dot(demo_Bh.T),color='k',lw=0.7)\n",
    "xlim(0,ndemo); yscalebar(mean(ylim()),10,'10 dB'); noxyaxes()\n",
    "title('Stimulus contribution to log-intensity')\n",
    "subfigurelabel('D')\n",
    "\n",
    "# Sample the spiking response of the GLM\n",
    "a5=subplot2grid((5,2),(4,0),colspan=2)\n",
    "nsample = 20\n",
    "stim = m + bhat_stimulus.dot(demo_Bh.T)\n",
    "ysamp,logratesamp = ensemble_sample(stim,B,beta,nsample)\n",
    "pcolormesh(1-ysamp.T,cmap=\"gray\")\n",
    "noaxis(); xticks(arange(0,251,50)); yticks([0,nsample],['0','%s'%nsample])\n",
    "xlabel('Time (ms)'); ylabel('Sample #',fontsize=9); fudgey(20)\n",
    "title('Sampled autoregressive point-process model')\n",
    "subfigurelabel('E',dy=10)\n",
    "\n",
    "# Make final adjustments\n",
    "plt.draw()\n",
    "subplots_adjust(hspace=0.5)\n",
    "nudge_axis_y(-10,a2); adjust_axis_height_pixels(20,a3); \n",
    "nudge_axis_y(-10,a3); adjust_axis_height_pixels(20,a4)\n",
    "suptitle('Phasic bursting autoregressive PP-GLM model')\n",
    "\n",
    "savefig(figure_prefix+'1.pdf',transparent=True,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct low-dimensional system for history process\n",
    "\n",
    "If the history basis is chosen suitably, the resuling linear system closely approximates the history basis. One can also use a linear system for the history filter form the outset, e.g. a collection of decaying exponential basis functions, enabeling an exact model. Since histor bases are commonly used, and the filtering approach is discussed elsewhere, we demonstrate the low-dimensional delay-line projection here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create discrete differentiation operator\n",
    "Dtau = -eye(N) + eye(N,k=-1)\n",
    "# Create delta operator (to inject signal into delay line)\n",
    "S = zeros((N,1))\n",
    "S[0,0] = 1\n",
    "# Perform a change of basis from function space into the basis projection B\n",
    "A = B.dot(Dtau).dot(pinv(B))\n",
    "C = B.dot(S)\n",
    "\n",
    "figure(figsize=(8,4))\n",
    "subplot(221); imshow(Dtau)\n",
    "title('$\\partial_\\\\tau$')\n",
    "subplot(222); imshow(S.T,aspect=N/2)\n",
    "title('$\\delta_{\\\\tau=0}$')\n",
    "subplot(223); imshow(A)\n",
    "title('$B \\partial_\\\\tau B^{+}$')\n",
    "subplot(224)\n",
    "imshow(C.T,aspect=K/2)\n",
    "title('$B \\delta_{\\\\tau=0}$')\n",
    "subplots_adjust(hspace=0.5,wspace=-0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_training_model = {}\n",
    "saved_training_model['K'] = K\n",
    "saved_training_model['B'] = B\n",
    "saved_training_model['By'] = By\n",
    "saved_training_model['Bh'] = Bh\n",
    "saved_training_model['A'] = A\n",
    "saved_training_model['C'] = C\n",
    "saved_training_model['Y'] = Y \n",
    "saved_training_model['dt'] = dt\n",
    "saved_training_model = scipy.io.savemat('saved_training_model.mat',saved_training_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrate basis projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figure(figsize=(9,1.5))\n",
    "styles = ['--','-',':']\n",
    "\n",
    "impulse = zeros(N)\n",
    "impulse[0]=1\n",
    "\n",
    "subplot(121)\n",
    "for i,b in enumerate(array([convolve(b,impulse) for b in B])):\n",
    "    plot(b[:N],lw=1,linestyle=styles[i%len(styles)],color='k',clip_on=False)\n",
    "simpleaxis(); xlim(0,N); ylim(0,.5); nicexy()\n",
    "title('Original basis')\n",
    "xticks([0,150],['0','150 ms'])\n",
    "\n",
    "filtered = linfilter(A,C,impulse)\n",
    "subplot(122)\n",
    "for i,b in enumerate(filtered.T):\n",
    "    plot(b[:N],lw=1,linestyle=styles[i%len(styles)],color='k',clip_on=False)\n",
    "simpleaxis(); xlim(0,N); ylim(0,.5); nicexy()\n",
    "title('Approximated (filtered) basis')\n",
    "xticks([0,150],['0','150 ms'])\n",
    "\n",
    "savefig(figure_prefix+'2.pdf',transparent=True,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate single-time marginal log-intensity and varience using several different procedures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"True\" sample from point process model\n",
    "demo_logxpp,demo_logvpp,_,_ = ensemble_sample_moments(stim,B,beta,M=10000)\n",
    "demo_lxpp = box_filter(demo_logxpp,5)\n",
    "demo_lvpp = box_filter(demo_logvpp,5)\n",
    "\n",
    "# Sample from langevin approximation of point process\n",
    "demo_logxlv,demo_logvlv,_,_  = langevin_sample_moments(stim,A,beta,C,M=10000)\n",
    "demo_lxlv = box_filter(demo_logxlv,5)\n",
    "demo_lvlv = box_filter(demo_logvlv,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate moments from mean-field and linear noise approximation\n",
    "demo_logxmf,demo_logvmf,_,_ = integrate_moments(stim,A,beta,C,\n",
    "                                                method     = \"LNA\",\n",
    "                                                int_method = \"euler\")\n",
    "\n",
    "# Only first two moments of rate are used for filtering\n",
    "demo_logxso,demo_logvso,_,_ = integrate_moments(stim,A,beta,C,\n",
    "                                                method     = \"second_order\",\n",
    "                                                int_method = \"euler\")\n",
    "# Estimate using moment closure\n",
    "demo_logxmc,demo_logvmc,_,_ = integrate_moments(stim,A,beta,C,\n",
    "                                                method     = \"moment_closure\",\n",
    "                                                int_method = \"euler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(12,5))\n",
    "\n",
    "# Plot sampled point process against sampled Langevin\n",
    "subplot(221)\n",
    "stderrplot(demo_lxpp,demo_lvpp,BLACK,filled=1)\n",
    "stderrplot(demo_lxlv,demo_lvlv,OCHRE,filled=0)\n",
    "xlim(0,ndemo); noxyaxes()\n",
    "title('Langevin')\n",
    "\n",
    "# Plot LNA against sampled Langevin\n",
    "subplot(322)\n",
    "stderrplot(demo_lxpp,demo_lvpp,BLACK,filled=1)\n",
    "stderrplot(demo_logxmf,demo_logvmf,TURQUOISE,filled=0)\n",
    "xlim(0,ndemo); noxyaxes()\n",
    "title('Mean-field, linear noise approximation')\n",
    "\n",
    "# Plot moment-closure against sampled Langevin\n",
    "subplot(223)\n",
    "stderrplot(demo_lxpp,demo_lvpp,BLACK,filled=1)\n",
    "stderrplot(demo_logxmc,demo_logvmc,RUST,filled=0)\n",
    "xlim(0,ndemo); noy(); noxyaxes()\n",
    "title('Gaussian moment-closure')\n",
    "\n",
    "# Plot second-order against sampled Langevin\n",
    "# This amounts to moment closure, where the GLM nonlinearity\n",
    "# is locally approximated as a quadratic function. The log-\n",
    "# Gaussian distribution on the rates is, in genral, too right\n",
    "# skewed, and over-estimates the probability of high rates. \n",
    "# The quadratic approximation removes the effects of higher\n",
    "# order moments, attenuating this heavy tail and leading to\n",
    "# a moment closure that is less stiff to integrate and more\n",
    "# accurately captures the second moment.\n",
    "subplot(224)\n",
    "stderrplot(demo_lxpp,demo_lvpp,BLACK,filled=1)\n",
    "stderrplot(demo_logxso,demo_logvso, AZURE,filled=0)\n",
    "xlim(0,ndemo); noy(); noxyaxes();\n",
    "title('Second-order approximation')\n",
    "\n",
    "\n",
    "subplots_adjust(wspace=0.1,hspace=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration pulse sequence\n",
    "\n",
    "Construct a more \"naturalistic\" intput stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSTIM    = 3000\n",
    "\n",
    "# Random pulse sequence\n",
    "offset     = -0.5\n",
    "pulse_stimulus = pulse_sequence(linspace(0.5,1.0,5),int32(linspace(50,500,7)),offset)\n",
    "\n",
    "# OU process defining additional Gaussian noise\n",
    "ntrain = len(pulse_stimulus)\n",
    "ssvar    = 1\n",
    "tau      = 100\n",
    "noisevar = 2*ssvar/tau\n",
    "sigma    = sqrt(noisevar)\n",
    "noise2   = sample_ou_process(0,sigma,tau,dt,ntrain,ntrial=1).ravel()\n",
    "\n",
    "# Combine pulses with noise, apply synaptic filter\n",
    "stimulus = pulse_stimulus + noise2\n",
    "stimulus = stimulus[:NSTIM*2]\n",
    "\n",
    "# Plot\n",
    "subplot(411); plot(stimulus[NSTIM:])\n",
    "xlim(0,NSTIM); ylabel('pA'); noaxis(); nox()\n",
    "title('Stimulus')\n",
    "\n",
    "# Solve Izh model\n",
    "state = sim_izh(*izh,stimulus,dt=dt)\n",
    "V     = state[:,1][NSTIM:]\n",
    "Y     = state[:,2][NSTIM:]\n",
    "subplot(312); plot(V,color=OCHRE);\n",
    "addspikes(Y)\n",
    "xlim(0,NSTIM); noaxis(); nox()\n",
    "title('Simulated voltage and spikes');\n",
    "ylabel('mV');\n",
    "\n",
    "stimulus = stimulus[NSTIM:]\n",
    "\n",
    "# Build stimulus filter (history trace of I)\n",
    "# These are needed to model subthreshold dynamics\n",
    "demo_Bh = array([convolve(b,stimulus) for b in B ]).T[:NSTIM]\n",
    "demo_By = array([convolve(b,Y)        for b in Bp]).T[:NSTIM,:]\n",
    "\n",
    "# Plot stimulus history features\n",
    "subplot(313); plot(demo_Bh); \n",
    "xlim(0,NSTIM); noaxis(); xlabel('Time (ms)')\n",
    "title('Stimulus history features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrate moment-closure approximation of the AR-PP-GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered stimulus with offset\n",
    "stim = m + bhat_stimulus.dot(demo_Bh.T)\n",
    "\n",
    "# \"True\" sample from point process model\n",
    "logxpp,logvpp,ratepp,ratevpp = ensemble_sample_moments(stim,B,beta,M=1000)\n",
    "lxpp = box_filter(logxpp,5)\n",
    "lvpp = box_filter(logvpp,5)\n",
    "\n",
    "# Sample from langevin approximation of point process\n",
    "logxlv,logvlv,expmlv,expvlv  = langevin_sample_moments(stim,A,beta,C,M=5000)\n",
    "lxlv = box_filter(logxlv,5)\n",
    "lvlv = box_filter(logvlv,5)\n",
    "\n",
    "# Estimate moments from expansion to second order \n",
    "# Only first two moments of rate are used for filtering\n",
    "logxso,logvso,_,_ = integrate_moments(stim,A,beta,C,\n",
    "                                            method     = \"second_order\",\n",
    "                                            int_method = \"exponential\",\n",
    "                                            oversample = 3)\n",
    "\n",
    "logxmc,logvmc,_,_ = integrate_moments(stim,A,beta,C,\n",
    "                                            method     = \"moment_closure\",\n",
    "                                            int_method = \"euler\",\n",
    "                                            oversample = 5)\n",
    "\n",
    "logxmf,logvmf,_,_ = integrate_moments(stim,A,beta,C,\n",
    "                                            method     = \"LNA\",\n",
    "                                            int_method = \"euler\",\n",
    "                                            oversample = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(8,13))\n",
    "NROWS = 10\n",
    "NPLOT = 3000\n",
    "NSHOW = 1000\n",
    "\n",
    "def stimmarks():\n",
    "    axvline(padding,color=(0.5,)*3,lw=0.5)\n",
    "    axvline(ndemo-padding,color=(0.5,)*3,lw=0.5)\n",
    "\n",
    "# Plot second-order approximation\n",
    "subplot2grid((NROWS,2),(1,1),facecolor=(1,1,1,0))\n",
    "stderrplot(demo_lxpp  ,demo_lvpp  ,BLACK    ,filled=1)\n",
    "stderrplot(demo_logxso,demo_logvso,AZURE,filled=0)\n",
    "stimmarks(); xlim(0,ndemo); noy(); noaxis()\n",
    "yl = ylim()\n",
    "xlabel('Time (ms)')\n",
    "title('Second order')\n",
    "subfigurelabel('D')\n",
    "    \n",
    "# Plot true sampled GLM against Langevin sampled GLM\n",
    "subplot2grid((NROWS,2),(0,0),facecolor=(1,1,1,0))\n",
    "stderrplot(demo_lxpp,demo_lvpp,BLACK,filled=1)\n",
    "stderrplot(demo_lxlv,demo_lvlv,OCHRE,filled=0)\n",
    "stimmarks(); ylim(*yl); xlim(0,ndemo); noxyaxes()\n",
    "yscalebar(mean(ylim())/dB,20/dB,'20 dB'); \n",
    "title('Langevin approximation')\n",
    "subfigurelabel('A')\n",
    "\n",
    "# Plot mean-field LNA solution for moments\n",
    "subplot2grid((NROWS,2),(0,1),facecolor=(1,1,1,0))\n",
    "stderrplot(demo_lxpp  ,demo_lvpp  ,BLACK,filled=1)\n",
    "stderrplot(demo_logxmf,demo_logvmf,TURQUOISE,filled=0)\n",
    "stimmarks(); ylim(*yl); xlim(0,ndemo); noxyaxes(); simpleraxis()\n",
    "title('Mean-field, LNA')\n",
    "subfigurelabel('B')\n",
    "\n",
    "# Plot moment closure moments\n",
    "subplot2grid((NROWS,2),(1,0),facecolor=(1,1,1,0))\n",
    "stderrplot(demo_lxpp,demo_lvpp,BLACK,filled=1)\n",
    "stderrplot(demo_logxmc,demo_logvmc,RUST,filled=0)\n",
    "stimmarks(); ylim(*yl); xlim(0,ndemo); noy(); noaxis()\n",
    "xlabel('Time (ms)')\n",
    "title('Gaussian moment-closure')\n",
    "subfigurelabel('C')\n",
    "\n",
    "# Plot Izh neuron\n",
    "sc = 20\n",
    "ax4=subplot2grid((NROWS,2),(2,0),colspan=2,facecolor=(1,1,1,0))\n",
    "plot(V,color=RUST,lw=1.25)\n",
    "xlim(0,NSHOW);\n",
    "yscalebar(min(V)+25,50,'50 mV')\n",
    "offset = -min(stimulus*sc) + ylim()[1]+30\n",
    "ss = stimulus*sc + offset\n",
    "plot(ss,color=BLACK,lw=1)\n",
    "yscalebar(mean(ss),sc*5,'5 pA'); \n",
    "noxyaxes()\n",
    "title('Stimulus example')\n",
    "subfigurelabel('E')\n",
    "\n",
    "# Plot stimulus\n",
    "ax5=subplot2grid((NROWS,2),(3,0),colspan=2,facecolor=(1,1,1,0))\n",
    "stderrplot(lxpp,lvpp,BLACK,filled=1)\n",
    "# Langevin approximation\n",
    "stderrplot(logxlv,logvlv,OCHRE,filled=0)\n",
    "xlim(0,NSHOW); ylim(*yl); yscalebar(mean(ylim()),20,'20 dB'); noxyaxes(); \n",
    "title('Langevin approximation')\n",
    "subfigurelabel('F')\n",
    "\n",
    "# Plot sampled from Langevin (preserves some autocorrelation)\n",
    "ax6=subplot2grid((NROWS,2),(4,0),colspan=2,facecolor=(1,1,1,0))\n",
    "nsamp = 20\n",
    "p = np.random.poisson(exp(langevin_sample(stim,A,beta,C,M=nsamp)))\n",
    "pcolormesh(-int32(p.T>0),cmap='gray')\n",
    "noaxis(); nox(); xlim(0,NSHOW);\n",
    "ylabel('Sample',fontsize=9);\n",
    "\n",
    "# Plot stimulus\n",
    "ax7=subplot2grid((NROWS,2),(5,0),colspan=2,facecolor=(1,1,1,0))\n",
    "stderrplot(lxpp,lvpp,BLACK,filled=1)\n",
    "stderrplot(logxso,logvso,AZURE,filled=0)\n",
    "xlim(0,NSHOW); ylim(*yl); yscalebar(mean(ylim()),20,'20 dB'); noxyaxes(); \n",
    "title('Second-order state-space model')\n",
    "subfigurelabel('G')\n",
    "\n",
    "# Plot sampled from single-time marginals (no time correlation)\n",
    "ax8=subplot2grid((NROWS,2),(6,0),colspan=2,facecolor=(1,1,1,0))\n",
    "rate = exp(logxso)*(1+0.5*logvso)\n",
    "p = np.random.poisson(rate[:,None],(len(rate),nsamp))\n",
    "pcolormesh(-int32(p.T>0),cmap='gray')\n",
    "noaxis(); xticks(arange(0,1001,100)); xlim(0,NSHOW);\n",
    "xlabel('Time (ms)'); ylabel('Sample',fontsize=9); \n",
    "\n",
    "# Adjust axes\n",
    "subplots_adjust(wspace=0.1,hspace=0.3)\n",
    "nudge_axis_y(-75,ax4)\n",
    "adjust_axis_height_pixels(20,ax5)\n",
    "nudge_axis_y(-85,ax5)\n",
    "adjust_axis_height_pixels(30,ax6)\n",
    "nudge_axis_y(-35,ax6)\n",
    "adjust_axis_height_pixels(20,ax7)\n",
    "nudge_axis_y(-40,ax7)\n",
    "adjust_axis_height_pixels(30,ax8)\n",
    "nudge_axis_y(10,ax8)\n",
    "\n",
    "savefig(figure_prefix+'4.pdf',transparent=True,bbox_inches='tight',format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurement, filtering, and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFILT = NPLOT#200\n",
    "#assert(NFILT<=NPLOT)\n",
    "\n",
    "from measurements import *\n",
    "from arppglm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different updates (variational, Laplace, moment-matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logxso,logvso,M1,M2 = integrate_moments(stim,A,beta,C,\n",
    "                                        method     = \"second_order\",\n",
    "                                        int_method = \"exponential\",\n",
    "                                        oversample = 3)\n",
    "\n",
    "t = find(Y>0)[0]\n",
    "m1 = M1[t]\n",
    "m2 = M2[t]\n",
    "s  = stim[t]\n",
    "y  = Y[i]\n",
    "\n",
    "# Plot Prior\n",
    "v  = beta.T.dot(m2).dot(beta)[0,0]\n",
    "mu = beta.T.dot(m1)\n",
    "ss = sqrt(v)\n",
    "x = np.linspace(mu-4*ss,mu+6*ss,150)\n",
    "plot(x,npdf(mu,v**0.5,x).ravel(),color=GREEN,label='prior')\n",
    "\n",
    "# posterior, exact\n",
    "l = y*(x+s)-sexp(x+s)\n",
    "l-= np.max(l)\n",
    "l+=-.5*(x-mu)**2/v-.5*slog(v) \n",
    "p = sexp(l)\n",
    "eps = 1e-12\n",
    "p[p<eps] = eps   \n",
    "p = (p/np.sum(p)).ravel()\n",
    "plot(x,p/diff(x)[0],color=OCHRE,label='posterior')\n",
    "pmode = argmax(p)\n",
    "scatter([x[pmode]],[p[pmode]/diff(x)[0]],s=20,color=BLACK)\n",
    "axvline(x[pmode],color=BLACK)\n",
    "\n",
    "# Posterior moments\n",
    "mp,vp = univariate_lgp_update_moment(mu,v,y,s,1.0)\n",
    "l = -.5*(x-mp)**2/vp-.5*slog(vp) \n",
    "p = sexp(l-np.max(l))\n",
    "eps = 1e-12\n",
    "p[p<eps] = eps   \n",
    "p /= np.sum(p)\n",
    "plot(x,p/diff(x)[0],color=RUST,label='posterior moments')\n",
    "\n",
    "# Posterior moments\n",
    "mp,vp = univariate_lgp_update_variational(mu,v,y,s,1.0)\n",
    "l = -.5*(x-mp)**2/vp-.5*slog(vp) \n",
    "p = sexp(l-np.max(l))\n",
    "eps = 1e-12\n",
    "p[p<eps] = eps   \n",
    "p /= np.sum(p)\n",
    "plot(x,p/diff(x)[0],color=AZURE,label='posterior variational')\n",
    "\n",
    "# Posterior moments\n",
    "mp,vp = univariate_lgp_update_laplace(mu,v,y,s,1.0)\n",
    "l = -.5*(x-mp)**2/vp-.5*slog(vp) \n",
    "p = sexp(l-np.max(l))\n",
    "eps = 1e-12\n",
    "p[p<eps] = eps   \n",
    "p /= np.sum(p)\n",
    "plot(x,p/diff(x)[0],color=MAUVE,label='posterior Laplace')\n",
    "\n",
    "legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark different measurement updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = -5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,8))\n",
    "\n",
    "for i,measurement in enumerate(\"variational laplace moment\".split()):\n",
    "    tic()\n",
    "    fallLR,fallLV,fallM1,fallM2,nll = filter_moments(stim[:NFILT],Y[:NFILT],A,beta,C,m,\n",
    "                                         method      = \"moment_closure\",\n",
    "                                         int_method  = \"euler\",\n",
    "                                         measurement = measurement,\n",
    "                                         oversample  = 25,\n",
    "                                         reg_cov     = 0.0001,\n",
    "                                         reg_rate    = 0.0000)\n",
    "    toc()\n",
    "    print(nll)\n",
    "    subplot(4,1,i+1)\n",
    "    logr = m + bhat_stimulus.dot(demo_Bh.T) + bhat_spikehist.dot(demo_By.T)\n",
    "    stderrplot(fallLR,fallLV,BLACK,filled=1,lw=0.5)\n",
    "    xlim(0,NFILT);\n",
    "    plot(logr,color=RUST,lw=0.5)\n",
    "    simpleraxis()\n",
    "    title('method = %s'%measurement)\n",
    "    ylim(-40,20)\n",
    "\n",
    "# Compare to moment integration without filtering\n",
    "subplot(4,1,i+1)\n",
    "tic()\n",
    "fallLR,fallLV,fallM1,fallM2 = integrate_moments(stim[:NFILT],A,beta,C,\n",
    "                                     method      = \"second_order\",\n",
    "                                     int_method  = \"euler\",\n",
    "                                     oversample  = 4)\n",
    "toc()\n",
    "subplot(4,1,4)\n",
    "logr = m + bhat_stimulus.dot(demo_Bh.T) + bhat_spikehist.dot(demo_By.T)\n",
    "stderrplot(fallLR,fallLV,BLACK,filled=1,lw=0.5)\n",
    "xlim(0,NFILT);\n",
    "plot(logr,color=RUST,lw=0.5)\n",
    "simpleraxis()\n",
    "title('No Measurements')\n",
    "\n",
    "subplots_adjust(hspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optimize model likelihood using filtering (new model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "measurement = \"moment\"\n",
    "method      = \"moment_closure\"\n",
    "int_method  = \"euler\"\n",
    "oversample  = 25\n",
    "showplot    = False\n",
    "\n",
    "baseline_m = m\n",
    "\n",
    "#@memoize\n",
    "def objective(parameters):\n",
    "    # parameters encode beta,m\n",
    "    parameters = parameters.ravel()\n",
    "    m          = parameters[0]\n",
    "    beta       = parameters[1:].reshape((K,1))\n",
    "    stim2      = stim[:NFILT]*exp(m-baseline_m)\n",
    "    \n",
    "    # We need unconstrained system to also be stable!\n",
    "    '''\n",
    "    try:\n",
    "        LR,LV,M1,M2 = integrate_moments(stim2,A,beta,C,\n",
    "                                        method     = method,\n",
    "                                        int_method = int_method,\n",
    "                                        oversample = oversample)\n",
    "        # Ensure moments do not diverge\n",
    "        rate = exp(LR)*(1+0.5*LV)\n",
    "        if not all([np.all(np.isfinite(x)) for x in [LR,LV,M1,M2,rate]]): \n",
    "            return inf\n",
    "    except (KeyboardInterrupt, SystemExit): raise\n",
    "    except: return inf\n",
    "    '''\n",
    "    \n",
    "    # Get likelihood by filtering\n",
    "    try:\n",
    "        LR,LV,M1,M2,nll = filter_moments(stim2,Y[:NFILT],A,beta,C,m,\n",
    "                                         method      = method,\n",
    "                                         int_method  = int_method,\n",
    "                                         measurement = measurement,\n",
    "                                         oversample  = oversample,\n",
    "                                         reg_cov     = 0.005,\n",
    "                                         reg_rate    = 0.005)\n",
    "    except (KeyboardInterrupt, SystemExit): raise\n",
    "    except: \n",
    "        return inf\n",
    "    \n",
    "    print(nll,'['+','.join(['%0.6f'%x for x in parameters])+']')\n",
    "    if showplot:\n",
    "        subplot(311)\n",
    "        logr = m + bhat_stimulus.dot(demo_Bh.T) + bhat_spikehist.dot(demo_By.T)\n",
    "        stderrplot(fallLR,fallLV,BLACK,filled=1,lw=0.5)\n",
    "        xlim(0,NFILT);\n",
    "        plot(logr,color=RUST,lw=0.5)\n",
    "        simpleraxis()\n",
    "        show()\n",
    "    \n",
    "    if not np.isfinite(nll):\n",
    "        return inf\n",
    "    return nll\n",
    "\n",
    "p0 = np.zeros((1+K))\n",
    "p0[0 ] = m\n",
    "p0[1:] = beta.ravel()\n",
    "\n",
    "# Some previous optimization results; might want to start here \n",
    "p0 = [-5.11891304,7.73303371,-17.66706182,14.49299672,-8.02784155,4.92439071,-3.49133731,1.31580891,-0.97790629]\n",
    "parameters = minimize_retry(objective,p0)\n",
    "nll = objective(parameters)\n",
    "print(nll,'['+','.join(['%0.8f'%x for x in parameters])+']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new parameters from optimization\n",
    "parameters = array(parameters)\n",
    "m2         = parameters[0]-0.5\n",
    "beta2      = parameters[1:].reshape((K,1))\n",
    "\n",
    "logr2      = m2 + bhat_stimulus.dot(demo_Bh.T) + (beta2.T.dot(demo_By.T))[0]\n",
    "\n",
    "stim2 = stim*exp(m2-m)\n",
    "# \"True\" sample from new point process model\n",
    "logxpp2,logvpp2,ratepp2,ratevpp2 = ensemble_sample_moments(stim2,B,beta2,M=1000)\n",
    "lxpp2 = box_filter(logxpp2,5)\n",
    "lvpp2 = box_filter(logvpp2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSHOW = 1000\n",
    "\n",
    "subplot(411)\n",
    "fallLR,fallLV,fallM1,fallM2,nll = filter_moments(stim[:NFILT],Y[:NFILT],A,beta,C,m,\n",
    "                                     method      = \"second_order\",\n",
    "                                     int_method  = \"euler\",\n",
    "                                     oversample  = 5,\n",
    "                                     reg_cov     = 0.001)\n",
    "logr = m + bhat_stimulus.dot(demo_Bh.T) + bhat_spikehist.dot(demo_By.T)\n",
    "stderrplot(lxpp,lvpp,BLACK,filled=1)\n",
    "stderrplot(fallLR,fallLV,AZURE,filled=0)\n",
    "xlim(0,NSHOW);\n",
    "plot(logr,color=RUST)\n",
    "simpleraxis()\n",
    "title('unconstrained')\n",
    "\n",
    "subplot(412)\n",
    "fallLR,fallLV,fallM1,fallM2,nll = filter_moments(stim2[:NFILT],Y[:NFILT],A,beta2,C,m2,\n",
    "                                     method      = \"second_order\",\n",
    "                                     int_method  = \"euler\",\n",
    "                                     oversample  = 5,\n",
    "                                     reg_cov     = 0.001)\n",
    "stderrplot(lxpp,lvpp,BLACK,filled=1)\n",
    "stderrplot(fallLR,fallLV,AZURE,filled=0)\n",
    "xlim(0,NSHOW);\n",
    "plot(logr2,color=RUST)\n",
    "simpleraxis()\n",
    "\n",
    "# Unconstrained filtering\n",
    "subplot(413)\n",
    "fallLR,fallLV,fallM1,fallM2 = integrate_moments(stim[:NFILT],A,beta,C,\n",
    "                                     method      = \"second_order\",\n",
    "                                     int_method  = \"euler\",\n",
    "                                     oversample  = 5)\n",
    "stderrplot(lxpp,lvpp,BLACK,filled=1)\n",
    "stderrplot(fallLR,fallLV,AZURE,filled=0)\n",
    "xlim(0,NSHOW);\n",
    "plot(logr,color=RUST)\n",
    "simpleraxis()\n",
    "\n",
    "# Unconstrained filtering\n",
    "subplot(414)\n",
    "logxso2,logvso2,fallM1,fallM2 = integrate_moments(stim2[:NFILT],A,beta2,C,\n",
    "                                     method      = \"second_order\",\n",
    "                                     int_method  = \"euler\",\n",
    "                                     oversample  = 5)\n",
    "stderrplot(lxpp2,lvpp2,BLACK,filled=1)\n",
    "stderrplot(logxso2,logvso2,AZURE,filled=0)\n",
    "xlim(0,NSHOW);\n",
    "plot(logr2,color=RUST)\n",
    "simpleraxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(8,13))\n",
    "\n",
    "sc = 20\n",
    "ax4=subplot2grid((NROWS,2),(2,0),colspan=2,facecolor=(1,1,1,0))\n",
    "plot(V,color=RUST,lw=1.25)\n",
    "xlim(0,NSHOW);\n",
    "yscalebar(min(V)+25,50,'50 mV')\n",
    "offset = -min(stimulus*sc) + ylim()[1]+30\n",
    "ss = stimulus*sc + offset\n",
    "plot(ss,color=BLACK,lw=1)\n",
    "yscalebar(mean(ss),sc*5,'5 pA'); \n",
    "noxyaxes()\n",
    "title('Stimulus example')\n",
    "subfigurelabel('A')\n",
    "\n",
    "yl = (-40,20)\n",
    "\n",
    "# Plot stimulus\n",
    "ax5=subplot2grid((NROWS,2),(3,0),colspan=2,facecolor=(1,1,1,0))\n",
    "stderrplot(lxpp,lvpp,BLACK,filled=1)\n",
    "stderrplot(logxso,logvso,AZURE,filled=0)\n",
    "xlim(0,NSHOW); ylim(*yl); yscalebar(mean(ylim()),20,'20 dB'); noxyaxes(); \n",
    "title('Second-order state-space model')\n",
    "subfigurelabel('B')\n",
    "\n",
    "# Plot sampled from single-time marginals (no time correlation)\n",
    "ax6=subplot2grid((NROWS,2),(4,0),colspan=2,facecolor=(1,1,1,0))\n",
    "rate = exp(logxso)*(1+0.5*logvso)\n",
    "p = np.random.poisson(rate[:,None],(len(rate),nsamp))\n",
    "pcolormesh(-int32(p.T>0),cmap='gray')\n",
    "noxyaxes();  xlim(0,NSHOW);\n",
    "ylabel('Sample',fontsize=9); \n",
    "\n",
    "# Plot stimulus\n",
    "ax7=subplot2grid((NROWS,2),(5,0),colspan=2,facecolor=(1,1,1,0))\n",
    "stderrplot(lxpp2,lvpp2,BLACK,filled=1)\n",
    "stderrplot(logxso2,logvso2,AZURE,filled=0)\n",
    "xlim(0,NSHOW); ylim(*yl); yscalebar(mean(ylim()),20,'20 dB'); noxyaxes(); \n",
    "title('Second-order state-space model')\n",
    "subfigurelabel('G')\n",
    "\n",
    "# Plot sampled from single-time marginals (no time correlation)\n",
    "ax8=subplot2grid((NROWS,2),(6,0),colspan=2,facecolor=(1,1,1,0))\n",
    "rate = exp(logxso2)*(1+0.5*logvso2)\n",
    "p = np.random.poisson(rate[:,None],(len(rate),nsamp))\n",
    "pcolormesh(-int32(p.T>0),cmap='gray')\n",
    "noaxis(); xticks(arange(0,1001,100)); xlim(0,NSHOW);\n",
    "xlabel('Time (ms)'); ylabel('Sample',fontsize=9); \n",
    "\n",
    "\n",
    "# Adjust axes\n",
    "subplots_adjust(wspace=0.1,hspace=0.3)\n",
    "nudge_axis_y(-75,ax4)\n",
    "adjust_axis_height_pixels(20,ax5)\n",
    "nudge_axis_y(-85,ax5)\n",
    "adjust_axis_height_pixels(30,ax6)\n",
    "nudge_axis_y(-35,ax6)\n",
    "adjust_axis_height_pixels(20,ax7)\n",
    "nudge_axis_y(-40,ax7)\n",
    "adjust_axis_height_pixels(30,ax8)\n",
    "nudge_axis_y(10,ax8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems!\n",
    "\n",
    "Optimization is WAY too slow. There's also something wrong (excessive biase toward high rates). But to figure out what's wrong, we need a faster update!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The surrogate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arppglm import *\n",
    "from measurements import *\n",
    "from utilities import *\n",
    "from arguments import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_moments_surrogate(stim,Y,A,beta,C,m,\n",
    "    dt          = 1.0,\n",
    "    oversample  = 10,\n",
    "    maxrate     = 500,\n",
    "    maxvcorr    = 2000,\n",
    "    method      = \"moment_closure\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = 0.01,\n",
    "    reg_rate    = 0.001,\n",
    "    return_surrogates = True,\n",
    "    surrogates        = None):\n",
    "    # check arguments\n",
    "    if oversample<1:\n",
    "        raise ValueError('oversample must be non-negative integer')\n",
    "    if return_surrogates and not surrogates is None:\n",
    "        raise ValueError('Asked to compute surrogate likelihoods, but surrogates provided?')\n",
    "    if not return_surrogates and surrogates is None:\n",
    "        raise ValueError('No surrogate likelihoods provided?')\n",
    "    # Precompute constants\n",
    "    maxlogr   = np.log(maxrate)\n",
    "    maxratemc = maxvcorr*maxrate\n",
    "    dtfine    = dt/oversample\n",
    "    T         = len(stim)\n",
    "    K         = beta.size\n",
    "    I         = np.eye(K)\n",
    "    Cb        = C.dot(beta.T)\n",
    "    CC        = C.dot(C.T)\n",
    "    BB        = beta.dot(beta.T)\n",
    "    Adt       = A*dtfine\n",
    "    # Get measurement update function\n",
    "    measurement            = get_measurement(measurement)\n",
    "    mean_update,cov_update = get_moment_integrator(int_method,Adt)\n",
    "    update                 = get_update_function(method,Cb,Adt,maxvcorr)\n",
    "    # accumulate negative log-likelihood up to a constant\n",
    "    nll = 0\n",
    "    llrescale = 1.0/len(stim)\n",
    "    # Store surrogate likelihoods\n",
    "    if return_surrogates:\n",
    "        surrogates = np.zeros((T,2))\n",
    "    # Initial condition for moments\n",
    "    M1 = pinv(beta,m).reshape((K,1))\n",
    "    M2 = np.eye(K)*1e-2\n",
    "    for i,s in enumerate(stim):\n",
    "        # Integrate moments forward\n",
    "        for j in range(oversample):\n",
    "            logv  = beta.T.dot(M2).dot(beta)\n",
    "            logx  = min(beta.T.dot(M1)+s,maxlogr)\n",
    "            R0    = sexp(logx)*dtfine\n",
    "            Rm,J  = update(logx,logv,R0,M1,M2)\n",
    "            M2    = cov_update(M2,J) + CC*Rm\n",
    "            M1    = mean_update(M1)  + C*Rm\n",
    "        # Measurement update\n",
    "        pM1,pM2 = M1,M2\n",
    "        # If computing surrogates, requenst and store them\n",
    "        if return_surrogates:\n",
    "            M1,M2,ll,(mr,tr) = measurement_update_projected_gaussian_surrogate(\\\n",
    "                      M1,M2,Y[i],beta,s,dt,m,reg_rate,measurement,\n",
    "                      return_surrogate=True)\n",
    "            surrogates[i] = mr,tr\n",
    "        # Otherwise, pass precomputed surrogate likelihood for update\n",
    "        else:\n",
    "            mr,tr = surrogates[i]\n",
    "            M1,M2,ll = measurement_update_projected_gaussian_surrogate(\\\n",
    "                      M1,M2,Y[i],beta,s,dt,m,reg_rate,measurement,\n",
    "                      surrogate=(mr, tr))\n",
    "        nll -= ll*llrescale\n",
    "        \n",
    "        # Regularize\n",
    "        strength = reg_cov+max(0,-np.min(np.diag(M2)))\n",
    "        M2 = 0.5*(M2+M2.T) + strength*np.eye(K) \n",
    "        # Store moments\n",
    "        allM1[i] = M1[:,0].copy()\n",
    "        allM2[i] = M2.copy()\n",
    "        allLR[i] = beta.T.dot(M1)+s\n",
    "        allLV[i] = beta.T.dot(M2).dot(beta)\n",
    "        \n",
    "        # Heuristic: detect numerical failure and exit early\n",
    "        failed = False\n",
    "        failed|= np.any(M1)<-1e5\n",
    "        failed|= logx>100*maxlogr\n",
    "        failed|= nll<-1e10\n",
    "        if failed:\n",
    "            nll = inf\n",
    "            break\n",
    "    if return_surrogates:\n",
    "        return allLR,allLV,allM1,allM2,nll,surrogates\n",
    "    else:\n",
    "        return allLR,allLV,allM1,allM2,nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_likelihood_surrogate(stim,Y,A,beta,C,m,\n",
    "    dt          = 1.0,\n",
    "    oversample  = 10,\n",
    "    maxrate     = 500,\n",
    "    maxvcorr    = 2000,\n",
    "    method      = \"moment_closure\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = 0.01,\n",
    "    reg_rate    = 0.001,\n",
    "    surrogates  = None):\n",
    "    assert surrogates is not none\n",
    "    # Precompute constants\n",
    "    maxlogr   = np.log(maxrate)\n",
    "    maxratemc = maxvcorr*maxrate\n",
    "    dtfine    = dt/oversample\n",
    "    T         = len(stim)\n",
    "    K         = beta.size\n",
    "    I         = np.eye(K)\n",
    "    Cb        = C.dot(beta.T)\n",
    "    CC        = C.dot(C.T)\n",
    "    BB        = beta.dot(beta.T)\n",
    "    Adt       = A*dtfine\n",
    "    # Get measurement update function\n",
    "    measurement = get_measurement(measurement)\n",
    "    # Buid moment integrator functions\n",
    "    mean_update, cov_update = get_moment_integrator(int_method,Adt)\n",
    "    # Get update function (computes expected rate from moments)\n",
    "    update = get_update_function(method,Cb,Adt,maxvcorr)\n",
    "    # accumulate negative log-likelihood up to a constant\n",
    "    nll = 0\n",
    "    llrescale = 1.0/len(stim)\n",
    "    # Store moments\n",
    "    allM1 = np.zeros((T,K))\n",
    "    allM2 = np.zeros((T,K,K))\n",
    "    allLR = np.zeros((T))\n",
    "    allLV = np.zeros((T))\n",
    "    # Store surrogate likelihoods\n",
    "    if return_surrogates:\n",
    "        surrogates = np.zeros((T,2))\n",
    "    # Initial condition for moments\n",
    "    M1 = pinv(beta,m).reshape((K,1))\n",
    "    M2 = np.eye(K)*1e-2\n",
    "    for i,s in enumerate(stim):\n",
    "        # Regularize\n",
    "        M2 = 0.5*(M2+M2.T)+(reg_cov+max(0,-np.min(np.diag(M2))))*I\n",
    "        # Integrate moments forward\n",
    "        for j in range(oversample):\n",
    "            logv  = beta.T.dot(M2).dot(beta)\n",
    "            logx  = min(beta.T.dot(M1)+s,maxlogr)\n",
    "            R0    = sexp(logx)*dtfine\n",
    "            Rm,J  = update(logx,logv,R0,M1,M2)\n",
    "            M2    = cov_update(M2,J) + CC*Rm\n",
    "            M1    = mean_update(M1)  + C*Rm\n",
    "        # Measurement update\n",
    "        mr,tr    = surrogates[i]\n",
    "        M1,M2,ll = measurement_update_projected_gaussian_surrogate(\\\n",
    "                  M1,M2,Y[i],beta,s,dt,m,reg_rate,measurement,\n",
    "                  surrogate=(mr, tr))\n",
    "        nll -= ll*llrescale\n",
    "        # Heuristic: detect numerical failure and exit early\n",
    "        failed = False\n",
    "        failed|= np.any(M1)<-1e5\n",
    "        failed|= logx>100*maxlogr\n",
    "        failed|= nll<-1e10\n",
    "        if failed:\n",
    "            nll = inf\n",
    "            break\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement = \"moment\"\n",
    "method      = \"second_order\"\n",
    "int_method  = \"euler\"\n",
    "oversample  = 4\n",
    "showplot    = False\n",
    "\n",
    "p0 = np.zeros((1+K))\n",
    "p0[0 ] = m\n",
    "p0[1:] = beta.ravel()\n",
    "\n",
    "tic()\n",
    "LR,LV,M1,M2,nll,surrogates = filter_moments_surrogate(stim[:NFILT],Y[:NFILT],A,beta,C,m,\n",
    "                                 method      = method,\n",
    "                                 int_method  = int_method,\n",
    "                                 measurement = measurement,\n",
    "                                 oversample  = oversample,\n",
    "                                 reg_cov     = 0.0001,\n",
    "                                 reg_rate    = 0.0001,\n",
    "                                 return_surrogates = True)\n",
    "toc()\n",
    "print(nll)\n",
    "subplot(311)\n",
    "logr = m + bhat_stimulus.dot(demo_Bh.T) + bhat_spikehist.dot(demo_By.T)\n",
    "stderrplot(LR,LV,BLACK,filled=1,lw=0.5)\n",
    "xlim(0,NFILT);\n",
    "plot(logr,color=RUST,lw=0.5)\n",
    "simpleraxis()\n",
    "title('With measurements')\n",
    "\n",
    "tic()\n",
    "LR,LV,M1,M2,nll = filter_moments_surrogate(stim[:NFILT],Y[:NFILT],A,beta,C,m,\n",
    "                                 method      = method,\n",
    "                                 int_method  = int_method,\n",
    "                                 measurement = measurement,\n",
    "                                 oversample  = oversample,\n",
    "                                 reg_cov     = 0.0001,\n",
    "                                 reg_rate    = 0.0001,\n",
    "                                 return_surrogates = False,\n",
    "                                 surrogates  = surrogates)\n",
    "toc()\n",
    "print(nll)\n",
    "subplot(312)\n",
    "logr = m + bhat_stimulus.dot(demo_Bh.T) + bhat_spikehist.dot(demo_By.T)\n",
    "stderrplot(LR,LV,BLACK,filled=1,lw=0.5)\n",
    "xlim(0,NFILT);\n",
    "plot(logr,color=RUST,lw=0.5)\n",
    "simpleraxis()\n",
    "title('Surrogate measurements')\n",
    "\n",
    "\n",
    "tic()\n",
    "fallLR,fallLV,fallM1,fallM2 = integrate_moments(stim[:NFILT],A,beta,C,\n",
    "                                     method      = \"second_order\",\n",
    "                                     int_method  = \"euler\",\n",
    "                                     oversample  = 4)\n",
    "toc()\n",
    "print(nll)\n",
    "subplot(313)\n",
    "logr = m + bhat_stimulus.dot(demo_Bh.T) + bhat_spikehist.dot(demo_By.T)\n",
    "stderrplot(fallLR,fallLV,BLACK,filled=1,lw=0.5)\n",
    "xlim(0,NFILT);\n",
    "plot(logr,color=RUST,lw=0.5)\n",
    "simpleraxis()\n",
    "title('No measurements')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_m = m\n",
    "\n",
    "def objective(parameters):\n",
    "    # parameters encode beta,m\n",
    "    parameters = parameters.ravel()\n",
    "    \n",
    "    m    = parameters[0]\n",
    "    beta = parameters[1:].reshape((K,1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get likelihood by filtering\n",
    "    try:\n",
    "        LR,LV,M1,M2,nll = filter_moments_surrogate(\\\n",
    "                                                   stim[:NFILT]*exp(m-baseline_m),\n",
    "                                                   Y[:NFILT],\n",
    "                                                   A,beta,C,m,\n",
    "                                 method      = method,\n",
    "                                 int_method  = int_method,\n",
    "                                 measurement = measurement,\n",
    "                                 oversample  = oversample,\n",
    "                                 reg_cov     = 0.0001,\n",
    "                                 reg_rate    = 0.0001,\n",
    "                                 return_surrogates = False,\n",
    "                                 surrogates  = surrogates)\n",
    "    except (KeyboardInterrupt, SystemExit): \n",
    "        raise\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        nll = inf\n",
    "    \n",
    "    print(nll,'['+','.join(['%0.6f'%x for x in parameters])+']')\n",
    "    return nll\n",
    "\n",
    "parameters = minimize_retry(objective,p0)\n",
    "print('['+','.join(['%0.4f'%x for x in parameters])+']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect dynamics of new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters = [-6.8034,-14.5821,-12.4526,19.5295,-11.7096,9.0415,-4.9698,-1.2497,-0.5224]\n",
    "\n",
    "# Get new parameters from optimization\n",
    "parameters = array(parameters)\n",
    "m2         = parameters[0]-0.5\n",
    "beta2      = parameters[1:].reshape((K,1))\n",
    "logr2      = m2 + bhat_stimulus.dot(demo_Bh.T) + (beta2.T.dot(demo_By.T))[0]\n",
    "\n",
    "stim2 = stim*exp(m2-m)\n",
    "# \"True\" sample from new point process model\n",
    "logxpp2,logvpp2,ratepp2,ratevpp2 = ensemble_sample_moments(stim2,B,beta2,M=1000)\n",
    "lxpp2 = box_filter(logxpp2,5)\n",
    "lvpp2 = box_filter(logvpp2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NSHOW = 1000\n",
    "\n",
    "subplot(411)\n",
    "fallLR,fallLV,fallM1,fallM2,nll = filter_moments(stim[:NFILT],Y[:NFILT],A,beta,C,m,\n",
    "                                     method      = \"second_order\",\n",
    "                                     int_method  = \"euler\",\n",
    "                                     oversample  = 5,\n",
    "                                     reg_cov     = 0.001)\n",
    "logr = m + bhat_stimulus.dot(demo_Bh.T) + bhat_spikehist.dot(demo_By.T)\n",
    "stderrplot(lxpp,lvpp,BLACK,filled=1)\n",
    "stderrplot(fallLR,fallLV,AZURE,filled=0)\n",
    "xlim(0,NSHOW);\n",
    "plot(logr,color=RUST)\n",
    "simpleraxis()\n",
    "title('unconstrained')\n",
    "\n",
    "subplot(412)\n",
    "fallLR,fallLV,fallM1,fallM2,nll = filter_moments(\n",
    "    stim2[:NFILT],Y[:NFILT],A,beta2,C,m2,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    oversample  = 5,\n",
    "    reg_cov     = 0.001)\n",
    "stderrplot(lxpp,lvpp,BLACK,filled=1)\n",
    "stderrplot(fallLR,fallLV,AZURE,filled=0)\n",
    "xlim(0,NSHOW);\n",
    "plot(logr2,color=RUST)\n",
    "simpleraxis()\n",
    "\n",
    "# Unconstrained filtering\n",
    "subplot(413)\n",
    "fallLR,fallLV,fallM1,fallM2 = integrate_moments(\n",
    "    stim[:NFILT],A,beta,C,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    oversample  = 5)\n",
    "stderrplot(lxpp,lvpp,BLACK,filled=1)\n",
    "stderrplot(fallLR,fallLV,AZURE,filled=0)\n",
    "xlim(0,NSHOW);\n",
    "plot(logr,color=RUST)\n",
    "simpleraxis()\n",
    "\n",
    "# Unconstrained filtering\n",
    "subplot(414)\n",
    "logxso2,logvso2,fallM1,fallM2 = integrate_moments(\n",
    "    stim2[:NFILT],A,beta2,C,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    oversample  = 5)\n",
    "stderrplot(lxpp2,lvpp2,BLACK,filled=1)\n",
    "stderrplot(logxso2,logvso2,AZURE,filled=0)\n",
    "xlim(0,NSHOW);\n",
    "plot(logr,color=RUST)\n",
    "simpleraxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(8,13))\n",
    "\n",
    "sc = 20\n",
    "ax4=subplot2grid((NROWS,2),(2,0),colspan=2,facecolor=(1,1,1,0))\n",
    "plot(V,color=RUST,lw=1.25)\n",
    "xlim(0,NSHOW);\n",
    "yscalebar(min(V)+25,50,'50 mV')\n",
    "offset = -min(stimulus*sc) + ylim()[1]+30\n",
    "ss = stimulus*sc + offset\n",
    "plot(ss,color=BLACK,lw=1)\n",
    "yscalebar(mean(ss),sc*5,'5 pA'); \n",
    "noxyaxes()\n",
    "title('Stimulus example')\n",
    "subfigurelabel('A')\n",
    "\n",
    "yl = (-40,20)\n",
    "\n",
    "# Plot stimulus\n",
    "ax5=subplot2grid((NROWS,2),(3,0),colspan=2,facecolor=(1,1,1,0))\n",
    "stderrplot(lxpp,lvpp,BLACK,filled=1)\n",
    "stderrplot(logxso,logvso,AZURE,filled=0)\n",
    "xlim(0,NSHOW); ylim(*yl); yscalebar(mean(ylim()),20,'20 dB'); noxyaxes(); \n",
    "title('Second-order state-space model')\n",
    "subfigurelabel('B')\n",
    "\n",
    "# Plot sampled from single-time marginals (no time correlation)\n",
    "ax6=subplot2grid((NROWS,2),(4,0),colspan=2,facecolor=(1,1,1,0))\n",
    "rate = exp(logxso)*(1+0.5*logvso)\n",
    "p = np.random.poisson(rate[:,None],(len(rate),nsamp))\n",
    "pcolormesh(-int32(p.T>0),cmap='gray')\n",
    "noxyaxes();  xlim(0,NSHOW);\n",
    "ylabel('Sample',fontsize=9); \n",
    "\n",
    "# Plot stimulus\n",
    "ax7=subplot2grid((NROWS,2),(5,0),colspan=2,facecolor=(1,1,1,0))\n",
    "stderrplot(lxpp2,lvpp2,BLACK,filled=1)\n",
    "stderrplot(logxso2,logvso2,AZURE,filled=0)\n",
    "xlim(0,NSHOW); ylim(*yl); yscalebar(mean(ylim()),20,'20 dB'); noxyaxes(); \n",
    "title('Second-order state-space model')\n",
    "subfigurelabel('G')\n",
    "\n",
    "# Plot sampled from single-time marginals (no time correlation)\n",
    "ax8=subplot2grid((NROWS,2),(6,0),colspan=2,facecolor=(1,1,1,0))\n",
    "rate = exp(logxso2)*(1+0.5*logvso2)\n",
    "p = np.random.poisson(rate[:,None],(len(rate),nsamp))\n",
    "pcolormesh(-int32(p.T>0),cmap='gray')\n",
    "noaxis(); xticks(arange(0,1001,100)); xlim(0,NSHOW);\n",
    "xlabel('Time (ms)'); ylabel('Sample',fontsize=9); \n",
    "\n",
    "\n",
    "# Adjust axes\n",
    "subplots_adjust(wspace=0.1,hspace=0.3)\n",
    "nudge_axis_y(-75,ax4)\n",
    "adjust_axis_height_pixels(20,ax5)\n",
    "nudge_axis_y(-85,ax5)\n",
    "adjust_axis_height_pixels(30,ax6)\n",
    "nudge_axis_y(-35,ax6)\n",
    "adjust_axis_height_pixels(20,ax7)\n",
    "nudge_axis_y(-40,ax7)\n",
    "adjust_axis_height_pixels(30,ax8)\n",
    "nudge_axis_y(10,ax8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivation of variational update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match a multivariate Gaussian to the true measurement posterior using variational Bayes: minimize the KL divergence from the approximating to the true distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Pr(x) = \\left\\lvert 2\\pi\\Sigma \\right\\rvert ^{-\\frac 1 2} \\exp\\left({-\\frac 1 2 (x-\\mu)^\\top \\Sigma ^{-1} (x-\\mu)}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observation model is Poisson \n",
    "\n",
    "$$\n",
    "\\Pr(y|x) = \\frac 1 {y!} \\lambda^y e^{-\\lambda}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\ln\\lambda = \\beta^\\top x + I(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a variational update, we minimize\n",
    "\n",
    "$$\n",
    "D_{KL}( Q \\| \\Pr(x|y) ) = \n",
    "\\int_x Q(x) \\ln \\frac {Q(x)} {\\Pr(x|y)} = \\left< \\ln \\frac {Q(x)} {\\Pr(x|y)} \\right>_Q\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $Q(x)$ is the approximating variational posterior, which we will take to be multivariate normal $Q(x) \\sim \\mathcal{N}(\\tilde\\mu,\\tilde\\Sigma)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\Pr(x|y) \\propto \\Pr(y|x) P(x)$, we can minimize $D_{KL}$ by minimizing\n",
    "\n",
    "$$\n",
    "\\left< \\ln \\frac {Q(x) } {\\Pr(y|x)  {\\Pr(x)}  }\n",
    "\\right>_Q\n",
    "$$\n",
    "\n",
    "The prior and the likelihood can be separated, and we can focus on minimizing\n",
    "\n",
    "$$\n",
    "D_{KL}\\left( Q \\| P \\right)\n",
    "-\n",
    "\\left< \\ln \\Pr(y|x) \\right>_Q\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $D_{KL}\\left( Q \\| P \\right)$ between two Gaussian has the form\n",
    "\n",
    "$$\n",
    "D_{KL}\\left( Q \\| P \\right) = \n",
    "\\frac 1 2 \\left[tr( \\Sigma^{-1} \\tilde\\Sigma )\n",
    "+ (\\mu - \\tilde\\mu)^\\top \\Sigma^{-1} (\\mu - \\tilde\\mu)\n",
    "+ \\ln \\frac {|\\Sigma|}{|\\tilde\\Sigma|}\n",
    "\\right] + \\text{constant}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider then the second term, $\\left< \\ln \\Pr(y|x) \\right>_Q$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\ln\\Pr(y|x) = -\\ln y! + y \\ln \\lambda - \\lambda\n",
    "$$\n",
    "\n",
    "For the purposes of optimizing the posterior, $-\\ln y!$ is constant and can be ignored. Any terms here that do not depend on $x$ can be dropped as they are consant with respect to optimizing the posterior. Taking expectation over $Q$, we get\n",
    "\n",
    "$$\n",
    "\\left<\\ln\\Pr(y|x)\\right>_Q = \n",
    "y \\beta^\\top \\tilde\\mu - \\left< \\lambda \\right>_Q + \\text{constant}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expectation $\\left< \\lambda \\right>_Q$ looks familiar! It is the same expectation that we use for estimating $\\left<\\lambda\\right>$ in the moment closure, and we can use the same approximation for evaluating it, this time at the variational posterior $Q$. \n",
    "\n",
    "$$\n",
    "\\left< \\lambda \\right>_Q = \\exp\\left( \n",
    "\\beta^\\top \\tilde\\mu + I(t) + \\tfrac 1 2 \\beta^\\top \\tilde \\Sigma \\beta\n",
    "\\right)\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, we need to minimize\n",
    "\n",
    "$$\n",
    "\\frac 1 2 \\left[tr( \\Sigma^{-1} \\tilde\\Sigma )\n",
    "+ (\\tilde\\mu - \\mu)^\\top \\Sigma^{-1} (\\tilde\\mu - \\mu)\n",
    "+ \\ln \\frac {|\\Sigma|}{|\\tilde\\Sigma|}\n",
    "\\right]\n",
    "-\\left[\n",
    "y \\beta^\\top \\tilde\\mu - \\left< \\lambda \\right>_Q \n",
    "\\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient in $\\tilde\\mu$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla_{\\tilde\\mu}\n",
    "\\left[\\dots\n",
    "\\right] = \n",
    "\\Sigma^{-1} (\\tilde\\mu - \\mu)\n",
    "+\\left(\\left< \\lambda \\right>_Q - y\\right)\\beta^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hessian in $\\tilde\\mu$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla^2_{\\tilde\\mu} = \\Sigma^{-1} +  \\text{diag}\\left(\\left<\\lambda\\right>_Q\\beta^2\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fixed $\\tilde\\mu$, the optimal $\\tilde\\Sigma$ has the closed form (Zhao and Park 2016)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tilde\\Sigma^{-1} = \\Sigma^{-1} + \\text{diag}\\left( \n",
    "\\left<\\lambda\\right>_Q \\beta^2\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides a coordinate descent approach to obtaining the variational posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to backpropagate across a non-conjugate update. \n",
    "For a non-conjugate update, we estimate\n",
    "\n",
    "$$\n",
    "Q(x) \\approx P(x|y) = P(y|x) \\frac {P(x)} {P(y)}\n",
    "$$\n",
    "\n",
    "Usually $Q(x)\\sim\\mathcal{N}(\\hat\\mu,\\hat\\Sigma)$ is multivariate Gaussian. We estimate the likelihood $P(y)$ as\n",
    "\n",
    "$$\n",
    "P(y) \\approx \\frac{P(y|x{=}\\hat\\mu)} {Q(x{=}\\hat\\mu)} P(x{=}\\hat\\mu)\n",
    "$$\n",
    "\n",
    "Or the log-likelihood\n",
    "\n",
    "$$\n",
    "\\ln P(y) \\approx \\ln P(y|x{=}\\hat\\mu) - \\ln Q(x{=}\\hat\\mu) + \\ln P(x{=}\\hat\\mu)\n",
    "$$\n",
    "\n",
    "The likelihood and state-update are usually differentiable in parameters $\\theta$. The derivative of the posterior, which is the solution to a minimization problem, is less clear. \n",
    "\n",
    "$$\n",
    "\\nabla_\\theta \\ln Q(x{=}\\hat\\mu)\n",
    "$$\n",
    "\n",
    "If $Q$ is Gaussian evaluated at its mean, then \n",
    "\n",
    "$$\n",
    "\\ln Q(x{=}\\hat\\mu) = -\\frac 1 2 \\left\\lvert 2 \\pi \\hat \\Sigma \\right\\rvert\n",
    "$$\n",
    "\n",
    "To backpropagate / chain rule, we need to know\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta \\left\\lvert \\hat \\Sigma \\right\\rvert\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = 'float32'\n",
    "min_log = np.finfo(dtype).tiny\n",
    "max_exp = np.log(np.sqrt(np.finfo(dtype).max))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
