{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import absolute_import\n",
    "from __future__ import with_statement\n",
    "from __future__ import division\n",
    "from __future__ import nested_scopes\n",
    "from __future__ import generators\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "\n",
    "# Load scipy/numpy/matplotlib\n",
    "from   scipy.linalg import expm\n",
    "import matplotlib.pyplot as plt\n",
    "from   pylab import *\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from warnings import warn\n",
    "\n",
    "# Configure figure resolution\n",
    "plt.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "plt.rcParams['savefig.dpi'   ] = 100\n",
    "\n",
    "from izh       import * # Routines for sampling Izhikevich neurons\n",
    "from plot      import * # Misc. plotting routines\n",
    "from glm       import * # GLM fitting\n",
    "from arppglm   import * # Sampling and integration\n",
    "from utilities import * # Other utilities\n",
    "from arguments import * # Argument verification\n",
    "\n",
    "'''\n",
    "import os\n",
    "dtype='float64'\n",
    "flags = 'mode=FAST_RUN,device=gpu,floatX=%s'%dtype\n",
    "if dtype!='float64':\n",
    "    flags += ',warn_float64=warn'\n",
    "os.environ[\"THEANO_FLAGS\"] = flags\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "'''\n",
    "\n",
    "import os\n",
    "dtype='float32'\n",
    "os.environ['MKL_THREADING_LAYER']='GNU'\n",
    "flags = 'mode=FAST_COMPILE,device=cuda0,'#,floatX=%s'%dtype\n",
    "if dtype!='float64':\n",
    "     flags += ',warn_float64=warn'\n",
    "os.environ[\"THEANO_FLAGS\"] = flags\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from theano_arppglm import *\n",
    "\n",
    "print('Workspace Initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved GLM features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#filename = 'saved_training_model.mat'\n",
    "filename = 'saved_training_model_badburster.mat'\n",
    "\n",
    "saved_training_model = scipy.io.loadmat(filename)\n",
    "K  = np.array(saved_training_model['K'],dtype=dtype)\n",
    "B  = np.array(saved_training_model['B'],dtype=dtype)\n",
    "By = np.array(saved_training_model['By'],dtype=dtype)\n",
    "Bh = np.array(saved_training_model['Bh'],dtype=dtype)\n",
    "A  = np.array(saved_training_model['A'],dtype=dtype)\n",
    "C  = np.array(saved_training_model['C'],dtype=dtype)\n",
    "Y  = np.array(saved_training_model['Y'],dtype=dtype)\n",
    "dt = np.array(saved_training_model['dt'],dtype=dtype)\n",
    "\n",
    "Bh_train = saved_training_model['Bh_train']\n",
    "By_train = saved_training_model['By_train']\n",
    "X_train  = concatenate([By_train,Bh_train],axis=1)\n",
    "Y_train  = asvector(saved_training_model['Y_train'])\n",
    "\n",
    "Bh_test  = saved_training_model['Bh_test']\n",
    "By_test  = saved_training_model['By_test']\n",
    "X_test   = concatenate([By_test,Bh_test],axis=1)\n",
    "Y_test   = asvector(saved_training_model['Y_test'])\n",
    " \n",
    "K  = int(scalar(K))\n",
    "N  = prod(Y.shape)\n",
    "\n",
    "N = len(X_train)\n",
    "STARTPLOT=0\n",
    "NPLOT=N\n",
    "\n",
    "print('Saved GLM features loaded')\n",
    "print(N)\n",
    "\n",
    "#STARTSHOW = 14000\n",
    "#STOPSHOW = 16000\n",
    "STARTSHOW = 0\n",
    "STOPSHOW = N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLM helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def lograte(Bh,By,p):\n",
    "    '''\n",
    "    Log-intensity of point process model on this dataset\n",
    "    Predicted using the standard GLM way\n",
    "    '''\n",
    "    m       = array(p).ravel()[0]\n",
    "    beta    = ascolumn(p[1:K+1])\n",
    "    beta_st = ascolumn(p[1+K:])\n",
    "    lograte = m + Bh.dot(beta_st) + By.dot(beta)\n",
    "    return lograte\n",
    "\n",
    "def logmean(Bh,M1,p):\n",
    "    '''\n",
    "    Projected history process\n",
    "    Predicted using history-process means\n",
    "    '''\n",
    "    m       = array(p).ravel()[0]\n",
    "    beta    = ascolumn(p[1:K+1])\n",
    "    beta_st = ascolumn(p[1+K:])\n",
    "    M1      = np.squeeze(M1)\n",
    "    return (beta.T.dot(M1.T))[0] + (m + Bh.dot(beta_st))[:,0]\n",
    "\n",
    "def get_stim(Bh,p):\n",
    "    m        = array(p).ravel()[0]\n",
    "    beta     = ascolumn(p[1:K+1])\n",
    "    beta_st  = ascolumn(p[1+K:])\n",
    "    stim     = (m + Bh.dot(beta_st))[:,0]\n",
    "    return stim\n",
    "\n",
    "def filter_GLM_np(Bh,p):\n",
    "    m        = array(p).ravel()[0]\n",
    "    beta     = ascolumn(p[1:K+1])\n",
    "    beta_st  = ascolumn(p[1+K:])\n",
    "    stim     = get_stim(Bh,p)\n",
    "    allM1_np = np.zeros((N,K))\n",
    "    M1       = np.zeros((K,1))\n",
    "    for i in range(N):\n",
    "        R   = scalar(sexp(p0[1:K+1].dot(M1)+m+stim[i]))\n",
    "        M1 += A.dot(M1)*dt + C.dot(R)\n",
    "        allM1_np[i] = M1[:,0]\n",
    "    return allM1_np\n",
    "\n",
    "def addspikes_(Y_=None):\n",
    "    if Y_ is None or Y_ is True:\n",
    "        Y_ = Y\n",
    "    for t in find(Y_>0):\n",
    "        axvline(t,color=OCHRE,lw=0.4)\n",
    "    \n",
    "def niceaxis(plotspikes=True):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\",message='No labelled objects found')\n",
    "        legend()\n",
    "    simpleraxis()\n",
    "    xlim(STARTSHOW,STOPSHOW)\n",
    "    if plotspikes is True or not plotspikes is None:\n",
    "        addspikes_(plotspikes)\n",
    "\n",
    "print('GLM helpers done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# Re-fit GLM\n",
    "m,bhat  = fitGLM(X_train,asvector(Y_train))\n",
    "\n",
    "# Re-pack model parameters\n",
    "p0      = np.zeros((1+len(bhat)))\n",
    "p0[0 ]  = m\n",
    "p0[1:]  = bhat\n",
    "\n",
    "allM1_np = filter_GLM_np(Bh_train,p0)\n",
    "subplot(311)\n",
    "plot(lograte(Bh_train,By_train,p0),lw=0.4,label='conditional intensity')\n",
    "plot(logmean(Bh_train,allM1_np,p0),lw=0.4,label='mean-field',color=RUST)\n",
    "niceaxis()\n",
    "ylim(min(lograte(Bh_train,By_train,p0)),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters at which to filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "oversample = 10   # Integration resolution\n",
    "maxrate    = 10.0 # Largest allowed rate\n",
    "maxvcorr   = 10.0 # Largest allowed variance correction\n",
    "dt         = 1.0  # Data time resolution\n",
    "reg_cov    = 1e-5\n",
    "reg_rate   = 1e-5\n",
    "\n",
    "p = p0.copy()\n",
    "#p[1:K+1] *= 0.775\n",
    "stim_np = get_stim(Bh_train,p)\n",
    "beta_np = ascolumn(p[1:K+1])\n",
    "print('Filtering using p=',v2str(p))\n",
    "\n",
    "# Helper function to compute negative expected log-likelihood\n",
    "def post_hoc_nll(LR,LV):\n",
    "    R0 = sexp(LR)\n",
    "    R1 = R0*(1+0.5*LV)\n",
    "    ELL  = np.mean(Y*LR - R1)\n",
    "    return -ELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Theano routines\n",
    "\n",
    "For integrating moments (not conditioned on data), filtering (conditioned on data), and filtering using surrogate likelihoods (Gaussian approximations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "### Build Theano routines\n",
    "\n",
    "For integrating moments (not conditioned on data), filtering (conditioned on data), and filtering using surrogate likelihoods (Gaussian approximations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from theano_arppglm import *\n",
    "\n",
    "GLM_log_intensity, GLMNLL_f, GLMNLL_g, GLMNLL_h = build_ML_GLM_likelihood_theano()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "integrate_moments_theano, EMNLL_filt, EMNLL_grad = build_integrate_moments_theano(N,A,C,\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "filter_moments_theano, NLL_filt, NLL_grad = build_filter_moments_theano(N,A,C,\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    return_surrogates = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "filter_surrogate_theano, SNLL_filt, SNLL_grad = build_filter_moments_theano(N,A,C,\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    return_surrogates = False,\n",
    "    use_surrogates    = True)\n",
    "\n",
    "print('Theano functions bulit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate to establish prior\n",
    "\n",
    "We will use the integrated moments (without measurements) as a prior distribution for our K-step prediction with measurement updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m        = array(p).ravel()[0]\n",
    "beta     = ascolumn(p[1:K+1])\n",
    "beta_st  = ascolumn(p[1+K:])\n",
    "stim     = (m + Bh_train.dot(beta_st))[:,0]\n",
    "stim_np  = stim\n",
    "beta_np  = ascolumn(p[1:K+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "p = p0.copy()\n",
    "#p[1:]*=3\n",
    "\n",
    "m        = array(p).ravel()[0]\n",
    "beta     = ascolumn(p[1:K+1])\n",
    "beta_st  = ascolumn(p[1+K:])\n",
    "stim     = (m + Bh_train.dot(beta_st))[:,0]\n",
    "stim_np  = stim\n",
    "beta_np  = ascolumn(p[1:K+1])\n",
    "\n",
    "print('Filtering using p=',v2str(p))\n",
    "\n",
    "tic()\n",
    "allLRni,allLVni,allM1ni,allM2ni = integrate_moments(stim_np,A,beta_np,C,\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\")\n",
    "toc()\n",
    "subplot(411)\n",
    "stderrplot(allLRni,allLVni,color=BLACK,lw=0.5)\n",
    "niceaxis()\n",
    "xlim(STARTSHOW,STOPSHOW)\n",
    "title('Integrating, numpy')\n",
    "\n",
    "tic()\n",
    "allLRti,allLVti,allM1ti,allM2ti = integrate_moments_theano(Bh_train,p)\n",
    "toc()\n",
    "subplot(412)\n",
    "stderrplot(allLRti,allLVti,color=BLACK,lw=0.5)\n",
    "niceaxis()\n",
    "xlim(STARTSHOW,STOPSHOW)\n",
    "title('Integrating, theano')\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep filtering in Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "tic()\n",
    "allLRn,allLVn,allM1n,allM2n,nlln,mrn,vrn = filter_moments(stim,Y_train,A,beta,C,p[0],\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    return_surrogates = True)\n",
    "toc()\n",
    "\n",
    "subplot(411)\n",
    "stderrplot(allLRn,allLVn,color=BLACK,lw=0.5)\n",
    "niceaxis()\n",
    "xlim(STARTSHOW,STOPSHOW)\n",
    "title('Filtering, numpy')\n",
    "print('nll, numpy',nlln)\n",
    "\n",
    "tic()\n",
    "allLRt,allLVt,allM1t,allM2t,nllt,mrt,vrt = filter_moments_theano(Bh_train,Y_train,p)\n",
    "toc()\n",
    "subplot(412)\n",
    "stderrplot(allLRt,allLVt,color=BLACK,lw=0.5)\n",
    "niceaxis()\n",
    "xlim(STARTSHOW,STOPSHOW)\n",
    "title('Filtering, theano')\n",
    "print('nll, theano',nllt)\n",
    "\n",
    "subplot(413)\n",
    "plot(allLRn,color=BLACK,label='log-λ numpy')\n",
    "plot(allLRt,':',color=RUST,label='log-λ theano')\n",
    "niceaxis()\n",
    "xlim(STARTSHOW,STOPSHOW)\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5\n",
    "ND = N-D\n",
    "\n",
    "priorLR,priorLV,priorM1,priorM2 = allLRt,allLVt,allM1t,allM2t\n",
    "\n",
    "# shift prior one time-step to exactly match case\n",
    "# in which we filter linearly starting at time 0\n",
    "#priorM1[1:]=priorM1[:-1]\n",
    "#priorM2[1:]=priorM2[:-1]\n",
    "#priorM1[0]=np.zeros((K,1))\n",
    "#priorM2[0]=np.eye(K)*1e-6\n",
    "\n",
    "defaultM1 = np.zeros((K,1))\n",
    "defaultM2 = np.eye(K)*1e-6\n",
    "\n",
    "iniM1 = np.zeros((N,K,1))\n",
    "iniM2 = np.zeros((N,K,K))\n",
    "iniM1[:D-1]=defaultM1\n",
    "iniM2[:D-1]=defaultM2\n",
    "iniM1[D-1:]=priorM1[:-D+1]\n",
    "iniM2[D-1:]=priorM2[:-D+1]\n",
    "allM1 = iniM1.copy()\n",
    "allM2 = iniM2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Start with naive implementation for reference\n",
    "\n",
    "Demonstrate shallow depth-5 filtering. Even starting from a prior with no inforamation about the filtered state, these results can be relatively accurate. This could lead to parallel filtering routines to accelerate inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Precompute constants\n",
    "maxlogr   = np.log(maxrate)\n",
    "maxratemc = maxvcorr*maxrate\n",
    "dtfine    = dt/oversample\n",
    "Cb        = C.dot(beta.T)\n",
    "CC        = C.dot(C.T)\n",
    "Adt       = A*dtfine\n",
    "\n",
    "themeasurement = 'moment'\n",
    "int_method = 'euler'\n",
    "method = 'second_order'\n",
    "\n",
    "# Get measurement update function\n",
    "measurement = get_measurement(themeasurement)\n",
    "# Buid moment integrator functions\n",
    "mean_update, cov_update = get_moment_integrator(int_method,Adt)\n",
    "# Get update function (computes expected rate from moments)\n",
    "update = get_update_function(method,Cb,Adt,maxvcorr)\n",
    "\n",
    "allLR = np.zeros(N)\n",
    "allLV = np.zeros(N)\n",
    "\n",
    "for i in range(N):\n",
    "    b = i+1\n",
    "    a = i-D+1\n",
    "    a = max(0,a)\n",
    "    c = i-D+1\n",
    "    ini = (priorM1[c],priorM2[c]) if c>=0 else (defaultM1,defaultM2)\n",
    "    lr,lv,_,_,_,_,_ = filter_moments(stim[a:b],Y_train[a:b],A,beta,C,p[0],\n",
    "        dt          = dt,\n",
    "        oversample  = oversample,\n",
    "        maxrate     = maxrate,\n",
    "        maxvcorr    = maxvcorr,\n",
    "        method      = \"second_order\",\n",
    "        int_method  = \"euler\",\n",
    "        measurement = \"moment\",\n",
    "        reg_cov     = reg_cov,\n",
    "        reg_rate    = reg_rate,\n",
    "        return_surrogates = True,\n",
    "        initial_conditions = ini)\n",
    "    allLR[i] = lr[-1]\n",
    "    allLV[i] = lv[-1]\n",
    "\n",
    "assert(all(isfinite(allLR)))\n",
    "assert(all(isfinite(allLV)))\n",
    "\n",
    "allLRref,allLVref = allLR,allLV\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRn,allLVn,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "ylim(max(ylim()[0],-100),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpack naive parallel filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "allLR = np.zeros(N)\n",
    "allLV = np.zeros(N)\n",
    "\n",
    "for i in range(N):\n",
    "    b = i+1\n",
    "    a = i-D+1\n",
    "    # Initial condition for moments\n",
    "    M1 = priorM1[a] if a>=0 else defaultM1\n",
    "    M2 = priorM2[a] if a>=0 else defaultM2\n",
    "    \n",
    "    a = max(0,a)\n",
    "    S = stim[a:b]\n",
    "    Y = Y_train[a:b]\n",
    "    \n",
    "    for j,(s,y) in enumerate(zip(S,Y)):\n",
    "        # Regularize\n",
    "        if reg_cov>0:\n",
    "            strength = reg_cov+max(0,-np.min(np.diag(M2)))\n",
    "            M2 = 0.5*(M2+M2.T) + strength*np.eye(K) \n",
    "        # Integrate moments forward\n",
    "        for k in range(oversample):\n",
    "            logv  = beta.T.dot(M2).dot(beta)\n",
    "            logx  = min(beta.T.dot(M1)+s,maxlogr)\n",
    "            R0    = sexp(logx)\n",
    "            R0    = min(maxrate,R0)\n",
    "            R0   *= dtfine\n",
    "            Rm,J  = update(logx,logv,R0,M1,M2)\n",
    "            M2    = cov_update(M2,J) + CC*Rm\n",
    "            M1    = mean_update(M1)  + C*Rm\n",
    "        # Measurement update\n",
    "        pM1,pM2 = M1,M2\n",
    "        M1,M2,ll,mr,vr = measurement_update_projected_gaussian(\\\n",
    "                  M1,M2,y,beta,s,dt,m,reg_rate,measurement)\n",
    "       \n",
    "    allLR[i] = min(beta.T.dot(M1)+s,maxlogr)\n",
    "    allLV[i] = beta.T.dot(M2).dot(beta)\n",
    "\n",
    "    assert(all(isfinite(allLR)))\n",
    "    assert(all(isfinite(allLV)))\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "ylim(max(ylim()[0],-100),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-order loops toward a parallel implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "S = stim\n",
    "Y = Y_train\n",
    "allLR = np.zeros(N)\n",
    "allLV = np.zeros(N)\n",
    "allM1 = np.zeros((N,K,1))\n",
    "allM2 = np.zeros((N,K,K))\n",
    "allRC = np.zeros((N,K,K))\n",
    "for i in range(N):\n",
    "    allRC[i,...]=reg_cov*np.eye(K)\n",
    "\n",
    "iniM1 = np.zeros((N,K,1))\n",
    "iniM2 = np.zeros((N,K,K))\n",
    "iniM1[:D-1]=defaultM1\n",
    "iniM2[:D-1]=defaultM2\n",
    "iniM1[D-1:]=priorM1[:-D+1]\n",
    "iniM2[D-1:]=priorM2[:-D+1]\n",
    "allM1[...] = iniM1\n",
    "allM2[...] = iniM2\n",
    "\n",
    "for di in arange(-D+1,1):\n",
    "    for i in range(N):\n",
    "        # Initial condition for moments\n",
    "        M1 = allM1[i]\n",
    "        M2 = allM2[i]\n",
    "        offset = max(0,di+i)\n",
    "        s = S[offset]\n",
    "        y = Y[offset]\n",
    "        # Regularize\n",
    "        if reg_cov>0:\n",
    "            strength = reg_cov+max(0,-np.min(np.diag(M2)))\n",
    "            M2 = 0.5*(M2+M2.T) + strength*np.eye(K) \n",
    "        # Integrate moments forward\n",
    "        for k in range(oversample):\n",
    "            logv  = beta.T.dot(M2).dot(beta)\n",
    "            logx  = min(beta.T.dot(M1)+s,maxlogr)\n",
    "            R0    = sexp(logx)\n",
    "            R0    = min(maxrate,R0)\n",
    "            R0   *= dtfine\n",
    "            Rm,J  = update(logx,logv,R0,M1,M2)\n",
    "            M2    = cov_update(M2,J) + CC*Rm\n",
    "            M1    = mean_update(M1)  + C*Rm\n",
    "        # Measurement update\n",
    "        M1,M2,ll,mr,vr = measurement_update_projected_gaussian(\\\n",
    "                  M1,M2,y,beta,s,dt,m,reg_rate,measurement)\n",
    "        allM1[i]=M1\n",
    "        allM2[i]=M2\n",
    "        assert(all(isfinite(allM1)))\n",
    "        assert(all(isfinite(allM2)))\n",
    "        \n",
    "for i in range(N):\n",
    "    M1 = allM1[i,:,0]\n",
    "    M2 = allM2[i]\n",
    "    allLR[i] = min(beta.T.dot(M1)+S[i],maxlogr)\n",
    "    allLV[i] = beta.T.dot(M2).dot(beta)\n",
    "    assert(all(isfinite(allLR)))\n",
    "    assert(all(isfinite(allLV)))\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "ylim(max(ylim()[0],-100),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One more loop re-arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "S = stim\n",
    "Y = Y_train\n",
    "allLR = np.zeros(N)\n",
    "allLV = np.zeros(N)\n",
    "allM1 = np.zeros((N,K,1))\n",
    "allM2 = np.zeros((N,K,K))\n",
    "allRC = np.zeros((N,K,K))\n",
    "for i in range(N):\n",
    "    allRC[i,...]=reg_cov*np.eye(K)\n",
    "allM1[...] = iniM1\n",
    "allM2[...] = iniM2\n",
    "    \n",
    "for di in arange(-D+1,1):\n",
    "    # Reset values that really shouldn't be being integrated? \n",
    "    #allM1[:-di,...]=iniM1[:-di,...]\n",
    "    #allM2[:-di,...]=iniM2[:-di,...]\n",
    "    if reg_cov>0:\n",
    "        for i in range(N):\n",
    "            M2 = allM2[i]\n",
    "            M2 = 0.5*(M2+M2.T) + reg_cov*np.eye(K) \n",
    "            allM2[i] = M2\n",
    "    \n",
    "    for k in range(oversample):\n",
    "        for i in range(N):\n",
    "            # Initial condition for moments\n",
    "            M1 = allM1[i]\n",
    "            M2 = allM2[i]\n",
    "            offset = max(0,di+i)\n",
    "            s = S[offset]\n",
    "            logv  = beta.T.dot(M2).dot(beta)\n",
    "            logx  = min(beta.T.dot(M1)+s,maxlogr)\n",
    "            R0    = sexp(logx)\n",
    "            R0    = min(maxrate,R0)\n",
    "            R0   *= dtfine\n",
    "            Rm,J  = update(logx,logv,R0,M1,M2)\n",
    "            M2    = cov_update(M2,J) + CC*Rm\n",
    "            M1    = mean_update(M1)  + C*Rm\n",
    "            allM1[i]=M1\n",
    "            allM2[i]=M2\n",
    "            \n",
    "    # Measurement update\n",
    "    for i in range(N):\n",
    "        M1    = allM1[i]\n",
    "        M2    = allM2[i]\n",
    "        offset = max(0,di+i)\n",
    "        s     = S[offset]\n",
    "        y     = Y[offset]\n",
    "        M1,M2,ll,mr,vr = measurement_update_projected_gaussian(\\\n",
    "                  M1,M2,y,beta,s,dt,m,reg_rate,measurement,safe=True)\n",
    "        allM1[i]=M1\n",
    "        allM2[i]=M2\n",
    "        assert(all(isfinite(allM1)))\n",
    "        assert(all(isfinite(allM2)))\n",
    "        \n",
    "for i in range(N):\n",
    "    M1 = allM1[i,:,0]\n",
    "    M2 = allM2[i]\n",
    "    allLR[i] = min(beta.T.dot(M1)+S[i],maxlogr)\n",
    "    allLV[i] = beta.T.dot(M2).dot(beta)\n",
    "    assert(all(isfinite(allLR)))\n",
    "    assert(all(isfinite(allLV)))\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "ylim(max(ylim()[0],-100),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some vectorization of inner loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "allLR = np.zeros(N)\n",
    "allLV = np.zeros(N)\n",
    "allM1 = np.zeros((N,K,1))\n",
    "allM2 = np.zeros((N,K,K))\n",
    "S = stim\n",
    "Y = Y_train\n",
    "allM1[...] = iniM1\n",
    "allM2[...] = iniM2\n",
    "\n",
    "for di in arange(-D+1,1):\n",
    "    # Reset values that really shouldn't be being integrated? \n",
    "    allM1[:-di,...]=iniM1[:-di,...]\n",
    "    allM2[:-di,...]=iniM2[:-di,...]\n",
    "    # Regularize\n",
    "    if reg_cov>0:\n",
    "        allM2 = 0.5*(allM2 + allM2.transpose(0,2,1)) + allRC\n",
    "    # Integrate moments forward\n",
    "    for k in range(oversample):\n",
    "        offsets = np.maximum(0,arange(N)+di)\n",
    "        S_ = S[offsets]\n",
    "        LOGV = allM2.dot(beta[:,0]).dot(beta[:,0])\n",
    "        LOGX = np.minimum(maxlogr,allM1[:,:,0].dot(beta[:,0])+S_)\n",
    "        R0_  = np.minimum(maxrate,sexp(LOGX))*dtfine\n",
    "        RM = R0_ * np.minimum(1+0.5*LOGV,maxvcorr)\n",
    "        J_   = Cb[None,:,:]*R0_[:,None,None]+Adt[None,:,:]\n",
    "        allM1 += np.matmul(Adt,allM1[:,:,:])\n",
    "        JM2_   = np.matmul(J_,allM2)\n",
    "        allM2 += JM2_ + JM2_.transpose((0,2,1))\n",
    "        allM1 +=  C[None,:,:]*RM[:,None,None]\n",
    "        allM2 += CC[None,:,:]*RM[:,None,None]\n",
    "        allM1 = np.clip(allM1,-100,100)\n",
    "        allM2 = np.clip(allM2,-100,100)\n",
    "    # Measurement update\n",
    "    for i in range(N):\n",
    "        M1    = allM1[i]\n",
    "        M2    = allM2[i]\n",
    "        offset = max(0,di+i)\n",
    "        s     = S[offset]\n",
    "        y     = Y[offset]\n",
    "        M1,M2,ll,mr,vr = measurement_update_projected_gaussian(\\\n",
    "                  M1,M2,y,beta,s,dt,m,reg_rate,measurement)\n",
    "        allM1[i]=M1\n",
    "        allM2[i]=M2\n",
    "    allM1 = np.clip(allM1,-100,100)\n",
    "    allM2 = np.clip(allM2,-100,100)\n",
    "        \n",
    "for i in range(N):\n",
    "    M1 = allM1[i,:,0]\n",
    "    M2 = allM2[i]\n",
    "    allLR[i] = min(beta.T.dot(M1)+S[i],maxlogr)\n",
    "    allLV[i] = beta.T.dot(M2).dot(beta)\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "ylim(max(ylim()[0],-100),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The parallel measurement is a tricky one! Start by unpacking it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "allLR = np.zeros(N)\n",
    "allLV = np.zeros(N)\n",
    "allM1 = np.zeros((N,K,1))\n",
    "allM2 = np.zeros((N,K,K))\n",
    "S = stim\n",
    "Y = Y_train\n",
    "allM1[...] = iniM1\n",
    "allM2[...] = iniM2\n",
    "\n",
    "for di in arange(-D+1,1):\n",
    "    # Reset values that really shouldn't be being integrated? \n",
    "    allM1[:-di,...]=iniM1[:-di,...]\n",
    "    allM2[:-di,...]=iniM2[:-di,...]\n",
    "    # Regularize\n",
    "    if reg_cov>0:\n",
    "        allM2 = 0.5*(allM2 + allM2.transpose(0,2,1)) + allRC\n",
    "    # Integrate moments forward\n",
    "    for k in range(oversample):\n",
    "        offsets = np.maximum(0,arange(N)+di)\n",
    "        S_ = S[offsets]\n",
    "        LOGV = allM2.dot(beta[:,0]).dot(beta[:,0])\n",
    "        LOGX = np.minimum(maxlogr,allM1[:,:,0].dot(beta[:,0])+S_)\n",
    "        R0_  = np.minimum(maxrate,sexp(LOGX))*dtfine\n",
    "        RM = R0_ * np.minimum(1+0.5*LOGV,maxvcorr)\n",
    "        J_   = Cb[None,:,:]*R0_[:,None,None]+Adt[None,:,:]\n",
    "        allM1 += np.matmul(Adt,allM1[:,:,:])\n",
    "        JM2_   = np.matmul(J_,allM2)\n",
    "        allM2 += JM2_ + JM2_.transpose((0,2,1))\n",
    "        allM1 +=  C[None,:,:]*RM[:,None,None]\n",
    "        allM2 += CC[None,:,:]*RM[:,None,None]\n",
    "        allM1 = np.clip(allM1,-100,100)\n",
    "        allM2 = np.clip(allM2,-100,100)\n",
    "    # Measurement update\n",
    "    for i in range(N):\n",
    "        M1    = allM1[i]\n",
    "        M2    = allM2[i]\n",
    "        offset = max(0,di+i)\n",
    "        s     = S[offset]\n",
    "        y     = Y[offset]\n",
    "        #M1,M2,ll,mr,vr = measurement_update_projected_gaussian(\\\n",
    "        #          M1,M2,y,beta,s,dt,m,reg_rate,measurement)\n",
    "        # Validate arguments\n",
    "        m2b = M2.dot(beta)\n",
    "        lv  = max(eps,(beta.T.dot(m2b))[0,0])\n",
    "        lm  = (beta.T.dot(M1))[0,0]\n",
    "        lt  = 1/lv\n",
    "        tq  = lt + reg_rate\n",
    "        mq = (lm*lt+m*reg_rate)/tq\n",
    "        vq  = 1/tq\n",
    "        mp,vp = measurement(mq,vq,y,s,dt)\n",
    "        if vp<eps: vp=eps\n",
    "        tp = 1/vp\n",
    "        tr = max(eps,tp-lt)\n",
    "        vr = scalar(1/tr)\n",
    "        mr = (mp*tp-lm*lt)/tr\n",
    "        Kg  = m2b/(vr+lv)\n",
    "        M2 = M2 - Kg.dot(m2b.T)\n",
    "        M1 = M1 + Kg*(mr-lm)\n",
    "        #logr   = mp+s\n",
    "        #logPyx = y*logr-sexp(logr)\n",
    "        #ll     = logPyx + 0.5*slog(vp/v) - 0.5*(mp-m)**2/v \n",
    "        allM1[i]=M1\n",
    "        allM2[i]=M2\n",
    "        allM1 = np.clip(allM1,-100,100)\n",
    "        allM2 = np.clip(allM2,-100,100)\n",
    "        \n",
    "for i in range(N):\n",
    "    M1 = allM1[i,:,0]\n",
    "    M2 = allM2[i]\n",
    "    allLR[i] = min(beta.T.dot(M1)+S[i],maxlogr)\n",
    "    allLV[i] = beta.T.dot(M2).dot(beta)\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "ylim(max(ylim()[0],-100),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "allLR = np.zeros(N)\n",
    "allLV = np.zeros(N)\n",
    "allM1 = np.zeros((N,K,1))\n",
    "allM2 = np.zeros((N,K,K))\n",
    "allM1[...] = iniM1\n",
    "allM2[...] = iniM2\n",
    "\n",
    "for di in arange(-D+1,1):\n",
    "    # Reset values that really shouldn't be being integrated? \n",
    "    allM1[:-di,...]=iniM1[:-di,...]\n",
    "    allM2[:-di,...]=iniM2[:-di,...]\n",
    "    # Regularize\n",
    "    if reg_cov>0:\n",
    "        allM2 = 0.5*(allM2 + allM2.transpose(0,2,1)) + allRC\n",
    "    # Integrate moments forward\n",
    "    for k in range(oversample):\n",
    "        offsets = np.maximum(0,arange(N)+di)\n",
    "        S_ = S[offsets]\n",
    "        LOGV = allM2.dot(beta[:,0]).dot(beta[:,0])\n",
    "        LOGX = np.minimum(maxlogr,allM1[:,:,0].dot(beta[:,0])+S_)\n",
    "        R0_  = np.minimum(maxrate,sexp(LOGX))*dtfine\n",
    "        RM = R0_ * np.minimum(1+0.5*LOGV,maxvcorr)\n",
    "        J_   = Cb[None,:,:]*R0_[:,None,None]+Adt[None,:,:]\n",
    "        allM1 += np.matmul(Adt,allM1[:,:,:])\n",
    "        JM2_   = np.matmul(J_,allM2)\n",
    "        allM2 += JM2_ + JM2_.transpose((0,2,1))\n",
    "        allM1 +=  C[None,:,:]*RM[:,None,None]\n",
    "        allM2 += CC[None,:,:]*RM[:,None,None]\n",
    "        allM1 = np.clip(allM1,-100,100)\n",
    "        allM2 = np.clip(allM2,-100,100)\n",
    "    # Parallel measurement update\n",
    "    offsets = maximum(0,arange(N)+di)\n",
    "    S_ = S[offsets]\n",
    "    Y_ = Y[offsets]\n",
    "    M2B_ = np.matmul(allM2,beta)\n",
    "    LV = allM2.dot(beta[:,0]).dot(beta[:,0])\n",
    "    LV = maximum(1e-12,LV)\n",
    "    LM = allM1[:,:,0].dot(beta[:,0])\n",
    "    LT = 1/LV\n",
    "    TQ = LT + reg_rate\n",
    "    VQ = 1/TQ\n",
    "    MQ = (LM*LT+m*reg_rate)*VQ\n",
    "    intr = linspace(-4,4,25)\n",
    "    X_ = intr[None,:]*sqrt(VQ)[:,None]+MQ[:,None]\n",
    "    R0_ = X_ + S_[:,None]+slog(dt)\n",
    "    L = Y_[:,None]*R0_-sexp(R0_)\n",
    "    L = L - np.max(L,axis=1)[:,None]\n",
    "    L += -.5*(X_-MQ[:,None])**2/VQ[:,None]-.5*slog(VQ)[:,None]\n",
    "    PR = sexp(L)\n",
    "    PR = maximum(1e-7,PR)\n",
    "    NR = np.sum(PR,axis=1)\n",
    "    MP = np.sum(X_*PR,axis=1)/NR\n",
    "    VP = np.sum((X_-MP[:,None])**2*PR,axis=1)/NR\n",
    "    VP = maximum(1e-12,VP)\n",
    "    TP = 1/VP\n",
    "    TR = TP-LT\n",
    "    TR = maximum(1e-12,TR)\n",
    "    VR = 1/TR\n",
    "    MR = (MP*TP-LM*LT)*VR\n",
    "    KG = M2B_/(VR+LV)[:,None,None]\n",
    "    allM2 -= np.matmul(KG,M2B_.transpose(0,2,1))\n",
    "    allM1 += KG*(MR-LM)[:,None,None]\n",
    "    # likelihood\n",
    "    LOGR = MP+S_\n",
    "    LOGPYX = Y_*LOGR-sexp(LOGR)\n",
    "    LL = LOGPYX + 0.5*slog(VP/LV) - 0.5*(MP-LM)**2/LV\n",
    "for i in range(N):\n",
    "    M1 = allM1[i,:,0]\n",
    "    M2 = allM2[i]\n",
    "    allLR[i] = min(beta.T.dot(M1)+S[i],maxlogr)\n",
    "    allLV[i] = beta.T.dot(M2).dot(beta)\n",
    "    allM1 = np.clip(allM1,-100,100)\n",
    "    allM2 = np.clip(allM2,-100,100)\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "ylim(max(ylim()[0],-100),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean things up a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "allLR = np.zeros(N)\n",
    "allLV = np.zeros(N)\n",
    "allM1 = np.zeros((N,K,1))\n",
    "allM2 = np.zeros((N,K,K))\n",
    "allM1[...] = iniM1\n",
    "allM2[...] = iniM2\n",
    "\n",
    "for di in range(-D+1,1):\n",
    "    # Reset values that really shouldn't be being integrated? \n",
    "    allM1[:-di,...]=iniM1[:-di,...]\n",
    "    allM2[:-di,...]=iniM2[:-di,...]\n",
    "    # Regularize\n",
    "    if reg_cov>0:\n",
    "        allM2 = 0.5*(allM2 + allM2.transpose(0,2,1)) + allRC\n",
    "    offsets = np.maximum(0,np.arange(N)+di)\n",
    "    S_ = S[offsets]\n",
    "    Y_ = Y[offsets]\n",
    "    for k in range(oversample):\n",
    "        LOGV = allM2.dot(beta[:,0]).dot(beta[:,0])\n",
    "        LOGX = np.minimum(maxlogr,allM1[:,:,0].dot(beta[:,0])+S_)\n",
    "        R0_  = np.minimum(maxrate,sexp(LOGX))*dtfine\n",
    "        RM = R0_ * np.minimum(1+0.5*LOGV,maxvcorr)\n",
    "        J_   = Cb[None,:,:]*R0_[:,None,None]+Adt[None,:,:]\n",
    "        allM1 += np.matmul(Adt,allM1[:,:,:])\n",
    "        JM2_   = np.matmul(J_,allM2)\n",
    "        allM2 += JM2_ + JM2_.transpose((0,2,1))\n",
    "        allM1 +=  C[None,:,:]*RM[:,None,None]\n",
    "        allM2 += CC[None,:,:]*RM[:,None,None]\n",
    "    # Parallel measurement update\n",
    "    M2B_ = np.matmul(allM2,beta)\n",
    "    LV = allM2.dot(beta[:,0]).dot(beta[:,0])\n",
    "    LV = np.maximum(1e-12,LV)\n",
    "    LM = allM1[:,:,0].dot(beta[:,0])\n",
    "    LT = 1/LV\n",
    "    TQ = LT + reg_rate\n",
    "    VQ = 1/TQ\n",
    "    MQ = (LM*LT+m*reg_rate)*VQ\n",
    "    intr = np.linspace(-4,4,25)\n",
    "    X_ = intr[None,:]*np.sqrt(VQ)[:,None]+MQ[:,None]\n",
    "    R0_ = X_ + S_[:,None]+slog(dt)\n",
    "    L = Y_[:,None]*R0_-sexp(R0_)\n",
    "    L = L - np.max(L,axis=1)[:,None]\n",
    "    L += -.5*((intr**2)[None,:]+slog(VQ)[:,None])\n",
    "    PR = sexp(L)\n",
    "    PR = np.maximum(1e-7,PR)\n",
    "    NR = 1/np.sum(PR,axis=1)\n",
    "    MP = np.sum(X_*PR,axis=1)*NR\n",
    "    VP = np.sum((X_-MP[:,None])**2*PR,axis=1)*NR\n",
    "    VP = np.maximum(1e-12,VP)\n",
    "    TP = 1/VP\n",
    "    VR = 1/np.maximum(1e-12,TP-LT)\n",
    "    MR = (MP*TP-LM*LT)*VR\n",
    "    KG = M2B_/(VR+LV)[:,None,None]\n",
    "    allM2 -= np.matmul(KG,M2B_.transpose(0,2,1))\n",
    "    allM1 += KG*(MR-LM)[:,None,None]\n",
    "    LOGR = MP+S_\n",
    "    LOGPYX = Y_*LOGR-sexp(LOGR)\n",
    "    LL = LOGPYX - 0.5*(slog(LV/VP) + (MP-LM)**2/LV)\n",
    "for i in range(N):\n",
    "    M1 = allM1[i,:,0]\n",
    "    M2 = allM2[i]\n",
    "    allLR[i] = min(beta.T.dot(M1)+S[i],maxlogr)\n",
    "    allLV[i] = beta.T.dot(M2).dot(beta)\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,-mean(LL))\n",
    "ylim(max(ylim()[0],-100),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to theano scan style syntax\n",
    "\n",
    "Buliding a theano program with a for loop leads to computational grpahs that are too large, they need to be written as scans for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "allLR = np.zeros(N)\n",
    "allLV = np.zeros(N)\n",
    "allM1 = np.zeros((N,K,1))\n",
    "allM2 = np.zeros((N,K,K))\n",
    "allM1[...] = iniM1\n",
    "allM2[...] = iniM2\n",
    "\n",
    "def project_moments_parallel(allM1,allM2,S_):\n",
    "    LOGV   = allM2.dot(beta[:,0]).dot(beta[:,0])\n",
    "    LOGM   = allM1[:,:,0].dot(beta[:,0])\n",
    "    LOGX   = np.minimum(maxlogr,LOGM+S_)\n",
    "    return LOGV,LOGM,LOGX\n",
    "\n",
    "def integrate_moments_parallel(allM1,allM2,S_):\n",
    "    #LOGV   = allM2.dot(beta[:,0]).dot(beta[:,0])\n",
    "    #LOGX   = np.minimum(maxlogr,allM1[:,:,0].dot(beta[:,0])+S_)\n",
    "    LOGV,LOGM,LOGX = project_moments_parallel(allM1,allM2,S_)\n",
    "    R0_    = np.minimum(maxrate,sexp(LOGX))*dtfine\n",
    "    RM     = R0_ * np.minimum(1+0.5*LOGV,maxvcorr)\n",
    "    allM1 += np.matmul(Adt,allM1[:,:,:])\n",
    "    allM1 += C[None,:,:]*RM[:,None,None]\n",
    "    J_     = Cb[None,:,:]*R0_[:,None,None]+Adt[None,:,:]\n",
    "    JM2_   = np.matmul(J_,allM2)\n",
    "    allM2 += JM2_ + JM2_.transpose((0,2,1))\n",
    "    allM2 += CC[None,:,:]*RM[:,None,None]\n",
    "    return allM1,allM2\n",
    "\n",
    "def measurement_update_parallel(allM1,allM2,S_,Y_):\n",
    "    # Parallel measurement update\n",
    "    M2B_ = np.matmul(allM2,beta)\n",
    "    LV = allM2.dot(beta[:,0]).dot(beta[:,0])\n",
    "    LV = np.maximum(1e-12,LV)\n",
    "    LM = allM1[:,:,0].dot(beta[:,0])\n",
    "    LT = 1/LV\n",
    "    TQ = LT + reg_rate\n",
    "    VQ = 1/TQ\n",
    "    MQ = (LM*LT+m*reg_rate)*VQ\n",
    "    intr = np.linspace(-4,4,25)\n",
    "    X_ = intr[None,:]*np.sqrt(VQ)[:,None]+MQ[:,None]\n",
    "    R0_ = X_ + S_[:,None]+slog(dt)\n",
    "    L = Y_[:,None]*R0_-sexp(R0_)\n",
    "    L = L - np.max(L,axis=1)[:,None]\n",
    "    L += -.5*((intr**2)[None,:]+slog(VQ)[:,None])\n",
    "    PR = np.maximum(1e-7,sexp(L))\n",
    "    NR = 1/np.sum(PR,axis=1)\n",
    "    MP = np.sum(X_*PR,axis=1)*NR\n",
    "    VP = np.sum((X_-MP[:,None])**2*PR,axis=1)*NR\n",
    "    TP = 1/np.maximum(1e-12,VP)\n",
    "    VR = 1/np.maximum(1e-12,TP-LT)\n",
    "    MR = (MP*TP-LM*LT)*VR\n",
    "    KG = M2B_/(VR+LV)[:,None,None]\n",
    "    allM2 -= np.matmul(KG,M2B_.transpose(0,2,1))\n",
    "    allM1 += KG*(MR-LM)[:,None,None]\n",
    "    LOGR = MP+S_\n",
    "    LOGPYX = Y_*LOGR-sexp(LOGR)\n",
    "    LL = LOGPYX - 0.5*(slog(LV/VP) + (MP-LM)**2/LV)\n",
    "    return allM1,allM2,LL\n",
    "\n",
    "def filter_moments_parallel(di,allM1,allM2):\n",
    "    # Reset values that really shouldn't be being integrated? \n",
    "    allM1[:-di,...]=iniM1[:-di,...]\n",
    "    allM2[:-di,...]=iniM2[:-di,...]\n",
    "    # Regularize\n",
    "    if reg_cov>0:\n",
    "        allM2 = 0.5*(allM2 + allM2.transpose(0,2,1)) + allRC\n",
    "    offsets = np.maximum(0,np.arange(N)+di)\n",
    "    S_ = S[offsets]\n",
    "    Y_ = Y[offsets]\n",
    "    for k in range(oversample):\n",
    "        allM1,allM2 = integrate_moments_parallel(allM1,allM2,S_)\n",
    "    allM1,allM2,LL = measurement_update_parallel(allM1,allM2,S_,Y_)\n",
    "    return allM1,allM2,LL\n",
    "\n",
    "for di in range(-D+1,1):\n",
    "    allM1,allM2,LL = filter_moments_parallel(di,allM1,allM2)\n",
    "\n",
    "allLV = allM2.dot(beta[:,0]).dot(beta[:,0])\n",
    "allLR = np.minimum(maxlogr,allM1[:,:,0].dot(beta[:,0])+S)\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,-mean(LL))\n",
    "ylim(max(ylim()[0],-100),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compartamentalize in function\n",
    "\n",
    "Note that parallel shallow filtering is still slower than running the full forward pass, as we must perform O(D*N) work as opposed to O(N). However, this will admits a depth-D algorithm in theano which may give us some improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "tic()\n",
    "allLRn,allLVn,allM1n,allM2n,nlln,mrn,vrn = filter_moments(stim,Y_train,A,beta,C,p[0],\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    return_surrogates = True)\n",
    "toc()\n",
    "\n",
    "from dstep import filter_moments_dstep\n",
    "\n",
    "tic()\n",
    "allLRnd,allLVnd,allM1nd,allM2nd,nllnd = filter_moments_dstep(D,stim,Y_train,A,beta,C,p[0],\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    prior       = (iniM1,iniM2))\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLRnd,allLVnd,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "ylim(max(ylim()[0],-100),5)\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,nllnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add prior for initial conditions\n",
    "\n",
    "This can get us a little closer to the \"true\" filtered states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "'''_,_,priorM1,priorM2 = integrate_moments_theano(Bh_train,p)\n",
    "\n",
    "tic()\n",
    "allLRnd,allLVnd,allM1nd,allM2nd,nllnd = filter_moments_dstep(D,stim,Y_train,A,beta,C,p[0],\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    prior       = (priorM1,priorM2))\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=AZURE,lw=0.5,filled=0)\n",
    "stderrplot(allLRt,allLVt,color=BLACK,lw=0.5)\n",
    "#stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLRnd,allLVnd,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "ylim(max(ylim()[0],-100),5)\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,nllnd)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm that shallow filtering can handle cases where deep filtering fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "'''p = p0.copy()\n",
    "p[1:]*=5\n",
    "\n",
    "m        = array(p).ravel()[0]\n",
    "beta     = ascolumn(p[1:K+1])\n",
    "beta_st  = ascolumn(p[1+K:])\n",
    "stim     = (m + Bh_train.dot(beta_st))[:,0]\n",
    "\n",
    "D = 5\n",
    "\n",
    "tic()\n",
    "allLRn,allLVn,allM1n,allM2n,nlln,mrn,vrn = filter_moments(stim,Y_train,A,beta,C,p[0],\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    return_surrogates = True)\n",
    "toc()\n",
    "\n",
    "\n",
    "tic()\n",
    "allLRt,allLVt,allM1t,allM2t,nllt,mrt,vrt = filter_moments_theano(Bh_train,Y_train,p)\n",
    "toc()\n",
    "\n",
    "from dstep import filter_moments_dstep\n",
    "\n",
    "\n",
    "pLR,pLV,priorM1,priorM2 = integrate_moments_theano(Bh_train,p)\n",
    "\n",
    "tic()\n",
    "allLRnd,allLVnd,allM1nd,allM2nd,nllnd = filter_moments_dstep(D,stim,Y_train,A,beta,C,p[0],\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = 1,\n",
    "    maxvcorr    = 5,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    prior       = (priorM1,priorM2))\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRn,allLVn,color=BLACK,lw=0.5)\n",
    "stderrplot(allLRt,allLVt,color=AZURE,lw=0.5,filled=0)\n",
    "stderrplot(pLR,pLV,color=OCHRE,lw=0.5,filled=0)\n",
    "stderrplot(allLRnd,allLVnd,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,nllnd)\n",
    "\n",
    "ylim(-50,10)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now work toward a theano implementation\n",
    "\n",
    "The hope is that on a good GPU, shallow depth-D filtering will be faster that deep filtering. Implementing this all at once is much too challenging, let's implement theano functio to replace pieces at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation in Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano_arppglm import *\n",
    "from theano_arppglm import Tmatmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m        = array(p).ravel()[0]\n",
    "beta     = ascolumn(p[1:K+1])\n",
    "beta_st  = ascolumn(p[1+K:])\n",
    "stim     = (m + Bh_train.dot(beta_st))[:,0]\n",
    "stim_np  = stim\n",
    "beta_np  = ascolumn(p[1:K+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "S = stim\n",
    "Y = Y_train\n",
    "\n",
    "allRC = np.zeros((N,K,K))\n",
    "for i in range(N):\n",
    "    allRC[i,...]=reg_cov*np.eye(K)\n",
    "\n",
    "TAdt  = Tcon(Adt)\n",
    "Tbeta = Tcon(beta)\n",
    "Tb    = Tcon(p.ravel()[1:K+1])\n",
    "TC    = Tcon(C ).dimshuffle('x',0,1)\n",
    "TCb   = Tcon(Cb).dimshuffle('x',0,1)\n",
    "TCC   = Tcon(CC).dimshuffle('x',0,1)\n",
    "\n",
    "mxl = Tcon(maxlogr)\n",
    "mxr = Tcon(maxrate)\n",
    "dtf = Tcon(dtfine)\n",
    "xvc = Tcon(maxvcorr)\n",
    "rr  = Tcon(reg_rate)\n",
    "mm  = Tcon(m)\n",
    "\n",
    "def project_moments_parallel_theano_source(M1,M2,S):\n",
    "    LOGV = M2.dot(Tb).dot(Tb) # N\n",
    "    LOGM = M1[:,:,0].dot(Tb) # N\n",
    "    LOGX = Tmn(mxl,LOGM+S) # N\n",
    "    R0   = Tmn(mxr,Tsexp(LOGX))*dtf # N \n",
    "    RM   = R0 * Tmn(1.0+0.5*LOGV,xvc) # N\n",
    "    return LOGV,LOGM,LOGX,R0,RM\n",
    "TallM1 = T.tensor3(\"TallM1\",dtype=dtype)\n",
    "TallM2 = T.tensor3(\"TallM2\",dtype=dtype)\n",
    "TallS_ = T.vector(\"TallS_\",dtype=dtype)\n",
    "project_moments_parallel_theano = Tfun(\n",
    "    inp = [TallM1,TallM2,TallS_],\n",
    "    out = project_moments_parallel_theano_source(TallM1,TallM2,TallS_))\n",
    "\n",
    "def euler_update_moments_parallel_theano_source(M1,M2,R0,RM):\n",
    "    M1  += TAdt.dot(M1).transpose(1,0,2)\n",
    "    J    = TCb*R0[:,None,None]+TAdt[None,:,:]\n",
    "    JM2  = T.batched_dot(J,M2)\n",
    "    M2  += JM2 + JM2.transpose((0,2,1))\n",
    "    M1  += TC *RM[:,None,None]\n",
    "    M2  += TCC*RM[:,None,None]\n",
    "    return M1,M2\n",
    "TR0 = T.vector(\"TR0\",dtype=dtype)\n",
    "TRM = T.vector(\"TRM\",dtype=dtype)\n",
    "euler_update_moments_parallel_theano = Tfun(\n",
    "    inp = [TallM1,TallM2,TR0,TRM],\n",
    "    out = euler_update_moments_parallel_theano_source(TallM1,TallM2,TR0,TRM))\n",
    "\n",
    "def integrate_moments_parallel_theano_source(M1,M2,S):\n",
    "    LOGV,LOGM,LOGX,R0,RM = project_moments_parallel_theano_source(M1,M2,S)\n",
    "    M1,M2 = euler_update_moments_parallel_theano_source(M1,M2,R0,RM)\n",
    "    return M1,M2\n",
    "integrate_moments_parallel_theano = Tfun(\n",
    "    inp = [TallM1,TallM2,TallS_],\n",
    "    out = integrate_moments_parallel_theano_source(TallM1,TallM2,TallS_))\n",
    "\n",
    "def univariate_prior_parallel_theano_source(LM,LT):\n",
    "    TQ = LT + rr\n",
    "    VQ = Tsinv(TQ)\n",
    "    MQ = (LM*LT+mm*rr)*VQ\n",
    "    return MQ,VQ\n",
    "TLM = T.vector(\"TLM\",dtype=dtype)\n",
    "TLT = T.vector(\"TLT\",dtype=dtype)\n",
    "univariate_prior_parallel_theano = Tfun(\n",
    "    inp = [TLM,TLT],\n",
    "    out = univariate_prior_parallel_theano_source(TLM,TLT))\n",
    "\n",
    "def quadrature_moments_parallel(MQ,VQ,S_,Y_):\n",
    "    intr = np.linspace(-4,4,25)\n",
    "    X_ = intr[None,:]*np.sqrt(VQ)[:,None]+MQ[:,None]\n",
    "    R0_ = X_ + S_[:,None]+slog(dt)\n",
    "    L = Y_[:,None]*R0_-sexp(R0_)\n",
    "    L = L - np.max(L,axis=1)[:,None]\n",
    "    L += -.5*((intr**2)[None,:]+slog(VQ)[:,None])\n",
    "    PR = np.maximum(1e-7,sexp(L))\n",
    "    NR = 1/np.sum(PR,axis=1)\n",
    "    MP = np.sum(X_*PR,axis=1)*NR\n",
    "    VP = np.sum((X_-MP[:,None])**2*PR,axis=1)*NR\n",
    "    return MP,VP\n",
    "\n",
    "Tintr = Tcon(np.linspace(-4,4,25))\n",
    "def quadrature_moments_parallel_theano_source(MQ,VQ,S,Y):\n",
    "    X  = Tintr[None,:]*T.sqrt(VQ)[:,None]+MQ[:,None]\n",
    "    R0 = X + S[:,None]+Tslog(Tcast(dt))\n",
    "    L  = Y[:,None]*R0-Tsexp(R0)\n",
    "    L  = L - T.max(L,axis=1)[:,None]\n",
    "    L += -0.5*((Tintr**2.0)[None,:]+Tslog(VQ)[:,None])\n",
    "    PR = Tmx(Tcon(1e-7),Tsexp(L))\n",
    "    NR = Tsinv(T.sum(PR,axis=1))\n",
    "    MP = T.sum(X*PR,axis=1)*NR\n",
    "    VP = T.sum((X-MP[:,None])**2.0*PR,axis=1)*NR\n",
    "    return MP,VP\n",
    "\n",
    "TMQ = T.vector(\"TMQ\",dtype=dtype)\n",
    "TVQ = T.vector(\"TVQ\",dtype=dtype)\n",
    "TS_ = T.vector(\"TS_\",dtype=dtype)\n",
    "TY_ = T.vector(\"TY_\",dtype=dtype)\n",
    "quadrature_moments_parallel_theano = Tfun(\n",
    "    inp = [TMQ,TVQ,TS_,TY_],\n",
    "    out = quadrature_moments_parallel_theano_source(TMQ,TVQ,TS_,TY_))\n",
    "\n",
    "def surrogate_likelihood_parallel_theano_source(LM,LT,MP,TP):\n",
    "    VR = Tsinv(TP-LT)\n",
    "    MR = (MP*TP-LM*LT)*VR\n",
    "    return MR,VR\n",
    "TLM = T.vector(\"TLM\",dtype=dtype)\n",
    "TLT = T.vector(\"TLT\",dtype=dtype)\n",
    "TMP = T.vector(\"TMP\",dtype=dtype)\n",
    "TTP = T.vector(\"TTP\",dtype=dtype)\n",
    "surrogate_likelihood_parallel_theano = Tfun(\n",
    "    inp = [TLM,TLT,TMP,TTP],\n",
    "    out = surrogate_likelihood_parallel_theano_source(TLM,TLT,TMP,TTP))\n",
    "\n",
    "def conditional_gaussian_parallel_theano_source(M1,M2,MR,VR,LM,LV):\n",
    "    M2B = M2.dot(Tbeta) # NxKx1\n",
    "    KG  = M2B/(VR+LV)[:,None,None] #NxKx1\n",
    "    M2 -= T.batched_dot(KG,M2B.transpose(0,2,1))\n",
    "    M1 += KG*(MR-LM)[:,None,None]\n",
    "    return M1,M2\n",
    "TMR = T.vector(\"TLM\",dtype=dtype)\n",
    "TVR = T.vector(\"TLT\",dtype=dtype)\n",
    "TLV = T.vector(\"TLV\",dtype=dtype)\n",
    "conditional_gaussian_parallel_theano = Tfun(\n",
    "    inp = [TallM1,TallM2,TMR,TVR,TLM,TLV],\n",
    "    out = conditional_gaussian_parallel_theano_source(TallM1,TallM2,TMR,TVR,TLM,TLV))\n",
    "\n",
    "def loglikelihood_parallel_theano_source(M1,M2,S,LM,LV,MP,VP):\n",
    "    _,_,LR,_,_ = project_moments_parallel_theano_source(M1,M2,S)\n",
    "    LOGPYX     = Y_*LR-Tsexp(LR)\n",
    "    LL         = LOGPYX - 0.5*(Tslog(LV/VP) + (MP-LM)**2.0/LV)\n",
    "    return LL\n",
    "TVP = T.vector(\"TVP\",dtype=dtype)\n",
    "loglikelihood_parallel_theano = Tfun(\n",
    "    inp = [TallM1,TallM2,TS_,TLM,TLV,TMP,TVP],\n",
    "    out = loglikelihood_parallel_theano_source(TallM1,TallM2,TS_,TLM,TLV,TMP,TVP))\n",
    "\n",
    "def measurement_update_parallel_theano_source(M1,M2,S,Y):\n",
    "    LV,LM,_,_,_ = project_moments_parallel_theano_source(M1,M2,S)\n",
    "    LT    = Tsinv(LV)\n",
    "    MQ,VQ = univariate_prior_parallel_theano_source(LM,LT)\n",
    "    MP,VP = quadrature_moments_parallel_theano_source(MQ,VQ,S,Y)\n",
    "    TP    = Tsinv(VP)\n",
    "    MR,VR = surrogate_likelihood_parallel_theano_source(LM,LT,MP,TP)\n",
    "    M1,M2 = conditional_gaussian_parallel_theano_source(M1,M2,MR,VR,LM,LV)\n",
    "    LL    = loglikelihood_parallel_theano_source(M1,M2,S,LM,LV,MP,VP)\n",
    "    return M1,M2,LL\n",
    "measurement_update_parallel_theano = Tfun(\n",
    "    inp = [TallM1,TallM2,TS_,TY_],\n",
    "    out = measurement_update_parallel_theano_source(TallM1,TallM2,TS_,TY_))\n",
    "\n",
    "def integrate_dt_parallel_theano_source(M1,M2,S):\n",
    "    for k in range(oversample):\n",
    "        M1,M2 = integrate_moments_parallel_theano_source(M1,M2,S)\n",
    "    return M1,M2\n",
    "integrate_dt_parallel_theano = Tfun(\n",
    "    inp = [TallM1,TallM2,TS_],\n",
    "    out = integrate_dt_parallel_theano_source(TallM1,TallM2,TS_))\n",
    "\n",
    "def filter_moments_parallel_theano_source(di,M1,M2,S,Y):\n",
    "    if reg_cov>0.0:\n",
    "        M2 = 0.5*(M2 + M2.transpose(0,2,1)) + Tcast(allRC)\n",
    "    offsets = Tmx(0.0,T.arange(N)+di)\n",
    "    offsets = T.cast(offsets,'int32')\n",
    "    S = S[offsets]\n",
    "    Y = Y[offsets]\n",
    "    M1,M2    = integrate_dt_parallel_theano_source(M1,M2,S)\n",
    "    M1,M2,LL = measurement_update_parallel_theano_source(M1,M2,S,Y)\n",
    "    return M1,M2,LL\n",
    "Tdi = T.scalar(\"Tdi\",dtype=dtype)\n",
    "filter_moments_parallel_theano = Tfun(\n",
    "    inp = [Tdi,TallM1,TallM2,TS_,TY_],\n",
    "    out = filter_moments_parallel_theano_source(Tdi,TallM1,TallM2,TS_,TY_))\n",
    "\n",
    "# Depth D Loop\n",
    "[_M1,_M2,_LL], up = theano.scan(filter_moments_parallel_theano_source,\n",
    "                                sequences     = [Tcon(arange(1-D,1))],\n",
    "                                outputs_info  = [Tcon(iniM1),Tcon(iniM2),None],\n",
    "                                non_sequences = [TS_,TY_],\n",
    "                                n_steps       = D,\n",
    "                                name          = 'scan_moments_parallel_theano')\n",
    "#\n",
    "ALLM1,ALLM2 = _M1[-1],_M2[-1]\n",
    "ALLLV,_,ALLLR,_,_ = project_moments_parallel_theano_source(ALLM1,ALLM2,TS_)\n",
    "scan_moments_parallel_theano = Tfun(\\\n",
    "    inp = [TS_,TY_],\n",
    "    out = [ALLLR,ALLLV,ALLM1,ALLM2,-T.mean(_LL[-1])],\n",
    "    upd = up)\n",
    "                                                 \n",
    "##########################################\n",
    "\n",
    "tic()\n",
    "allLR,allLV,allM1,allM2,NLL = scan_moments_parallel_theano(S,Y)\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,NLL)\n",
    "ylim(max(ylim()[0],-100),5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy integrator broken down into functions for easier conversion to theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "S = stim\n",
    "Y = Y_train\n",
    "\n",
    "allLR = np.zeros(N)\n",
    "allLV = np.zeros(N)\n",
    "allM1 = np.zeros((N,K,1))\n",
    "allM2 = np.zeros((N,K,K))\n",
    "allRC = np.zeros((N,K,K))\n",
    "for i in range(N):\n",
    "    allRC[i,...]=reg_cov*np.eye(K)\n",
    "allM1[...] = iniM1\n",
    "allM2[...] = iniM2\n",
    "\n",
    "########################################################\n",
    "# Numpy\n",
    "\n",
    "def project_moments_parallel(allM1,allM2,S_):\n",
    "    LOGV   = allM2.dot(beta[:,0]).dot(beta[:,0])\n",
    "    LOGM   = allM1[:,:,0].dot(beta[:,0])\n",
    "    LOGX   = np.minimum(maxlogr,LOGM+S_)\n",
    "    R0_    = np.minimum(maxrate,sexp(LOGX))*dtfine # N \n",
    "    RM     = R0_ * np.minimum(1+0.5*LOGV,maxvcorr) # N\n",
    "    return LOGV,LOGM,LOGX,R0_,RM\n",
    "\n",
    "def euler_update_moments_parallel(allM1,allM2,R0,RM):\n",
    "    allM1 += np.matmul(Adt,allM1)\n",
    "    allM1 += C [None,:,:]*RM[:,None,None]\n",
    "    J_     = Cb[None,:,:]*R0[:,None,None]+Adt[None,:,:]\n",
    "    JM2_   = np.matmul(J_,allM2)\n",
    "    allM2 += JM2_ + JM2_.transpose((0,2,1))\n",
    "    allM2 += CC[None,:,:]*RM[:,None,None]\n",
    "    return allM1,allM2\n",
    "\n",
    "def integrate_moments_parallel(allM1,allM2,S_):\n",
    "    LOGV,LOGM,LOGX,R0,RM = project_moments_parallel(allM1,allM2,S_)\n",
    "    allM1,allM2 = euler_update_moments_parallel(allM1,allM2,R0,RM)\n",
    "    return allM1,allM2\n",
    "\n",
    "def integrate_dt_parallel(allM1,allM2,S_):\n",
    "    for k in range(oversample):\n",
    "        allM1,allM2 = integrate_moments_parallel(allM1,allM2,S_)\n",
    "    return allM1,allM2\n",
    "\n",
    "def quadrature_moments_parallel(MQ,VQ,S_,Y_):\n",
    "    intr = np.linspace(-4,4,25)\n",
    "    X_ = intr[None,:]*np.sqrt(VQ)[:,None]+MQ[:,None]\n",
    "    R0_ = X_ + S_[:,None]+slog(dt)\n",
    "    L = Y_[:,None]*R0_-sexp(R0_)\n",
    "    L = L - np.max(L,axis=1)[:,None]\n",
    "    L += -.5*((intr**2)[None,:]+slog(VQ)[:,None])\n",
    "    PR = np.maximum(1e-7,sexp(L))\n",
    "    NR = 1/np.sum(PR,axis=1)\n",
    "    MP = np.sum(X_*PR,axis=1)*NR\n",
    "    VP = np.sum((X_-MP[:,None])**2*PR,axis=1)*NR\n",
    "    return MP,VP\n",
    "\n",
    "def univariate_prior_parallel(LM,LT):\n",
    "    TQ = LT + reg_rate\n",
    "    VQ = 1/TQ\n",
    "    MQ = (LM*LT+m*reg_rate)*VQ\n",
    "    return MQ,VQ\n",
    "\n",
    "def surrogate_likelihood_parallel(LM,LT,MP,TP):\n",
    "    VR = 1/np.maximum(1e-12,TP-LT)\n",
    "    MR = (MP*TP-LM*LT)*VR\n",
    "    return MR,VR\n",
    "\n",
    "def conditional_gaussian_parallel(allM1,allM2,MR,VR,LM,LV):\n",
    "    M2B_ = np.matmul(allM2,beta)\n",
    "    KG = M2B_/(VR+LV)[:,None,None]\n",
    "    allM2 -= np.matmul(KG,M2B_.transpose(0,2,1))\n",
    "    allM1 += KG*(MR-LM)[:,None,None]\n",
    "    return allM1,allM2\n",
    "\n",
    "def loglikelihood_parallel(allM1,allM2,S_,LM,LV,MP,VP):\n",
    "    _,_,LR,_,_ = project_moments_parallel(allM1,allM2,S_)\n",
    "    LOGPYX     = Y_*LR-sexp(LR)\n",
    "    LL         = LOGPYX - 0.5*(slog(LV/VP) + (MP-LM)**2/LV)\n",
    "    return LL\n",
    "\n",
    "def measurement_update_parallel(allM1,allM2,S_,Y_):\n",
    "    LV,LM,_,_,_ = project_moments_parallel_theano(allM1,allM2,S_)\n",
    "    LT          = 1/np.maximum(1e-12,LV)\n",
    "    MQ,VQ       = univariate_prior_parallel_theano(LM,LT)\n",
    "    MP,VP       = quadrature_moments_parallel(MQ,VQ,S_,Y_)\n",
    "    TP          = 1/np.maximum(1e-12,VP)\n",
    "    MR,VR       = surrogate_likelihood_parallel_theano(LM,LT,MP,TP)\n",
    "    allM1,allM2 = conditional_gaussian_parallel_theano(allM1,allM2,MR,VR,LM,LV)\n",
    "    LL          = loglikelihood_parallel_theano(allM1,allM2,S_,LM,LV,MP,VP)\n",
    "    return allM1,allM2,LL\n",
    "\n",
    "def filter_moments_parallel(di,allM1,allM2,S,Y):\n",
    "    # Reset values that really shouldn't be being integrated? \n",
    "    allM1[:-di,...]=iniM1[:-di,...]\n",
    "    allM2[:-di,...]=iniM2[:-di,...]\n",
    "    # Regularize\n",
    "    if reg_cov>0:\n",
    "        allM2 = 0.5*(allM2 + allM2.transpose(0,2,1)) + allRC\n",
    "    offsets = np.maximum(0,np.arange(N)+di)\n",
    "    S = S[offsets]\n",
    "    Y = Y[offsets]\n",
    "    allM1,allM2 = integrate_dt_parallel_theano(allM1,allM2,S)\n",
    "    allM1,allM2,LL = measurement_update_parallel_theano(allM1,allM2,S,Y)\n",
    "    return allM1,allM2,LL\n",
    "\n",
    "def scan_moments_parallel():\n",
    "    allM1 = iniM1.copy()\n",
    "    allM2 = iniM2.copy()\n",
    "    for di in range(-D+1,1):\n",
    "        allM1,allM2,LL = filter_moments_parallel(di,allM1,allM2,S,Y)\n",
    "    allLV = allM2.dot(beta[:,0]).dot(beta[:,0])\n",
    "    allLR = np.minimum(maxlogr,allM1[:,:,0].dot(beta[:,0])+S)\n",
    "    return allLR,allLV,allM1,allM2,-mean(LL)\n",
    "\n",
    "tic()\n",
    "allLR,allLV,allM1,allM2,NLL = scan_moments_parallel()\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,-mean(LL))\n",
    "ylim(max(ylim()[0],-100),5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorganize Theano implementation\n",
    "\n",
    "Separate functions are great for debugging, but let's clean things up a bit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "S = stim\n",
    "Y = Y_train\n",
    "\n",
    "TAdt  = Tcon(Adt)\n",
    "Tbeta = Tcon(beta)\n",
    "Tb    = Tcon(p.ravel()[1:K+1])\n",
    "TC    = Tcon(C ).dimshuffle('x',0,1)\n",
    "TCb   = Tcon(Cb).dimshuffle('x',0,1)\n",
    "TCC   = Tcon(CC).dimshuffle('x',0,1)\n",
    "\n",
    "mxl = Tcon(maxlogr)\n",
    "mxr = Tcon(maxrate)\n",
    "dtf = Tcon(dtfine)\n",
    "xvc = Tcon(maxvcorr)\n",
    "rr  = Tcon(reg_rate)\n",
    "mm  = Tcon(m)\n",
    "\n",
    "TM1 = T.tensor3(\"TM1\",dtype=dtype)\n",
    "TM2 = T.tensor3(\"TM2\",dtype=dtype)\n",
    "\n",
    "def integrate_moments_parallel_theano_source(M1,M2,S):\n",
    "    LOGV = M2.dot(Tb).dot(Tb) # N\n",
    "    LOGM = M1[:,:,0].dot(Tb)  # N\n",
    "    LOGX = Tmn(mxl,LOGM+S) # N\n",
    "    R0   = Tmn(mxr,Tsexp(LOGX))*dtf # N \n",
    "    RM   = R0 * Tmn(1.0+0.5*LOGV,xvc) # N\n",
    "    J    = TCb*R0[:,None,None]+TAdt[None,:,:]\n",
    "    JM2  = T.batched_dot(J,M2)\n",
    "    M2  += JM2 + JM2.transpose(0,2,1)    + TCC*RM[:,None,None]\n",
    "    M1  += TAdt.dot(M1).transpose(1,0,2) + TC *RM[:,None,None]\n",
    "    return M1,M2\n",
    "\n",
    "Tintr = Tcon(np.linspace(-4,4,25))\n",
    "def measurement_update_parallel_theano_source(M1,M2,S_,Y_):\n",
    "    LV = M2.dot(Tb).dot(Tb) # N\n",
    "    LM = M1[:,:,0].dot(Tb)  # N\n",
    "    LT = Tsinv(LV)\n",
    "    TQ = LT + rr\n",
    "    VQ = Tsinv(TQ)\n",
    "    MQ = (LM*LT+mm*rr)*VQ\n",
    "    X_ = Tintr[None,:]*T.sqrt(VQ)[:,None]+MQ[:,None]\n",
    "    R0 = X_ + S_[:,None]+Tslog(dt)\n",
    "    L  = Y_[:,None]*R0-Tsexp(R0)\n",
    "    L  = L - T.max(L,axis=1)[:,None]\n",
    "    L += -0.5*((Tintr**2.0)[None,:]+Tslog(VQ)[:,None])\n",
    "    PR = Tmx(1e-7,Tsexp(L))\n",
    "    NR = Tsinv(T.sum(PR,axis=1))\n",
    "    MP = T.sum(X_*PR,axis=1)*NR\n",
    "    VP = T.sum((X_-MP[:,None])**2*PR,axis=1)*NR\n",
    "    TP = Tsinv(VP)\n",
    "    VR = Tsinv(TP-LT)\n",
    "    MR = (MP*TP-LM*LT)*VR\n",
    "    # Multivariate conditional update\n",
    "    M2B_  = M2.dot(Tbeta) # NxKx1\n",
    "    KG    = M2B_/(VR+LV)[:,None,None] #NxKx1\n",
    "    M2   -= T.batched_dot(KG,M2B_.transpose(0,2,1))\n",
    "    M1   += KG*(MR-LM)[:,None,None]\n",
    "    LR    = Tmn(mxl,M1[:,:,0].dot(Tb)+S_) # N\n",
    "    LOGPYX= Y_*LR-Tsexp(LR)\n",
    "    LL    = LOGPYX - 0.5*(Tslog(LV/VP) + (MP-LM)**2.0/LV)\n",
    "    return M1,M2,-T.mean(LL)\n",
    "\n",
    "def filter_moments_parallel_theano_source(di,M1,M2,S_,Y_):\n",
    "    if reg_cov>0:\n",
    "        M2 = 0.5*(M2 + M2.transpose(0,2,1)) + Tcast(allRC)\n",
    "    offsets = T.maximum(0,T.arange(N)+di)\n",
    "    offsets = T.cast(offsets,'int32')\n",
    "    S_ = S_[offsets]\n",
    "    Y_ = Y_[offsets]\n",
    "    for k in range(oversample):\n",
    "        M1,M2 = integrate_moments_parallel_theano_source(M1,M2,S_)\n",
    "    M1,M2,NLL = measurement_update_parallel_theano_source(M1,M2,S_,Y_)\n",
    "    return M1,M2,NLL\n",
    "Tdi = T.scalar(\"Tdi\",dtype=dtype)\n",
    "filter_moments_parallel_theano = Tfun(\n",
    "    inp = [Tdi,TM1,TM2,TS_,TY_],\n",
    "    out = filter_moments_parallel_theano_source(Tdi,TM1,TM2,TS_,TY_))\n",
    "\n",
    "# Depth D Loop\n",
    "[_M1,_M2,_NLL], up = theano.scan(filter_moments_parallel_theano_source,\n",
    "                                sequences     = [Tcon(arange(1-D,1))],\n",
    "                                outputs_info  = [Tcon(iniM1),Tcon(iniM2),None],\n",
    "                                non_sequences = [TS_,TY_],\n",
    "                                n_steps       = D,\n",
    "                                name          = 'scan_moments_parallel_theano')\n",
    "#\n",
    "M1,M2 = _M1[-1],_M2[-1]\n",
    "ALLLV = M2.dot(Tb).dot(Tb) # N\n",
    "ALLLR = T.minimum(maxlogr,M1[:,:,0].dot(Tb)+TS_) # N\n",
    "\n",
    "scan_moments_parallel_theano = Tfun(\\\n",
    "    inp = [TS_,TY_],\n",
    "    out = [ALLLR,ALLLV,M1,M2,_NLL[-1]],\n",
    "    upd = up)\n",
    "                                                 \n",
    "##########################################\n",
    "\n",
    "tic()\n",
    "allLR,allLV,M1,M2,NLL = scan_moments_parallel_theano(S,Y)\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,NLL)\n",
    "ylim(max(ylim()[0],-100),5) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
