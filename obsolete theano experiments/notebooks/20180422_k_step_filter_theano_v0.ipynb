{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import absolute_import\n",
    "from __future__ import with_statement\n",
    "from __future__ import division\n",
    "from __future__ import nested_scopes\n",
    "from __future__ import generators\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "\n",
    "# Load scipy/numpy/matplotlib\n",
    "from   scipy.linalg import expm\n",
    "import matplotlib.pyplot as plt\n",
    "from   pylab import *\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from warnings import warn\n",
    "\n",
    "# Configure figure resolution\n",
    "plt.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "plt.rcParams['savefig.dpi'   ] = 100\n",
    "\n",
    "from izh       import * # Routines for sampling Izhikevich neurons\n",
    "from plot      import * # Misc. plotting routines\n",
    "from glm       import * # GLM fitting\n",
    "from arppglm   import * # Sampling and integration\n",
    "from utilities import * # Other utilities\n",
    "from arguments import * # Argument verification\n",
    "\n",
    "'''\n",
    "import os\n",
    "dtype='float64'\n",
    "flags = 'mode=FAST_RUN,device=gpu,floatX=%s'%dtype\n",
    "if dtype!='float64':\n",
    "    flags += ',warn_float64=warn'\n",
    "os.environ[\"THEANO_FLAGS\"] = flags\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "'''\n",
    "\n",
    "import os\n",
    "dtype='float32'\n",
    "os.environ['MKL_THREADING_LAYER']='GNU'\n",
    "flags = 'mode=FAST_COMPILE,device=cuda0,'#,floatX=%s'%dtype\n",
    "#if dtype!='float64':\n",
    "#     flags += ',warn_float64=warn'\n",
    "os.environ[\"THEANO_FLAGS\"] = flags\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from theano_arppglm import *\n",
    "\n",
    "print('Workspace Initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved GLM features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#filename = 'saved_training_model.mat'\n",
    "filename = 'saved_training_model_badburster.mat'\n",
    "\n",
    "saved_training_model = scipy.io.loadmat(filename)\n",
    "K  = np.array(saved_training_model['K'],dtype=dtype)\n",
    "B  = np.array(saved_training_model['B'],dtype=dtype)\n",
    "By = np.array(saved_training_model['By'],dtype=dtype)\n",
    "Bh = np.array(saved_training_model['Bh'],dtype=dtype)\n",
    "A  = np.array(saved_training_model['A'],dtype=dtype)\n",
    "C  = np.array(saved_training_model['C'],dtype=dtype)\n",
    "Y  = np.array(saved_training_model['Y'],dtype=dtype)\n",
    "dt = np.array(saved_training_model['dt'],dtype=dtype)\n",
    "\n",
    "Bh_train = saved_training_model['Bh_train']\n",
    "By_train = saved_training_model['By_train']\n",
    "X_train  = concatenate([By_train,Bh_train],axis=1)\n",
    "Y_train  = asvector(saved_training_model['Y_train'])\n",
    "\n",
    "Bh_test  = saved_training_model['Bh_test']\n",
    "By_test  = saved_training_model['By_test']\n",
    "X_test   = concatenate([By_test,Bh_test],axis=1)\n",
    "Y_test   = asvector(saved_training_model['Y_test'])\n",
    " \n",
    "K  = int(scalar(K))\n",
    "N  = prod(Y.shape)\n",
    "\n",
    "N = len(X_train)\n",
    "STARTPLOT=0\n",
    "NPLOT=N\n",
    "\n",
    "print('Saved GLM features loaded')\n",
    "print(N)\n",
    "\n",
    "#STARTSHOW = 14000\n",
    "#STOPSHOW = 16000\n",
    "STARTSHOW = 0\n",
    "STOPSHOW = N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLM helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def lograte(Bh,By,p):\n",
    "    '''\n",
    "    Log-intensity of point process model on this dataset\n",
    "    Predicted using the standard GLM way\n",
    "    '''\n",
    "    m       = array(p).ravel()[0]\n",
    "    beta    = ascolumn(p[1:K+1])\n",
    "    beta_st = ascolumn(p[1+K:])\n",
    "    lograte = m + Bh.dot(beta_st) + By.dot(beta)\n",
    "    return lograte\n",
    "\n",
    "def logmean(Bh,M1,p):\n",
    "    '''\n",
    "    Projected history process\n",
    "    Predicted using history-process means\n",
    "    '''\n",
    "    m       = array(p).ravel()[0]\n",
    "    beta    = ascolumn(p[1:K+1])\n",
    "    beta_st = ascolumn(p[1+K:])\n",
    "    M1      = np.squeeze(M1)\n",
    "    return (beta.T.dot(M1.T))[0] + (m + Bh.dot(beta_st))[:,0]\n",
    "\n",
    "def get_stim(Bh,p):\n",
    "    m        = array(p).ravel()[0]\n",
    "    beta     = ascolumn(p[1:K+1])\n",
    "    beta_st  = ascolumn(p[1+K:])\n",
    "    stim     = (m + Bh.dot(beta_st))[:,0]\n",
    "    return stim\n",
    "\n",
    "def filter_GLM_np(Bh,p):\n",
    "    m        = array(p).ravel()[0]\n",
    "    beta     = ascolumn(p[1:K+1])\n",
    "    beta_st  = ascolumn(p[1+K:])\n",
    "    stim     = get_stim(Bh,p)\n",
    "    allM1_np = np.zeros((N,K))\n",
    "    M1       = np.zeros((K,1))\n",
    "    for i in range(N):\n",
    "        R   = scalar(sexp(p0[1:K+1].dot(M1)+m+stim[i]))\n",
    "        M1 += A.dot(M1)*dt + C.dot(R)\n",
    "        allM1_np[i] = M1[:,0]\n",
    "    return allM1_np\n",
    "\n",
    "def addspikes_(Y_=None):\n",
    "    if Y_ is None or Y_ is True:\n",
    "        Y_ = Y\n",
    "    for t in find(Y_>0):\n",
    "        axvline(t,color=OCHRE,lw=0.4)\n",
    "    \n",
    "def niceaxis(plotspikes=True):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\",message='No labelled objects found')\n",
    "        legend()\n",
    "    simpleraxis()\n",
    "    xlim(STARTSHOW,STOPSHOW)\n",
    "    if plotspikes is True or not plotspikes is None:\n",
    "        addspikes_(plotspikes)\n",
    "\n",
    "print('GLM helpers done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# Re-fit GLM\n",
    "m,bhat  = fitGLM(X_train,asvector(Y_train))\n",
    "\n",
    "# Re-pack model parameters\n",
    "p0      = np.zeros((1+len(bhat)))\n",
    "p0[0 ]  = m\n",
    "p0[1:]  = bhat\n",
    "\n",
    "allM1_np = filter_GLM_np(Bh_train,p0)\n",
    "subplot(311)\n",
    "plot(lograte(Bh_train,By_train,p0),lw=0.4,label='conditional intensity')\n",
    "plot(logmean(Bh_train,allM1_np,p0),lw=0.4,label='mean-field',color=RUST)\n",
    "niceaxis()\n",
    "ylim(min(lograte(Bh_train,By_train,p0)),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters at which to filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "oversample = 10   # Integration resolution\n",
    "maxrate    = 10.0 # Largest allowed rate\n",
    "maxvcorr   = 10.0 # Largest allowed variance correction\n",
    "dt         = 1.0  # Data time resolution\n",
    "reg_cov    = 1e-5\n",
    "reg_rate   = 1e-5\n",
    "\n",
    "p = p0.copy()\n",
    "#p[1:K+1] *= 0.775\n",
    "stim_np = get_stim(Bh_train,p)\n",
    "beta_np = ascolumn(p[1:K+1])\n",
    "print('Filtering using p=',v2str(p))\n",
    "\n",
    "# Helper function to compute negative expected log-likelihood\n",
    "def post_hoc_nll(LR,LV):\n",
    "    R0 = sexp(LR)\n",
    "    R1 = R0*(1+0.5*LV)\n",
    "    ELL  = np.mean(Y*LR - R1)\n",
    "    return -ELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "### Build Theano routines\n",
    "\n",
    "For integrating moments (not conditioned on data), filtering (conditioned on data), and filtering using surrogate likelihoods (Gaussian approximations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from theano_arppglm import *\n",
    "\n",
    "GLM_log_intensity, GLMNLL_f, GLMNLL_g, GLMNLL_h = build_ML_GLM_likelihood_theano()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "integrate_moments_theano, EMNLL_filt, EMNLL_grad = build_integrate_moments_theano(N,A,C,\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "filter_moments_theano, NLL_filt, NLL_grad = build_filter_moments_theano(N,A,C,\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    return_surrogates = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "filter_surrogate_theano, SNLL_filt, SNLL_grad = build_filter_moments_theano(N,A,C,\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    return_surrogates = False,\n",
    "    use_surrogates    = True)\n",
    "\n",
    "print('Theano functions bulit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate Without measurements.\n",
    "\n",
    "We will use the integrated moments (without measurements) as a prior distribution for our K-step prediction with measurement updates.\n",
    "\n",
    "Update: we now use the actual filtered states, to verify that shallow filtering is equivalent to deep filtering if provided appropriate initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "p = p0.copy()\n",
    "#p[1:]*=3\n",
    "\n",
    "m        = array(p).ravel()[0]\n",
    "beta     = ascolumn(p[1:K+1])\n",
    "beta_st  = ascolumn(p[1+K:])\n",
    "stim     = (m + Bh_train.dot(beta_st))[:,0]\n",
    "stim_np  = stim\n",
    "beta_np  = ascolumn(p[1:K+1])\n",
    "\n",
    "print('Filtering using p=',v2str(p))\n",
    "\n",
    "tic()\n",
    "allLRni,allLVni,allM1ni,allM2ni = integrate_moments(stim_np,A,beta_np,C,\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\")\n",
    "toc()\n",
    "subplot(411)\n",
    "stderrplot(allLRni,allLVni,color=BLACK,lw=0.5)\n",
    "niceaxis()\n",
    "xlim(STARTSHOW,STOPSHOW)\n",
    "title('Integrating, numpy')\n",
    "\n",
    "tic()\n",
    "allLRti,allLVti,allM1ti,allM2ti = integrate_moments_theano(Bh_train,p)\n",
    "toc()\n",
    "subplot(412)\n",
    "stderrplot(allLRti,allLVti,color=BLACK,lw=0.5)\n",
    "niceaxis()\n",
    "xlim(STARTSHOW,STOPSHOW)\n",
    "title('Integrating, theano')\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Deep\" filtering in Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "tic()\n",
    "allLRn,allLVn,allM1n,allM2n,nlln,mrn,vrn = filter_moments(stim,Y_train,A,beta,C,p[0],\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    return_surrogates = True)\n",
    "toc()\n",
    "subplot(411)\n",
    "stderrplot(allLRn,allLVn,color=BLACK,lw=0.5)\n",
    "niceaxis()\n",
    "xlim(STARTSHOW,STOPSHOW)\n",
    "title('Filtering, numpy')\n",
    "print('nll, numpy',nlln)\n",
    "\n",
    "tic()\n",
    "allLRt,allLVt,allM1t,allM2t,nllt,mrt,vrt = filter_moments_theano(Bh_train,Y_train,p)\n",
    "toc()\n",
    "subplot(412)\n",
    "stderrplot(allLRt,allLVt,color=BLACK,lw=0.5)\n",
    "niceaxis()\n",
    "xlim(STARTSHOW,STOPSHOW)\n",
    "title('Filtering, theano')\n",
    "print('nll, theano',nllt)\n",
    "\n",
    "subplot(413)\n",
    "plot(allLRn,color=BLACK,label='log-λ numpy')\n",
    "plot(allLRt,':',color=RUST,label='log-λ theano')\n",
    "niceaxis()\n",
    "xlim(STARTSHOW,STOPSHOW)\n",
    "\n",
    "priorLR,priorLV,priorM1,priorM2 = allLRt,allLVt,allM1t,allM2t\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First: let us see if we can get \"parallel\" moment integration (no measurements). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "## Start with naive implementation for reference\n",
    "\n",
    "Demonstrate shallow depth-5 filtering. Even starting from a prior with no inforamation about the filtered state, these results can be relatively accurate. This could lead to parallel filtering routines to accelerate inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from arppglm import filter_moments\n",
    "\n",
    "D  = 15\n",
    "ND = N-D\n",
    "\n",
    "# Precompute constants\n",
    "maxlogr   = np.log(maxrate)\n",
    "maxratemc = maxvcorr*maxrate\n",
    "dtfine    = dt/oversample\n",
    "Cb        = C.dot(beta.T)\n",
    "CC        = C.dot(C.T)\n",
    "Adt       = A*dtfine\n",
    "\n",
    "themeasurement = 'moment'\n",
    "int_method = 'euler'\n",
    "method = 'second_order'\n",
    "\n",
    "# Get measurement update function\n",
    "measurement = get_measurement(themeasurement)\n",
    "# Buid moment integrator functions\n",
    "mean_update, cov_update = get_moment_integrator(int_method,Adt)\n",
    "# Get update function (computes expected rate from moments)\n",
    "update = get_update_function(method,Cb,Adt,maxvcorr)\n",
    "\n",
    "allLR = np.zeros(N)\n",
    "allLV = np.zeros(N)\n",
    "\n",
    "tic()\n",
    "for i in range(N):\n",
    "    b = i+1\n",
    "    a = i-D+1\n",
    "    c = a-1\n",
    "    ini = (priorM1[c],priorM2[c]) if c>=0 else None\n",
    "    a = max(0,a)\n",
    "    c = max(0,a-1)\n",
    "    lr,lv,_,_,_,_,_ = filter_moments(stim[a:b],Y_train[a:b],A,beta,C,p[0],\n",
    "        dt          = dt,\n",
    "        oversample  = oversample,\n",
    "        maxrate     = maxrate,\n",
    "        maxvcorr    = maxvcorr,\n",
    "        method      = \"second_order\",\n",
    "        int_method  = \"euler\",\n",
    "        measurement = \"moment\",\n",
    "        reg_cov     = reg_cov,\n",
    "        reg_rate    = reg_rate,\n",
    "        return_surrogates = True,\n",
    "        initial_conditions = ini)\n",
    "    allLR[i] = lr[-1]\n",
    "    allLV[i] = lv[-1]\n",
    "toc()\n",
    "\n",
    "assert(all(isfinite(allLR)))\n",
    "assert(all(isfinite(allLV)))\n",
    "\n",
    "allLRref,allLVref = allLR,allLV\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRn,allLVn,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "ylim(max(ylim()[0],-100),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare prior for \"shallow\" filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tic()\n",
    "allLRt,allLVt,allM1t,allM2t,nllt,mrt,vrt = filter_moments_theano(Bh_train,Y_train,p)\n",
    "toc()\n",
    "\n",
    "priorLR,priorLV,priorM1,priorM2 = allLRt,allLVt,allM1t,allM2t\n",
    "defaultM1 = np.zeros((K,1))\n",
    "defaultM2 = np.eye(K)*1e-6\n",
    "\n",
    "iniM1 = np.zeros((N,K,1))\n",
    "iniM2 = np.zeros((N,K,K))\n",
    "iniM1[:D-1]=defaultM1\n",
    "iniM2[:D-1]=defaultM2\n",
    "iniM1[D-1:]=priorM1[:-D+1]\n",
    "iniM2[D-1:]=priorM2[:-D+1]\n",
    "\n",
    "print('Prior done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compartamentalize in function\n",
    "\n",
    "Note that parallel shallow filtering is still slower than running the full forward pass, as we must perform O(D*N) work as opposed to O(N). However, this will admits a depth-D algorithm in theano which may give us some improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "tic()\n",
    "allLRn,allLVn,allM1n,allM2n,nlln,mrn,vrn = filter_moments(stim,Y_train,A,beta,C,p[0],\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    return_surrogates = True)\n",
    "toc()\n",
    "\n",
    "from dstep import filter_moments_dstep\n",
    "\n",
    "tic()\n",
    "allLRt,allLVt,allM1t,allM2t,nllt,mrt,vrt = filter_moments_theano(Bh_train,Y_train,p)\n",
    "toc()\n",
    "\n",
    "priorLR,priorLV,priorM1,priorM2 = allLRt,allLVt,allM1t,allM2t\n",
    "defaultM1 = np.zeros((K,1))\n",
    "defaultM2 = np.eye(K)*1e-6\n",
    "\n",
    "iniM1 = np.zeros((N,K,1))\n",
    "iniM2 = np.zeros((N,K,K))\n",
    "iniM1[:D]=defaultM1\n",
    "iniM2[:D]=defaultM2\n",
    "iniM1[D:]=priorM1[:-D]\n",
    "iniM2[D:]=priorM2[:-D]\n",
    "\n",
    "\n",
    "tic()\n",
    "allLRnd,allLVnd,allM1nd,allM2nd,nllnd = filter_moments_dstep(D,stim,Y_train,A,beta,C,p[0],\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    prior       = (iniM1,iniM2))\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLRnd,allLVnd,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "ylim(max(ylim()[0],-100),5)\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,nllnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano implementation\n",
    "\n",
    "Separate functions are great for debugging, but let's clean things up a bit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "tic()\n",
    "allLRt,allLVt,allM1t,allM2t,nllt,mrt,vrt = filter_moments_theano(Bh_train,Y_train,p)\n",
    "toc()\n",
    "\n",
    "priorLR,priorLV,priorM1,priorM2 = allLRt,allLVt,allM1t,allM2t\n",
    "defaultM1 = np.zeros((K,1))\n",
    "defaultM2 = np.eye(K)*1e-6\n",
    "\n",
    "iniM1 = np.zeros((N,K,1))\n",
    "iniM2 = np.zeros((N,K,K))\n",
    "iniM1[:D]=defaultM1\n",
    "iniM2[:D]=defaultM2\n",
    "iniM1[D:]=priorM1[:-D]\n",
    "iniM2[D:]=priorM2[:-D]\n",
    "\n",
    "subplot(411)\n",
    "stderrplot(allLRt,allLVt,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "\n",
    "allRC = np.zeros((N,K,K))\n",
    "for i in range(N):\n",
    "    allRC[i] = np.eye(K)\n",
    "    \n",
    "print('Prior set for Theano implementations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano implementation: expanded version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m        = array(p).ravel()[0]\n",
    "beta     = ascolumn(p[1:K+1])\n",
    "beta_st  = ascolumn(p[1+K:])\n",
    "stim     = (m + Bh_train.dot(beta_st))[:,0]\n",
    "stim_np  = stim\n",
    "beta_np  = ascolumn(p[1:K+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = stim\n",
    "Y = Y_train\n",
    "\n",
    "allRC = np.zeros((N,K,K))\n",
    "for i in range(N):\n",
    "    allRC[i,...]=reg_cov*np.eye(K)*reg_cov\n",
    "TRC = Tcast(allRC)\n",
    "\n",
    "TAdt  = Tcon(Adt)\n",
    "Tbeta = Tcon(beta)\n",
    "Tb    = Tcon(p.ravel()[1:K+1])\n",
    "TC    = Tcon(C ).dimshuffle('x',0,1)\n",
    "TCb   = Tcon(Cb).dimshuffle('x',0,1)\n",
    "TCC   = Tcon(CC).dimshuffle('x',0,1)\n",
    "\n",
    "mxl = Tcon(maxlogr)\n",
    "mxr = Tcon(maxrate)\n",
    "dtf = Tcon(dtfine)\n",
    "xvc = Tcon(maxvcorr)\n",
    "rr  = Tcon(reg_rate)\n",
    "mm  = Tcon(m)\n",
    "\n",
    "def project_moments_parallel_theano_source(M1,M2,S):\n",
    "    LOGV = M2.dot(Tb).dot(Tb) # N\n",
    "    LOGM = M1[:,:,0].dot(Tb) # N\n",
    "    LOGX = Tmn(mxl,LOGM+S) # N\n",
    "    R0   = Tmn(mxr,Tsexp(LOGX))*dtf # N \n",
    "    RM   = R0 * Tmn(1.0+0.5*LOGV,xvc) # N\n",
    "    return LOGV,LOGM,LOGX,R0,RM\n",
    "TallM1 = T.tensor3(\"TallM1\",dtype=dtype)\n",
    "TallM2 = T.tensor3(\"TallM2\",dtype=dtype)\n",
    "TallS_ = T.vector(\"TallS_\",dtype=dtype)\n",
    "project_moments_parallel_theano = Tfun(\n",
    "    inp = [TallM1,TallM2,TallS_],\n",
    "    out = project_moments_parallel_theano_source(TallM1,TallM2,TallS_))\n",
    "\n",
    "def euler_update_moments_parallel_theano_source(M1,M2,R0,RM):\n",
    "    M1  += TAdt.dot(M1).transpose(1,0,2)\n",
    "    J    = TCb*R0[:,None,None]+TAdt[None,:,:]\n",
    "    JM2  = T.batched_dot(J,M2)\n",
    "    M2  += JM2 + JM2.transpose((0,2,1))\n",
    "    M1  += TC *RM[:,None,None]\n",
    "    M2  += TCC*RM[:,None,None]\n",
    "    return M1,M2\n",
    "TR0 = T.vector(\"TR0\",dtype=dtype)\n",
    "TRM = T.vector(\"TRM\",dtype=dtype)\n",
    "euler_update_moments_parallel_theano = Tfun(\n",
    "    inp = [TallM1,TallM2,TR0,TRM],\n",
    "    out = euler_update_moments_parallel_theano_source(TallM1,TallM2,TR0,TRM))\n",
    "\n",
    "def integrate_moments_parallel_theano_source(M1,M2,S):\n",
    "    LOGV,LOGM,LOGX,R0,RM = project_moments_parallel_theano_source(M1,M2,S)\n",
    "    M1,M2 = euler_update_moments_parallel_theano_source(M1,M2,R0,RM)\n",
    "    return M1,M2\n",
    "integrate_moments_parallel_theano = Tfun(\n",
    "    inp = [TallM1,TallM2,TallS_],\n",
    "    out = integrate_moments_parallel_theano_source(TallM1,TallM2,TallS_))\n",
    "\n",
    "def univariate_prior_parallel_theano_source(LM,LT):\n",
    "    TQ = LT + rr\n",
    "    VQ = Tsinv(TQ)\n",
    "    MQ = (LM*LT+mm*rr)*VQ\n",
    "    return MQ,VQ\n",
    "TLM = T.vector(\"TLM\",dtype=dtype)\n",
    "TLT = T.vector(\"TLT\",dtype=dtype)\n",
    "univariate_prior_parallel_theano = Tfun(\n",
    "    inp = [TLM,TLT],\n",
    "    out = univariate_prior_parallel_theano_source(TLM,TLT))\n",
    "\n",
    "def quadrature_moments_parallel(MQ,VQ,S_,Y_):\n",
    "    intr = np.linspace(-4,4,25)\n",
    "    X_ = intr[None,:]*np.sqrt(VQ)[:,None]+MQ[:,None]\n",
    "    R0_ = X_ + S_[:,None]+slog(dt)\n",
    "    L = Y_[:,None]*R0_-sexp(R0_)\n",
    "    L = L - np.max(L,axis=1)[:,None]\n",
    "    L += -.5*((intr**2)[None,:]+slog(VQ)[:,None])\n",
    "    PR = np.maximum(1e-7,sexp(L))\n",
    "    NR = 1/np.sum(PR,axis=1)\n",
    "    MP = np.sum(X_*PR,axis=1)*NR\n",
    "    VP = np.sum((X_-MP[:,None])**2*PR,axis=1)*NR\n",
    "    return MP,VP\n",
    "\n",
    "Tintr = Tcon(np.linspace(-4,4,25))\n",
    "def quadrature_moments_parallel_theano_source(MQ,VQ,S,Y):\n",
    "    X  = Tintr[None,:]*T.sqrt(VQ)[:,None]+MQ[:,None]\n",
    "    R0 = X + S[:,None]+Tslog(Tcast(dt))\n",
    "    L  = Y[:,None]*R0-Tsexp(R0)\n",
    "    L  = L - T.max(L,axis=1)[:,None]\n",
    "    L += -0.5*((Tintr**2.0)[None,:]+Tslog(VQ)[:,None])\n",
    "    PR = Tmx(Tcon(1e-7),Tsexp(L))\n",
    "    NR = Tsinv(T.sum(PR,axis=1))\n",
    "    MP = T.sum(X*PR,axis=1)*NR\n",
    "    VP = T.sum((X-MP[:,None])**2.0*PR,axis=1)*NR\n",
    "    return MP,VP\n",
    "\n",
    "TMQ = T.vector(\"TMQ\",dtype=dtype)\n",
    "TVQ = T.vector(\"TVQ\",dtype=dtype)\n",
    "TS_ = T.vector(\"TS_\",dtype=dtype)\n",
    "TY_ = T.vector(\"TY_\",dtype=dtype)\n",
    "quadrature_moments_parallel_theano = Tfun(\n",
    "    inp = [TMQ,TVQ,TS_,TY_],\n",
    "    out = quadrature_moments_parallel_theano_source(TMQ,TVQ,TS_,TY_))\n",
    "\n",
    "def surrogate_likelihood_parallel_theano_source(LM,LT,MP,TP):\n",
    "    VR = Tsinv(TP-LT)\n",
    "    MR = (MP*TP-LM*LT)*VR\n",
    "    return MR,VR\n",
    "TLM = T.vector(\"TLM\",dtype=dtype)\n",
    "TLT = T.vector(\"TLT\",dtype=dtype)\n",
    "TMP = T.vector(\"TMP\",dtype=dtype)\n",
    "TTP = T.vector(\"TTP\",dtype=dtype)\n",
    "surrogate_likelihood_parallel_theano = Tfun(\n",
    "    inp = [TLM,TLT,TMP,TTP],\n",
    "    out = surrogate_likelihood_parallel_theano_source(TLM,TLT,TMP,TTP))\n",
    "\n",
    "def conditional_gaussian_parallel_theano_source(M1,M2,MR,VR,LM,LV):\n",
    "    M2B = M2.dot(Tbeta) # NxKx1\n",
    "    KG  = M2B/(VR+LV)[:,None,None] #NxKx1\n",
    "    M2 -= T.batched_dot(KG,M2B.transpose(0,2,1))\n",
    "    M1 += KG*(MR-LM)[:,None,None]\n",
    "    return M1,M2\n",
    "TMR = T.vector(\"TLM\",dtype=dtype)\n",
    "TVR = T.vector(\"TLT\",dtype=dtype)\n",
    "TLV = T.vector(\"TLV\",dtype=dtype)\n",
    "conditional_gaussian_parallel_theano = Tfun(\n",
    "    inp = [TallM1,TallM2,TMR,TVR,TLM,TLV],\n",
    "    out = conditional_gaussian_parallel_theano_source(TallM1,TallM2,TMR,TVR,TLM,TLV))\n",
    "\n",
    "def loglikelihood_parallel_theano_source(M1,M2,S,Y,LM,LV,MP,VP):\n",
    "    _,_,LR,_,_ = project_moments_parallel_theano_source(M1,M2,S)\n",
    "    LOGPYX     = Y*LR-Tsexp(LR)\n",
    "    LL         = LOGPYX - 0.5*(Tslog(LV/VP) + (MP-LM)**2.0/LV)\n",
    "    return LL\n",
    "TVP = T.vector(\"TVP\",dtype=dtype)\n",
    "loglikelihood_parallel_theano = Tfun(\n",
    "    inp = [TallM1,TallM2,TS_,TY_,TLM,TLV,TMP,TVP],\n",
    "    out = loglikelihood_parallel_theano_source(TallM1,TallM2,TS_,TY_,TLM,TLV,TMP,TVP))\n",
    "\n",
    "def measurement_update_parallel_theano_source(M1,M2,S,Y):\n",
    "    LV,LM,_,_,_ = project_moments_parallel_theano_source(M1,M2,S)\n",
    "    LT    = Tsinv(LV)\n",
    "    MQ,VQ = univariate_prior_parallel_theano_source(LM,LT)\n",
    "    MP,VP = quadrature_moments_parallel_theano_source(MQ,VQ,S,Y)\n",
    "    TP    = Tsinv(VP)\n",
    "    MR,VR = surrogate_likelihood_parallel_theano_source(LM,LT,MP,TP)\n",
    "    M1,M2 = conditional_gaussian_parallel_theano_source(M1,M2,MR,VR,LM,LV)\n",
    "    LL    = loglikelihood_parallel_theano_source(M1,M2,S,Y,LM,LV,MP,VP)\n",
    "    return M1,M2,LL\n",
    "measurement_update_parallel_theano = Tfun(\n",
    "    inp = [TallM1,TallM2,TS_,TY_],\n",
    "    out = measurement_update_parallel_theano_source(TallM1,TallM2,TS_,TY_))\n",
    "\n",
    "def integrate_dt_parallel_theano_source(M1,M2,S):\n",
    "    for k in range(oversample):\n",
    "        M1,M2 = integrate_moments_parallel_theano_source(M1,M2,S)\n",
    "    return M1,M2\n",
    "integrate_dt_parallel_theano = Tfun(\n",
    "    inp = [TallM1,TallM2,TS_],\n",
    "    out = integrate_dt_parallel_theano_source(TallM1,TallM2,TS_))\n",
    "\n",
    "def filter_moments_parallel_theano_source(di,M1,M2,S,Y):\n",
    "    if reg_cov>0.0:\n",
    "        M2 = 0.5*(M2 + M2.transpose(0,2,1)) + Tcast(allRC)\n",
    "    offsets = Tmx(0.0,T.arange(N)+di)\n",
    "    offsets = T.cast(offsets,'int32')\n",
    "    S = S[offsets]\n",
    "    Y = Y[offsets]\n",
    "    M1,M2    = integrate_dt_parallel_theano_source(M1,M2,S)\n",
    "    M1,M2,LL = measurement_update_parallel_theano_source(M1,M2,S,Y)\n",
    "    return M1,M2,LL\n",
    "Tdi = T.scalar(\"Tdi\",dtype=dtype)\n",
    "filter_moments_parallel_theano = Tfun(\n",
    "    inp = [Tdi,TallM1,TallM2,TS_,TY_],\n",
    "    out = filter_moments_parallel_theano_source(Tdi,TallM1,TallM2,TS_,TY_))\n",
    "\n",
    "\n",
    "# Depth D Loop\n",
    "[_M1,_M2,_LL], up = theano.scan(filter_moments_parallel_theano_source,\n",
    "                                sequences     = [Tcon(arange(1-D,1))],\n",
    "                                outputs_info  = [Tcon(iniM1),Tcon(iniM2),None],\n",
    "                                non_sequences = [TS_,TY_],\n",
    "                                n_steps       = D,\n",
    "                                name          = 'scan_moments_parallel_theano')\n",
    "#\n",
    "ALLM1,ALLM2 = _M1[-1],_M2[-1]\n",
    "ALLLV,_,ALLLR,_,_ = project_moments_parallel_theano_source(ALLM1,ALLM2,TS_)\n",
    "scan_moments_parallel_theano = Tfun(\\\n",
    "    inp = [TS_,TY_],\n",
    "    out = [ALLLR,ALLLV,ALLM1,ALLM2,-T.mean(_LL[-1])],\n",
    "    upd = up)     \n",
    "\n",
    "\n",
    "    \n",
    "##########################################\n",
    "tic()\n",
    "allLR,allLV,allM1,allM2,NLL = scan_moments_parallel_theano(S,Y)\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,NLL)\n",
    "ylim(max(ylim()[0],-100),5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a wrapper so we can call this with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "\n",
    "def project_stimulus_theano_source(Xst,par):\n",
    "    mm  = par[0]\n",
    "    b   = par[1:K+1]\n",
    "    bst = par[K+1:]\n",
    "    return Xst.dot(bst) + m\n",
    "Xst = T.matrix(\"Xst\",dtype=dtype)\n",
    "par = T.vector(\"par\",dtype=dtype)\n",
    "project_stimulus_theano = Tfun(\n",
    "    inp = [Xst,par],\n",
    "    out = project_stimulus_theano_source(Xst,par))\n",
    "Tstim = project_stimulus_theano_source(Xst,par)\n",
    "[_M1par,_M2par,_LLpar], uppar = theano.scan(filter_moments_parallel_theano_source,\n",
    "                                sequences     = [Tcon(arange(1-D,1))],\n",
    "                                outputs_info  = [Tcon(iniM1),Tcon(iniM2),None],\n",
    "                                non_sequences = [Tstim,TY_],\n",
    "                                n_steps       = D,\n",
    "                                name          = 'scan_moments_parallel_theano')\n",
    "ALLM1par,ALLM2par = _M1par[-1],_M2par[-1]\n",
    "ALLLVpar,_,ALLLRpar,_,_ = project_moments_parallel_theano_source(ALLM1par,ALLM2par,Tstim)\n",
    "scan_moments_parallel_theano_parameters = Tfun(\\\n",
    "    inp = [Xst,TY_,par],\n",
    "    out = [ALLLRpar,ALLLVpar,ALLM1par,ALLM2par,-T.mean(_LLpar[-1])],\n",
    "    upd = uppar)                          \n",
    "\n",
    "tic()\n",
    "allLR,allLV,allM1,allM2,NLL = scan_moments_parallel_theano_parameters(Bh_train,Y_train,p)\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,NLL)\n",
    "ylim(max(ylim()[0],-100),5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to get this all cleaned up in one spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "p = p0.copy()\n",
    "m        = array(p).ravel()[0]\n",
    "beta     = ascolumn(p[1:K+1])\n",
    "beta_st  = ascolumn(p[1+K:])\n",
    "stim     = (m + Bh_train.dot(beta_st))[:,0]\n",
    "stim_np  = stim\n",
    "beta_np  = ascolumn(p[1:K+1])\n",
    "'''\n",
    "\n",
    "TAdt  = Tcon(Adt)\n",
    "#Tbeta = Tcon(beta)\n",
    "#Tb    = Tcon(p.ravel()[1:K+1])\n",
    "TC    = Tcon(C ).dimshuffle('x',0,1)\n",
    "TCb   = Tcon(Cb).dimshuffle('x',0,1)\n",
    "TCC   = Tcon(CC).dimshuffle('x',0,1)\n",
    "\n",
    "allRC = np.zeros((N,K,K))\n",
    "for i in range(N):\n",
    "    allRC[i] = np.eye(K)*reg_cov\n",
    "TRC   = Tcast(allRC)\n",
    "\n",
    "mxl = Tcon(maxlogr)\n",
    "mxr = Tcon(maxrate)\n",
    "dtf = Tcon(dtfine)\n",
    "xvc = Tcon(maxvcorr)\n",
    "rr  = Tcon(reg_rate)\n",
    "#mm  = Tcon(m)\n",
    "\n",
    "TM1 = T.tensor3(\"TM1\",dtype=dtype)\n",
    "TM2 = T.tensor3(\"TM2\",dtype=dtype)\n",
    "Xst = T.matrix(\"Xst\",dtype=dtype)\n",
    "par = T.vector(\"par\",dtype=dtype)\n",
    "\n",
    "Tb = par[1:K+1]\n",
    "mm = par[0]\n",
    "\n",
    "def integrate_moments_parallel_theano_source(M1,M2,S,Tb):\n",
    "    LOGV = M2.dot(Tb).dot(Tb) # N\n",
    "    LOGM = M1[:,:,0].dot(Tb)  # N\n",
    "    LOGX = Tmn(mxl,LOGM+S) # N\n",
    "    R0   = Tmn(mxr,Tsexp(LOGX))*dtf # N \n",
    "    RM   = R0 * Tmn(1.0+0.5*LOGV,xvc) # N\n",
    "    J    = TCb*R0[:,None,None]+TAdt[None,:,:]\n",
    "    JM2  = T.batched_dot(J,M2)\n",
    "    M2  += JM2 + JM2.transpose(0,2,1)    + TCC*RM[:,None,None]\n",
    "    M1  += TAdt.dot(M1).transpose(1,0,2) + TC *RM[:,None,None]\n",
    "    return M1,M2\n",
    "Tintr = Tcon(np.linspace(-4,4,25))\n",
    "def measurement_update_parallel_theano_source(M1,M2,S,Y,Tb):\n",
    "    LV = M2.dot(Tb).dot(Tb) # N\n",
    "    LM = M1[:,:,0].dot(Tb)  # N\n",
    "    LT = Tsinv(LV)\n",
    "    TQ = LT + rr\n",
    "    VQ = Tsinv(TQ)\n",
    "    MQ = (LM*LT+mm*rr)*VQ\n",
    "    X  = Tintr[None,:]*T.sqrt(VQ)[:,None]+MQ[:,None]\n",
    "    R0 = X + S[:,None]+Tslog(dt)\n",
    "    L  = Y[:,None]*R0-Tsexp(R0)\n",
    "    L  = L - T.max(L,axis=1)[:,None]\n",
    "    L += -0.5*((Tintr**2.0)[None,:]+Tslog(VQ)[:,None])\n",
    "    PR = Tmx(1e-7,Tsexp(L))\n",
    "    NR = Tsinv(T.sum(PR,axis=1))\n",
    "    MP = T.sum(X*PR,axis=1)*NR\n",
    "    VP = T.sum((X-MP[:,None])**2*PR,axis=1)*NR\n",
    "    TP = Tsinv(VP)\n",
    "    VR = Tsinv(TP-LT)\n",
    "    MR = (MP*TP-LM*LT)*VR\n",
    "    # Multivariate conditional update\n",
    "    M2B   = M2.dot(Tb.dimshuffle(0,'x')) # NxKx1\n",
    "    KG    = M2B/(VR+LV)[:,None,None] #NxKx1\n",
    "    M2   -= T.batched_dot(KG,M2B.transpose(0,2,1))\n",
    "    M1   += KG*(MR-LM)[:,None,None]\n",
    "    LR    = Tmn(mxl,M1[:,:,0].dot(Tb)+S) # N\n",
    "    LOGPYX= Y*LR-Tsexp(LR)\n",
    "    LL    = LOGPYX - 0.5*(Tslog(LV/VP) + (MP-LM)**2.0/LV)\n",
    "    return M1,M2,-T.mean(LL)\n",
    "def filter_moments_parallel_theano_source(di,M1,M2,S,Y,Tb):\n",
    "    if reg_cov>0:\n",
    "        M2 = 0.5*(M2 + M2.transpose(0,2,1)) + TRC\n",
    "    offsets = T.maximum(0,T.arange(N)+di)\n",
    "    offsets = T.cast(offsets,'int32')\n",
    "    S = S[offsets]\n",
    "    Y = Y[offsets]\n",
    "    for k in range(oversample):\n",
    "        M1,M2 = integrate_moments_parallel_theano_source(M1,M2,S,Tb)\n",
    "    M1,M2,NLL = measurement_update_parallel_theano_source(M1,M2,S,Y,Tb)\n",
    "    return M1,M2,NLL\n",
    "def project_stimulus_theano_source(Xst,par):\n",
    "    mm  = par[0]\n",
    "    b   = par[1:K+1]\n",
    "    bst = par[K+1:]\n",
    "    return Xst.dot(bst) + m\n",
    "Tstim = project_stimulus_theano_source(Xst,par)\n",
    "[_M1par,_M2par,_LLpar], uppar = theano.scan(filter_moments_parallel_theano_source,\n",
    "                                sequences     = [Tcon(arange(1-D,1))],\n",
    "                                outputs_info  = [Tcon(iniM1),Tcon(iniM2),None],\n",
    "                                non_sequences = [Tstim,TY_,Tb],\n",
    "                                n_steps       = D,\n",
    "                                name          = 'scan_moments_parallel_theano')\n",
    "ALLM1par,ALLM2par = _M1par[-1],_M2par[-1]\n",
    "ALLLVpar,_,ALLLRpar,_,_ = project_moments_parallel_theano_source(ALLM1par,ALLM2par,Tstim)\n",
    "scan_moments_parallel_theano_parameters = Tfun(\\\n",
    "    inp = [Xst,TY_,par],\n",
    "    out = [ALLLRpar,ALLLVpar,ALLM1par,ALLM2par,_LLpar[-1]],\n",
    "    upd = uppar)                          \n",
    "\n",
    "tic()\n",
    "allLR,allLV,allM1,allM2,NLL = scan_moments_parallel_theano_parameters(Bh_train,Y_train,p)\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5,label='Full filtering')\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0,label='D-step filtering')\n",
    "niceaxis()\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,NLL)\n",
    "ylim(max(ylim()[0],-100),5) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make new figure for talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=1,label='MC Filtering')\n",
    "plot(project_stimulus_theano(Bh_train,p) + By_train.dot(p[1:K+1]),color=RUST,lw=1,label='GLM log-λ')\n",
    "niceaxis()\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,NLL)\n",
    "ylim(max(ylim()[0],-100),5) \n",
    "xlabel('Time (ms)')\n",
    "ylabel('$\\ln(\\lambda)$')\n",
    "\n",
    "savefigure('MCARPPGLM_filtering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we need to add support for surrogate measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redefine measurement to use surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tdepth = T.scalar(\"Tdepth\",dtype='int32')\n",
    "\n",
    "def theano_build_depth_shifted_priors_source(M1,M2,D):\n",
    "    TdefaultM1 = Tcast(np.zeros((K,1)))\n",
    "    TdefaultM2 = Tcast(np.eye(K)*1e-6)\n",
    "    TiniM1 = T.concatenate([T.repeat(T.shape_padleft(TdefaultM1),D,axis=0),M1[:-D]])\n",
    "    TiniM2 = T.concatenate([T.repeat(T.shape_padleft(TdefaultM2),D,axis=0),M2[:-D]])\n",
    "    return TiniM1,TiniM2\n",
    "\n",
    "theano_build_depth_shifted_priors = Tfun(\\\n",
    "    inp = [TallM1,TallM2,Tdepth],\n",
    "    out = theano_build_depth_shifted_priors_source(TallM1,TallM2,Tdepth),\n",
    "    upd = uppar)                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "\n",
    "allRC = np.zeros((N,K,K))\n",
    "for i in range(N):\n",
    "    allRC[i] = np.eye(K)*reg_cov\n",
    "TRC = Tcast(allRC)\n",
    "\n",
    "MR_ = T.vector(\"MR_\",dtype=dtype)\n",
    "VR_ = T.vector(\"VR_\",dtype=dtype)\n",
    "TS_ = T.vector(\"TS_\",dtype=dtype)\n",
    "Xst = T.matrix(\"Xst\",dtype=dtype)\n",
    "par = T.vector(\"par\",dtype=dtype)\n",
    "\n",
    "TpriorM1 = T.tensor3(\"TpriorM1\",dtype=dtype)\n",
    "TpriorM2 = T.tensor3(\"TpriorM2\",dtype=dtype)\n",
    "\n",
    "TdefaultM1 = Tcast(np.zeros((K,1)))\n",
    "TdefaultM2 = Tcast(np.eye(K)*1e-6)\n",
    "\n",
    "#TiniM1     = Tcast(np.zeros((N,K,1)))\n",
    "#TiniM2     = Tcast(np.zeros((N,K,K)))\n",
    "#TiniM1[:D] = TdefaultM1\n",
    "#TiniM2[:D] = TdefaultM2\n",
    "#TiniM1[D:] = TpriorM1[:-D]\n",
    "#TiniM2[D:] = TpriorM2[:-D]\n",
    "#TiniM1 = T.concatenate([T.tile(TdefaultM1,Tdepth,ndim=3),TpriorM1[:-Tdepth]])\n",
    "#TiniM2 = T.concatenate([T.tile(TdefaultM2,Tdepth,ndim=3),TpriorM2[:-Tdepth]])\n",
    "\n",
    "TiniM1,TiniM2 = theano_build_depth_shifted_priors_source(TpriorM1,TpriorM2,Tdepth)\n",
    "\n",
    "#T.tile()\n",
    "\n",
    "#TiniM1 = priorM1.copy()\n",
    "#TiniM1 = T.set_subtensor(TiniM1[:D],np.zeros((K,1)))\n",
    "#TiniM1 = T.set_subtensor()\n",
    "\n",
    "Tb = par[1:K+1]\n",
    "mm = par[0]\n",
    "\n",
    "def measurement_update_parallel_theano_surrogate_source(M1,M2,S,Y,MR,VR,Tb):\n",
    "    LV  = M2.dot(Tb).dot(Tb) # N\n",
    "    LM  = Tcast(M1[:,:,0].dot(Tb)) # N\n",
    "    LT  = Tsinv(LV)\n",
    "    # Multivariate conditional update\n",
    "    M2B = M2.dot(Tb.dimshuffle(0,'x'))\n",
    "    KG  = Tsdiv(M2B,(VR+LV)[:,None,None])\n",
    "    M2 -= T.batched_dot(KG,M2B.transpose(0,2,1))\n",
    "    M1 += KG*(MR-LM)[:,None,None]\n",
    "    # Compute univariate update for likelihood\n",
    "    TR  = Tsinv(VR)\n",
    "    TP  = LT + TR\n",
    "    VP  = Tsinv(TP)\n",
    "    MP  = (LT*LM+TR*MR)*VP\n",
    "    # Compute likelihood\n",
    "    LR  = Tmn(mxl,M1[:,:,0].dot(Tb)+S)\n",
    "    LYX = Y*LR-Tsexp(LR)\n",
    "    LL  = LYX - 0.5*(Tslog(LV/VP) + (MP-LM)**2.0/LV)\n",
    "    return M1,M2,-T.mean(LL)\n",
    "\n",
    "def filter_moments_parallel_theano_surrogate_source(di,M1,M2,S,Y,MR,VR,Tb):\n",
    "    if reg_cov>0:\n",
    "        M2 = 0.5*(M2 + M2.transpose(0,2,1)) + TRC\n",
    "    offsets = T.maximum(0.0,T.arange(N)+di)\n",
    "    offsets = T.cast(offsets,'int32')\n",
    "    S  = S[offsets]\n",
    "    Y  = Y[offsets]\n",
    "    MR = MR[offsets]\n",
    "    VR = VR[offsets]\n",
    "    for k in range(oversample):\n",
    "        M1,M2 = integrate_moments_parallel_theano_source(M1,M2,S,Tb)\n",
    "    M1,M2,NLL = measurement_update_parallel_theano_surrogate_source(M1,M2,S,Y,MR,VR,Tb)\n",
    "    return M1,M2,NLL\n",
    "\n",
    "def project_stimulus_theano_source(Xst,par):\n",
    "    mm  = par[0]\n",
    "    b   = par[1:K+1]\n",
    "    bst = par[K+1:]\n",
    "    return Xst.dot(bst) + m\n",
    "\n",
    "Tstim = project_stimulus_theano_source(Xst,par)\n",
    "\n",
    "[_M1par,_M2par,_LLpar], uppar = theano.scan(filter_moments_parallel_theano_surrogate_source,\n",
    "                                sequences     = [T.arange(1-Tdepth,1)],\n",
    "                                outputs_info  = [TiniM1,TiniM2,None],\n",
    "                                non_sequences = [Tstim,TY_,MR_,VR_,Tb],\n",
    "                                name          = 'scan_moments_parallel_theano')\n",
    "\n",
    "ALLM1par,ALLM2par = _M1par[-1],_M2par[-1]\n",
    "ALLLVpar,_,ALLLRpar,_,_ = project_moments_parallel_theano_source(ALLM1par,ALLM2par,Tstim)\n",
    "scan_moments_parallel_theano_surrogate = Tfun(\\\n",
    "    inp = [Xst,TY_,MR_,VR_,par,TpriorM1,TpriorM2,Tdepth],\n",
    "    out = [ALLLRpar,ALLLVpar,ALLM1par,ALLM2par,_LLpar[-1]],\n",
    "    upd = uppar)                          \n",
    "\n",
    "'''\n",
    "# Depth D Loop\n",
    "[_M1,_M2,_NLL], up = theano.scan(filter_moments_parallel_theano_surrogate_source,\n",
    "                                sequences     = [Tcon(arange(1-D,1))],\n",
    "                                outputs_info  = [Tcon(iniM1),Tcon(iniM2),None],\n",
    "                                non_sequences = [TS_,TY_,MR_,VR_],\n",
    "                                n_steps       = D,\n",
    "                                name          = 'scan_moments_parallel_theano')\n",
    "M1,M2 = _M1[-1],_M2[-1]\n",
    "ALLLV = M2.dot(Tb).dot(Tb) # N\n",
    "ALLLR = T.minimum(maxlogr,M1[:,:,0].dot(Tb)+TS_) # N\n",
    "scan_moments_parallel_theano_surrogate = Tfun(\\\n",
    "    inp = [TS_,TY_,MR_,VR_],\n",
    "    out = [ALLLR,ALLLV,M1,M2,_NLL[-1]],\n",
    "    upd = up)\n",
    "'''\n",
    "\n",
    "print('Theano shallow filter using surrogate measurements defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test theano implementation with surrogate measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Get surrogate measurements\n",
    "allLRt,allLVt,allM1t,allM2t,nllt,mrt,vrt = filter_moments_theano(Bh_train,Y_train,p)\n",
    "\n",
    "tic()\n",
    "allLR,allLV,M1,M2,NLL = scan_moments_parallel_theano_surrogate(Bh_train,Y,mrt,vrt,p,priorM1,priorM2,3)\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,NLL)\n",
    "ylim(max(ylim()[0],-100),5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to Numpy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from dstep import filter_moments_dstep_surrogate\n",
    "\n",
    "tic()\n",
    "allLRnd,allLVnd,allM1nd,allM2nd,nllnd = filter_moments_dstep_surrogate(D,stim,Y_train,mrt,vrt,A,beta,C,p[0],\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    prior       = (iniM1,iniM2))\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLRnd,allLVnd,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "print(nllnd,NLL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute gradients\n",
    "\n",
    "With float32 precision, gradients are not accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''theano_shallow_gradient = Tfun(inp = [Xst,TY_,MR_,VR_,par], \n",
    "          out = [Tcast(theano.gradient.jacobian(Tcast(_LLpar[-1]),Tcast(par)))])\n",
    "\n",
    "large   = sqrt(np.finfo('float32').max)\n",
    "\n",
    "def objective(p):\n",
    "    allLR,allLV,M1,M2,NLL = scan_moments_parallel_theano_surrogate(Bh_train,Y,mrt,vrt,p)\n",
    "    if not isfinite(NLL):\n",
    "        NLL = large\n",
    "    return NLL\n",
    "\n",
    "def gradient(p):\n",
    "    g = theano_shallow_gradient(Bh_train,Y,mrt,vrt,p)[0]\n",
    "    return g\n",
    "\n",
    "g1 = numeric_grad(objective,p,1e-4)\n",
    "g2 = gradient(p)\n",
    "print(v2str(g1))\n",
    "print(v2str(g2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = p.copy()\n",
    "\n",
    "#result = array([-4.47485402448,-6.72860060925,-10.6006414101,16.3551035615,-17.4139653139,19.8456123891,-8.87941524903,-0.53968146647,0.40470884356,0.0081113061503,0.147167177181,0.730789289648,-0.232357798704,0.143245700568,-0.325816468342,0.304508845892,-0.195850447753])\n",
    "#result = array([-4.47881142922,-6.70467154546,-10.5773170227,16.3240680777,-17.4528938311,20.7620487554,-8.89687340784,-0.539562988035,0.404100055749,0.00812310614368,0.147457216399,0.732992182046,-0.231737112458,0.143636583881,-0.326526473195,0.304531168294,-0.195385352144]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should recompute surrogates near current parameters\n",
    "# Get surrogate measurements\n",
    "allLRt,allLVt,allM1t,allM2t,nllt,mrt,vrt = filter_moments_theano(Bh_train,Y_train,result)\n",
    "\n",
    "#logm,logv,expm,expv = ensemble_sample_moments(Bh_train.dot(result[K+1:])+result[0],B,result[1:K+1],M=100)\n",
    "\n",
    "verbose = 1\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "def objective(p):\n",
    "    global mrt,vrt,iteration\n",
    "    #if iteration>20:\n",
    "    #    allLRt,allLVt,allM1t,allM2t,NLL,mrt,vrt = filter_moments_theano(Bh_train,Y_train,result)\n",
    "    #    iteration = 0\n",
    "    #else:\n",
    "    #allLR,allLV,M1,M2,NLL = scan_moments_parallel_theano_surrogate(Bh_train,Y,mrt,vrt,p)\n",
    "    #    iteration += 1\n",
    "    \n",
    "    allLR,allLV,M1,M2,NLL = scan_moments_parallel_theano_surrogate(Bh_train,Y,mrt,vrt,p,allM1t,allM2t,30)\n",
    "    \n",
    "    if not isfinite(NLL):\n",
    "        NLL = large\n",
    "    \n",
    "    '''\n",
    "    logm,logv,expm,expv = ensemble_sample_moments(Bh_train.dot(result[K+1:])+result[0],B,result[1:K+1],M=100)\n",
    "    ll = Y_train*logm-sexp(logm)*(1+0.5*logv)\n",
    "    NLLPP = -mean(ll)\n",
    "    if not isfinite(NLLPP):\n",
    "        NLLPP=large\n",
    "    '''\n",
    "        \n",
    "    return NLL\n",
    "\n",
    "def gradient(p):\n",
    "    g = theano_shallow_gradient(Bh_train,Y,mrt,vrt,p)[0]\n",
    "    return g\n",
    "\n",
    "def og(p):\n",
    "    o = objective(p)\n",
    "    g = gradient(p)\n",
    "    return o,g\n",
    "\n",
    "try:\n",
    "    #result = minimize_retry(og,result,jac=True,verbose=verbose,simplex_only=False,options={'eps':1e-3})\n",
    "    #result = minimize_retry(objective,result,jac=False,verbose=verbose,simplex_only=False,options={'eps':1e-3})\n",
    "    result = minimize_retry(objective,result,jac=False,verbose=verbose,simplex_only=True)\n",
    "    print(\"Finished optimization\")\n",
    "except KeyboardInterrupt:\n",
    "    print('Optimization paused')\n",
    "    \n",
    "print('x=','['+','.join([np.float128(x).astype(str) for x in result])+']')\n",
    "print(\"Total absolute change from GLM fit is\",sum(abs(result-p0)))\n",
    "\n",
    "tic()\n",
    "allLR,allLV,allM1,allM2,NLL = scan_moments_parallel_theano_parameters(Bh_train,Y_train,result)\n",
    "toc()\n",
    "subplot(311)\n",
    "stderrplot(allLR,allLV,color=BLACK,lw=1,label='MC Filtering')\n",
    "plot(project_stimulus_theano(Bh_train,result) + By_train.dot(result[1:K+1]),color=RUST,lw=1,label='GLM log-λ')\n",
    "\n",
    "logm,logv,expm,expv = ensemble_sample_moments(Bh_train.dot(result[K+1:])+result[0],B,result[1:K+1],M=100)\n",
    "stderrplot(logm,logv,color=AZURE,filled=0,lw=1,label='point process monte carlo')\n",
    "\n",
    "niceaxis()\n",
    "ylim(max(ylim()[0],-100),5) \n",
    "xlabel('Time (ms)')\n",
    "ylabel('$\\ln(\\lambda)$')\n",
    "#savefigure('MCARPPGLM_filtering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(result[1:K+1].dot(B),color=AZURE)\n",
    "plot(result[K+1:].dot(B),color=RUST)\n",
    "axhline(color='k',lw=1)\n",
    "simpleraxis()\n",
    "positivex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm,logv,expm,expv = ensemble_sample_moments(Bh_train.dot(result[K+1:])+result[0],B,result[1:K+1],M=100)\n",
    "\n",
    "ll = Y_train*logm-sexp(logm)*(1+0.5*logv)\n",
    "NLLPP = -mean(ll)\n",
    "print(NLLPP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic()\n",
    "allLR,allLV,allM1,allM2,NLL = scan_moments_parallel_theano_parameters(Bh_train,Y_train,result)\n",
    "toc()\n",
    "subplot(311)\n",
    "stderrplot(allLR,allLV,color=BLACK,lw=1,label='MC Filtering')\n",
    "plot(project_stimulus_theano(Bh_train,result) + By_train.dot(result[1:K+1]),color=RUST,lw=1,label='GLM log-λ')\n",
    "\n",
    "logm,logv,expm,expv = ensemble_sample_moments(Bh_train.dot(result[K+1:])+result[0],B,result[1:K+1],M=1000)\n",
    "stderrplot(logm,logv,color=AZURE,filled=0,lw=1,label='point process monte carlo')\n",
    "niceaxis()\n",
    "ylim(max(ylim()[0],-100),5) \n",
    "xlabel('Time (ms)')\n",
    "ylabel('$\\ln(\\lambda)$')\n",
    "#savefigure('MCARPPGLM_filtering')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
