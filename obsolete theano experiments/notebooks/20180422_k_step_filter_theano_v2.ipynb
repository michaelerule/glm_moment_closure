{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import absolute_import\n",
    "from __future__ import with_statement\n",
    "from __future__ import division\n",
    "from __future__ import nested_scopes\n",
    "from __future__ import generators\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "\n",
    "# Load scipy/numpy/matplotlib\n",
    "from   scipy.linalg import expm\n",
    "import matplotlib.pyplot as plt\n",
    "from   pylab import *\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from warnings import warn\n",
    "\n",
    "# Configure figure resolution\n",
    "plt.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "plt.rcParams['savefig.dpi'   ] = 100\n",
    "\n",
    "from izh       import * # Routines for sampling Izhikevich neurons\n",
    "from plot      import * # Misc. plotting routines\n",
    "from glm       import * # GLM fitting\n",
    "from arppglm   import * # Sampling and integration\n",
    "from utilities import * # Other utilities\n",
    "from arguments import * # Argument verification\n",
    "\n",
    "'''\n",
    "import os\n",
    "dtype='float64'\n",
    "flags = 'mode=FAST_RUN,device=gpu,floatX=%s'%dtype\n",
    "if dtype!='float64':\n",
    "    flags += ',warn_float64=warn'\n",
    "os.environ[\"THEANO_FLAGS\"] = flags\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "'''\n",
    "\n",
    "import os\n",
    "dtype='float32'\n",
    "os.environ['MKL_THREADING_LAYER']='GNU'\n",
    "flags = 'mode=FAST_COMPILE,device=cuda0,'#,floatX=%s'%dtype\n",
    "if dtype!='float64':\n",
    "     flags += ',warn_float64=warn'\n",
    "os.environ[\"THEANO_FLAGS\"] = flags\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from theano_arppglm import *\n",
    "\n",
    "print('Workspace Initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved GLM features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#filename = 'saved_training_model.mat'\n",
    "filename = 'saved_training_model_badburster.mat'\n",
    "\n",
    "saved_training_model = scipy.io.loadmat(filename)\n",
    "K  = np.array(saved_training_model['K'],dtype=dtype)\n",
    "B  = np.array(saved_training_model['B'],dtype=dtype)\n",
    "By = np.array(saved_training_model['By'],dtype=dtype)\n",
    "Bh = np.array(saved_training_model['Bh'],dtype=dtype)\n",
    "A  = np.array(saved_training_model['A'],dtype=dtype)\n",
    "C  = np.array(saved_training_model['C'],dtype=dtype)\n",
    "Y  = np.array(saved_training_model['Y'],dtype=dtype)\n",
    "dt = np.array(saved_training_model['dt'],dtype=dtype)\n",
    "\n",
    "Bh_train = saved_training_model['Bh_train']\n",
    "By_train = saved_training_model['By_train']\n",
    "X_train  = concatenate([By_train,Bh_train],axis=1)\n",
    "Y_train  = asvector(saved_training_model['Y_train'])\n",
    "\n",
    "Bh_test  = saved_training_model['Bh_test']\n",
    "By_test  = saved_training_model['By_test']\n",
    "X_test   = concatenate([By_test,Bh_test],axis=1)\n",
    "Y_test   = asvector(saved_training_model['Y_test'])\n",
    " \n",
    "K  = int(scalar(K))\n",
    "N  = prod(Y.shape)\n",
    "\n",
    "N = len(X_train)\n",
    "STARTPLOT=0\n",
    "NPLOT=N\n",
    "\n",
    "print('Saved GLM features loaded')\n",
    "print(N)\n",
    "\n",
    "#STARTSHOW = 14000\n",
    "#STOPSHOW = 16000\n",
    "STARTSHOW = 0\n",
    "STOPSHOW = N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLM helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def lograte(Bh,By,p):\n",
    "    '''\n",
    "    Log-intensity of point process model on this dataset\n",
    "    Predicted using the standard GLM way\n",
    "    '''\n",
    "    m       = array(p).ravel()[0]\n",
    "    beta    = ascolumn(p[1:K+1])\n",
    "    beta_st = ascolumn(p[1+K:])\n",
    "    lograte = m + Bh.dot(beta_st) + By.dot(beta)\n",
    "    return lograte\n",
    "\n",
    "def logmean(Bh,M1,p):\n",
    "    '''\n",
    "    Projected history process\n",
    "    Predicted using history-process means\n",
    "    '''\n",
    "    m       = array(p).ravel()[0]\n",
    "    beta    = ascolumn(p[1:K+1])\n",
    "    beta_st = ascolumn(p[1+K:])\n",
    "    M1      = np.squeeze(M1)\n",
    "    return (beta.T.dot(M1.T))[0] + (m + Bh.dot(beta_st))[:,0]\n",
    "\n",
    "def get_stim(Bh,p):\n",
    "    m        = array(p).ravel()[0]\n",
    "    beta     = ascolumn(p[1:K+1])\n",
    "    beta_st  = ascolumn(p[1+K:])\n",
    "    stim     = (m + Bh.dot(beta_st))[:,0]\n",
    "    return stim\n",
    "\n",
    "def filter_GLM_np(Bh,p):\n",
    "    m        = array(p).ravel()[0]\n",
    "    beta     = ascolumn(p[1:K+1])\n",
    "    beta_st  = ascolumn(p[1+K:])\n",
    "    stim     = get_stim(Bh,p)\n",
    "    allM1_np = np.zeros((N,K))\n",
    "    M1       = np.zeros((K,1))\n",
    "    for i in range(N):\n",
    "        R   = scalar(sexp(p0[1:K+1].dot(M1)+m+stim[i]))\n",
    "        M1 += A.dot(M1)*dt + C.dot(R)\n",
    "        allM1_np[i] = M1[:,0]\n",
    "    return allM1_np\n",
    "\n",
    "def addspikes_(Y_=None):\n",
    "    if Y_ is None or Y_ is True:\n",
    "        Y_ = Y\n",
    "    for t in find(Y_>0):\n",
    "        axvline(t,color=OCHRE,lw=0.4)\n",
    "    \n",
    "def niceaxis(plotspikes=True):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\",message='No labelled objects found')\n",
    "        legend()\n",
    "    simpleraxis()\n",
    "    xlim(STARTSHOW,STOPSHOW)\n",
    "    if plotspikes is True or not plotspikes is None:\n",
    "        addspikes_(plotspikes)\n",
    "\n",
    "print('GLM helpers done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# Re-fit GLM\n",
    "m,bhat  = fitGLM(X_train,asvector(Y_train))\n",
    "\n",
    "# Re-pack model parameters\n",
    "p0      = np.zeros((1+len(bhat)))\n",
    "p0[0 ]  = m\n",
    "p0[1:]  = bhat\n",
    "\n",
    "allM1_np = filter_GLM_np(Bh_train,p0)\n",
    "subplot(311)\n",
    "plot(lograte(Bh_train,By_train,p0),lw=0.4,label='conditional intensity')\n",
    "plot(logmean(Bh_train,allM1_np,p0),lw=0.4,label='mean-field',color=RUST)\n",
    "niceaxis()\n",
    "ylim(min(lograte(Bh_train,By_train,p0)),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters at which to filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "oversample = 10   # Integration resolution\n",
    "maxrate    = 10.0 # Largest allowed rate\n",
    "maxvcorr   = 10.0 # Largest allowed variance correction\n",
    "dt         = 1.0  # Data time resolution\n",
    "reg_cov    = 1e-5\n",
    "reg_rate   = 1e-5\n",
    "\n",
    "p = p0.copy()\n",
    "#p[1:K+1] *= 0.775\n",
    "stim_np = get_stim(Bh_train,p)\n",
    "beta_np = ascolumn(p[1:K+1])\n",
    "print('Filtering using p=',v2str(p))\n",
    "\n",
    "# Helper function to compute negative expected log-likelihood\n",
    "def post_hoc_nll(LR,LV):\n",
    "    R0 = sexp(LR)\n",
    "    R1 = R0*(1+0.5*LV)\n",
    "    ELL  = np.mean(Y*LR - R1)\n",
    "    return -ELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "### Build Theano routines\n",
    "\n",
    "For integrating moments (not conditioned on data), filtering (conditioned on data), and filtering using surrogate likelihoods (Gaussian approximations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from theano_arppglm import *\n",
    "\n",
    "GLM_log_intensity, GLMNLL_f, GLMNLL_g, GLMNLL_h = build_ML_GLM_likelihood_theano()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "integrate_moments_theano, EMNLL_filt, EMNLL_grad = build_integrate_moments_theano(N,A,C,\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "filter_moments_theano, NLL_filt, NLL_grad = build_filter_moments_theano(N,A,C,\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    return_surrogates = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "filter_surrogate_theano, SNLL_filt, SNLL_grad = build_filter_moments_theano(N,A,C,\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    return_surrogates = False,\n",
    "    use_surrogates    = True)\n",
    "\n",
    "print('Theano functions bulit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate Without measurements.\n",
    "\n",
    "We will use the integrated moments (without measurements) as a prior distribution for our K-step prediction with measurement updates.\n",
    "\n",
    "Update: we now use the actual filtered states, to verify that shallow filtering is equivalent to deep filtering if provided appropriate initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "p = p0.copy()\n",
    "#p[1:]*=3\n",
    "\n",
    "m        = array(p).ravel()[0]\n",
    "beta     = ascolumn(p[1:K+1])\n",
    "beta_st  = ascolumn(p[1+K:])\n",
    "stim     = (m + Bh_train.dot(beta_st))[:,0]\n",
    "stim_np  = stim\n",
    "beta_np  = ascolumn(p[1:K+1])\n",
    "\n",
    "print('Filtering using p=',v2str(p))\n",
    "\n",
    "tic()\n",
    "allLRni,allLVni,allM1ni,allM2ni = integrate_moments(stim_np,A,beta_np,C,\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\")\n",
    "toc()\n",
    "subplot(411)\n",
    "stderrplot(allLRni,allLVni,color=BLACK,lw=0.5)\n",
    "niceaxis()\n",
    "xlim(STARTSHOW,STOPSHOW)\n",
    "title('Integrating, numpy')\n",
    "\n",
    "tic()\n",
    "allLRti,allLVti,allM1ti,allM2ti = integrate_moments_theano(Bh_train,p)\n",
    "toc()\n",
    "subplot(412)\n",
    "stderrplot(allLRti,allLVti,color=BLACK,lw=0.5)\n",
    "niceaxis()\n",
    "xlim(STARTSHOW,STOPSHOW)\n",
    "title('Integrating, theano')\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep filtering in Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "tic()\n",
    "allLRn,allLVn,allM1n,allM2n,nlln,mrn,vrn = filter_moments(stim,Y_train,A,beta,C,p[0],\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    return_surrogates = True)\n",
    "toc()\n",
    "subplot(411)\n",
    "stderrplot(allLRn,allLVn,color=BLACK,lw=0.5)\n",
    "niceaxis()\n",
    "xlim(STARTSHOW,STOPSHOW)\n",
    "title('Filtering, numpy')\n",
    "print('nll, numpy',nlln)\n",
    "\n",
    "tic()\n",
    "allLRt,allLVt,allM1t,allM2t,nllt,mrt,vrt = filter_moments_theano(Bh_train,Y_train,p)\n",
    "toc()\n",
    "subplot(412)\n",
    "stderrplot(allLRt,allLVt,color=BLACK,lw=0.5)\n",
    "niceaxis()\n",
    "xlim(STARTSHOW,STOPSHOW)\n",
    "title('Filtering, theano')\n",
    "print('nll, theano',nllt)\n",
    "\n",
    "subplot(413)\n",
    "plot(allLRn,color=BLACK,label='log-λ numpy')\n",
    "plot(allLRt,':',color=RUST,label='log-λ theano')\n",
    "niceaxis()\n",
    "xlim(STARTSHOW,STOPSHOW)\n",
    "\n",
    "priorLR,priorLV,priorM1,priorM2 = allLRt,allLVt,allM1t,allM2t\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First: let us see if we can get \"parallel\" moment integration (no measurements). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "## Start with naive implementation for reference\n",
    "\n",
    "Demonstrate shallow depth-5 filtering. Even starting from a prior with no inforamation about the filtered state, these results can be relatively accurate. This could lead to parallel filtering routines to accelerate inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arppglm import filter_moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "D  = 5\n",
    "ND = N-D\n",
    "\n",
    "# Precompute constants\n",
    "maxlogr   = np.log(maxrate)\n",
    "maxratemc = maxvcorr*maxrate\n",
    "dtfine    = dt/oversample\n",
    "Cb        = C.dot(beta.T)\n",
    "CC        = C.dot(C.T)\n",
    "Adt       = A*dtfine\n",
    "\n",
    "themeasurement = 'moment'\n",
    "int_method = 'euler'\n",
    "method = 'second_order'\n",
    "\n",
    "# Get measurement update function\n",
    "measurement = get_measurement(themeasurement)\n",
    "# Buid moment integrator functions\n",
    "mean_update, cov_update = get_moment_integrator(int_method,Adt)\n",
    "# Get update function (computes expected rate from moments)\n",
    "update = get_update_function(method,Cb,Adt,maxvcorr)\n",
    "\n",
    "allLR = np.zeros(N)\n",
    "allLV = np.zeros(N)\n",
    "\n",
    "tic()\n",
    "for i in range(N):\n",
    "    b = i+1\n",
    "    a = i-D+1\n",
    "    c = a-1\n",
    "    ini = (priorM1[c],priorM2[c]) if c>=0 else None\n",
    "    a = max(0,a)\n",
    "    c = max(0,a-1)\n",
    "    lr,lv,_,_,_,_,_ = filter_moments(stim[a:b],Y_train[a:b],A,beta,C,p[0],\n",
    "        dt          = dt,\n",
    "        oversample  = oversample,\n",
    "        maxrate     = maxrate,\n",
    "        maxvcorr    = maxvcorr,\n",
    "        method      = \"second_order\",\n",
    "        int_method  = \"euler\",\n",
    "        measurement = \"moment\",\n",
    "        reg_cov     = reg_cov,\n",
    "        reg_rate    = reg_rate,\n",
    "        return_surrogates = True,\n",
    "        initial_conditions = ini)\n",
    "    allLR[i] = lr[-1]\n",
    "    allLV[i] = lv[-1]\n",
    "toc()\n",
    "\n",
    "assert(all(isfinite(allLR)))\n",
    "assert(all(isfinite(allLV)))\n",
    "\n",
    "allLRref,allLVref = allLR,allLV\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRn,allLVn,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "ylim(max(ylim()[0],-100),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compartamentalize in function\n",
    "\n",
    "Note that parallel shallow filtering is still slower than running the full forward pass, as we must perform O(D*N) work as opposed to O(N). However, this will admits a depth-D algorithm in theano which may give us some improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic()\n",
    "allLRt,allLVt,allM1t,allM2t,nllt,mrt,vrt = filter_moments_theano(Bh_train,Y_train,p)\n",
    "toc()\n",
    "\n",
    "priorLR,priorLV,priorM1,priorM2 = allLRt,allLVt,allM1t,allM2t\n",
    "defaultM1 = np.zeros((K,1))\n",
    "defaultM2 = np.eye(K)*1e-6\n",
    "\n",
    "iniM1 = np.zeros((N,K,1))\n",
    "iniM2 = np.zeros((N,K,K))\n",
    "iniM1[:D-1]=defaultM1\n",
    "iniM2[:D-1]=defaultM2\n",
    "iniM1[D-1:]=priorM1[:-D+1]\n",
    "iniM2[D-1:]=priorM2[:-D+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "tic()\n",
    "allLRn,allLVn,allM1n,allM2n,nlln,mrn,vrn = filter_moments(stim,Y_train,A,beta,C,p[0],\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    return_surrogates = True)\n",
    "toc()\n",
    "\n",
    "from dstep import filter_moments_dstep\n",
    "\n",
    "tic()\n",
    "allLRt,allLVt,allM1t,allM2t,nllt,mrt,vrt = filter_moments_theano(Bh_train,Y_train,p)\n",
    "toc()\n",
    "\n",
    "priorLR,priorLV,priorM1,priorM2 = allLRt,allLVt,allM1t,allM2t\n",
    "defaultM1 = np.zeros((K,1))\n",
    "defaultM2 = np.eye(K)*1e-6\n",
    "\n",
    "iniM1 = np.zeros((N,K,1))\n",
    "iniM2 = np.zeros((N,K,K))\n",
    "iniM1[:D]=defaultM1\n",
    "iniM2[:D]=defaultM2\n",
    "iniM1[D:]=priorM1[:-D]\n",
    "iniM2[D:]=priorM2[:-D]\n",
    "\n",
    "\n",
    "tic()\n",
    "allLRnd,allLVnd,allM1nd,allM2nd,nllnd = filter_moments_dstep(D,stim,Y_train,A,beta,C,p[0],\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    prior       = (iniM1,iniM2))\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLRnd,allLVnd,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "ylim(max(ylim()[0],-100),5)\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,nllnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano implementation\n",
    "\n",
    "Separate functions are great for debugging, but let's clean things up a bit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic()\n",
    "allLRt,allLVt,allM1t,allM2t,nllt,mrt,vrt = filter_moments_theano(Bh_train,Y_train,p)\n",
    "toc()\n",
    "\n",
    "priorLR,priorLV,priorM1,priorM2 = allLRt,allLVt,allM1t,allM2t\n",
    "defaultM1 = np.zeros((K,1))\n",
    "defaultM2 = np.eye(K)*1e-6\n",
    "\n",
    "iniM1 = np.zeros((N,K,1))\n",
    "iniM2 = np.zeros((N,K,K))\n",
    "iniM1[:D-1]=defaultM1\n",
    "iniM2[:D-1]=defaultM2\n",
    "iniM1[D-1:]=priorM1[:-D+1]\n",
    "iniM2[D-1:]=priorM2[:-D+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRC = np.zeros((N,K,K))\n",
    "for i in range(N):\n",
    "    allRC[i] = np.eye(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "S = stim\n",
    "Y = Y_train\n",
    "\n",
    "TAdt  = Tcon(Adt)\n",
    "Tbeta = Tcon(beta)\n",
    "Tb    = Tcon(p.ravel()[1:K+1])\n",
    "TC    = Tcon(C ).dimshuffle('x',0,1)\n",
    "TCb   = Tcon(Cb).dimshuffle('x',0,1)\n",
    "TCC   = Tcon(CC).dimshuffle('x',0,1)\n",
    "TRC   = Tcon(allRC)\n",
    "\n",
    "TM1 = T.tensor3(\"TM1\",dtype=dtype)\n",
    "TM2 = T.tensor3(\"TM2\",dtype=dtype)\n",
    "\n",
    "mxl = Tcon(maxlogr)\n",
    "mxr = Tcon(maxrate)\n",
    "dtf = Tcon(dtfine)\n",
    "xvc = Tcon(maxvcorr)\n",
    "rr  = Tcon(reg_rate)\n",
    "mm  = Tcon(m)\n",
    "\n",
    "def integrate_moments_parallel_theano_source(M1,M2,S):\n",
    "    LOGV = M2.dot(Tb).dot(Tb) # N\n",
    "    LOGM = M1[:,:,0].dot(Tb)  # N\n",
    "    LOGX = T.minimum(mxl,LOGM+S) # N\n",
    "    R0   = T.minimum(mxr,Tsexp(LOGX))*dtf # N \n",
    "    RM   = R0 * T.minimum(1.0+0.5*LOGV,xvc) # N\n",
    "    J    = TCb*R0[:,None,None]+TAdt[None,:,:]\n",
    "    JM2  = T.batched_dot(J,M2)\n",
    "    M2  += JM2 + JM2.transpose(0,2,1)    + TCC*RM[:,None,None]\n",
    "    M1  += TAdt.dot(M1).transpose(1,0,2) + TC *RM[:,None,None]\n",
    "    return M1,M2\n",
    "\n",
    "Tintr = Tcon(np.linspace(-4,4,25))\n",
    "def measurement_update_parallel_theano_source(M1,M2,S_,Y_):\n",
    "    LV = M2.dot(Tb).dot(Tb) # N\n",
    "    LM = Tcast(M1[:,:,0].dot(Tb)) # N\n",
    "    LT = Tsinv(LV)\n",
    "    TQ = LT + rr\n",
    "    VQ = Tsinv(TQ)\n",
    "    MQ = (LM*LT+mm*rr)*VQ\n",
    "    X_ = Tintr[None,:]*T.sqrt(VQ)[:,None]+MQ[:,None]\n",
    "    R0 = X_ + S_[:,None]+Tslog(dt)\n",
    "    L  = Y_[:,None]*R0-Tsexp(R0)\n",
    "    L  = L - T.max(L,axis=1)[:,None]\n",
    "    L += -0.5*((Tintr**2.0)[None,:]+Tslog(VQ)[:,None])\n",
    "    PR = T.maximum(Tcast(1e-7),Tsexp(L))\n",
    "    NR = Tsinv(T.sum(PR,axis=1))\n",
    "    MP = T.sum(X_*PR,axis=1)*NR\n",
    "    VP = T.sum((X_-MP[:,None])**2.0*PR,axis=1)*NR\n",
    "    TP = Tsinv(VP)\n",
    "    VR = Tsinv(TP-LT)\n",
    "    MR = (MP*TP-LM*LT)*VR\n",
    "    # Multivariate conditional update\n",
    "    M2B   = M2.dot(Tbeta)\n",
    "    KG    = Tsdiv(M2B,(VR+LV)[:,None,None])\n",
    "    M2   -= T.batched_dot(KG,M2B.transpose(0,2,1))\n",
    "    M1   += KG*(MR-LM)[:,None,None]\n",
    "    LR    = Tmn(mxl,M1[:,:,0].dot(Tb)+S_)\n",
    "    LOGPYX= Y_*LR-Tsexp(LR)\n",
    "    LL    = LOGPYX - 0.5*(Tslog(LV/VP) + (MP-LM)**2.0/LV)\n",
    "    return M1,M2,-T.mean(LL)\n",
    "\n",
    "def filter_moments_parallel_theano_source(di,M1,M2,S_,Y_):\n",
    "    if reg_cov>0:\n",
    "        M2 = 0.5*(M2 + M2.transpose(0,2,1)) + TRC\n",
    "    offsets = T.maximum(0.0,T.arange(N)+di)\n",
    "    offsets = T.cast(offsets,'int32')\n",
    "    S_ = S_[offsets]\n",
    "    Y_ = Y_[offsets]\n",
    "    for k in range(oversample):\n",
    "        M1,M2 = integrate_moments_parallel_theano_source(M1,M2,S_)\n",
    "    M1,M2,NLL = measurement_update_parallel_theano_source(M1,M2,S_,Y_)\n",
    "    return M1,M2,NLL\n",
    "\n",
    "Tdi = T.scalar(\"Tdi\",dtype=dtype)\n",
    "TS_ = T.vector(\"TS_\",dtype=dtype)\n",
    "TY_ = T.vector(\"TY_\",dtype=dtype)\n",
    "\n",
    "filter_moments_parallel_theano = Tfun(\n",
    "    inp = [Tdi,TM1,TM2,TS_,TY_],\n",
    "    out = filter_moments_parallel_theano_source(Tdi,TM1,TM2,TS_,TY_))\n",
    "\n",
    "# Depth D Loop\n",
    "[_M1,_M2,_NLL], up = theano.scan(filter_moments_parallel_theano_source,\n",
    "                                sequences     = [Tcon(arange(1-D,1))],\n",
    "                                outputs_info  = [Tcon(iniM1),Tcon(iniM2),None],\n",
    "                                non_sequences = [TS_,TY_],\n",
    "                                n_steps       = D,\n",
    "                                name          = 'scan_moments_parallel_theano')\n",
    "#\n",
    "M1,M2 = _M1[-1],_M2[-1]\n",
    "ALLLV = M2.dot(Tb).dot(Tb) # N\n",
    "ALLLR = T.minimum(maxlogr,M1[:,:,0].dot(Tb)+TS_) # N\n",
    "scan_moments_parallel_theano = Tfun(\\\n",
    "    inp = [TS_,TY_],\n",
    "    out = [ALLLR,ALLLV,M1,M2,_NLL[-1]],\n",
    "    upd = up)\n",
    "\n",
    "print('Theano shallow filter defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "tic()\n",
    "#allLR,allLV,M1,M2,NLL = scan_moments_parallel_theano(Bh_train,Y,p)\n",
    "allLR,allLV,M1,M2,NLL = scan_moments_parallel_theano(S,Y)#,p)\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,NLL)\n",
    "ylim(max(ylim()[0],-100),5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we need to add support for surrogate measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redefine measurement to use surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "\n",
    "MR_ = T.vector(\"MR_\",dtype=dtype)\n",
    "VR_ = T.vector(\"VR_\",dtype=dtype)\n",
    "TS_ = T.vector(\"TS_\",dtype=dtype)\n",
    "\n",
    "Tintr = Tcon(np.linspace(-4,4,25))\n",
    "def measurement_update_parallel_theano_surrogate_source(M1,M2,S_,Y_,MR,VR):\n",
    "    LV  = M2.dot(Tb).dot(Tb) # N\n",
    "    LM  = Tcast(M1[:,:,0].dot(Tb)) # N\n",
    "    LT  = Tsinv(LV)\n",
    "    # Multivariate conditional update\n",
    "    M2B = M2.dot(Tbeta)\n",
    "    KG  = Tsdiv(M2B,(VR+LV)[:,None,None])\n",
    "    M2 -= T.batched_dot(KG,M2B.transpose(0,2,1))\n",
    "    M1 += KG*(MR-LM)[:,None,None]\n",
    "    # Compute univariate update for likelihood\n",
    "    TR  = Tsinv(VR)\n",
    "    TP  = LT + TR\n",
    "    VP  = Tsinv(TP)\n",
    "    MP  = (LT*LM+TR*MR)*VP\n",
    "    # Compute likelihood\n",
    "    LR  = Tmn(mxl,M1[:,:,0].dot(Tb)+S_)\n",
    "    LYX = Y_*LR-Tsexp(LR)\n",
    "    LL  = LYX - 0.5*(Tslog(LV/VP) + (MP-LM)**2.0/LV)\n",
    "    return M1,M2,-T.mean(LL)\n",
    "\n",
    "def filter_moments_parallel_theano_surrogate_source(di,M1,M2,S_,Y_,MR,VR):\n",
    "    if reg_cov>0:\n",
    "        M2 = 0.5*(M2 + M2.transpose(0,2,1)) + TRC\n",
    "    offsets = T.maximum(0.0,T.arange(N)+di)\n",
    "    offsets = T.cast(offsets,'int32')\n",
    "    S_ = S_[offsets]\n",
    "    Y_ = Y_[offsets]\n",
    "    MR = MR[offsets]\n",
    "    VR = VR[offsets]\n",
    "    for k in range(oversample):\n",
    "        M1,M2 = integrate_moments_parallel_theano_source(M1,M2,S_)\n",
    "    M1,M2,NLL = measurement_update_parallel_theano_surrogate_source(M1,M2,S_,Y_,MR,VR)\n",
    "    return M1,M2,NLL\n",
    "\n",
    "# Depth D Loop\n",
    "[_M1,_M2,_NLL], up = theano.scan(filter_moments_parallel_theano_surrogate_source,\n",
    "                                sequences     = [Tcon(arange(1-D,1))],\n",
    "                                outputs_info  = [Tcon(iniM1),Tcon(iniM2),None],\n",
    "                                non_sequences = [TS_,TY_,MR_,VR_],\n",
    "                                n_steps       = D,\n",
    "                                name          = 'scan_moments_parallel_theano')\n",
    "#\n",
    "M1,M2 = _M1[-1],_M2[-1]\n",
    "ALLLV = M2.dot(Tb).dot(Tb) # N\n",
    "ALLLR = T.minimum(maxlogr,M1[:,:,0].dot(Tb)+TS_) # N\n",
    "scan_moments_parallel_theano_surrogate = Tfun(\\\n",
    "    inp = [TS_,TY_,MR_,VR_],\n",
    "    out = [ALLLR,ALLLV,M1,M2,_NLL[-1]],\n",
    "    upd = up)\n",
    "\n",
    "print('Theano shallow filter using surrogate measurements defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test theano implementation with surrogate measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Get surrogate measurements\n",
    "allLRt,allLVt,allM1t,allM2t,nllt,mrt,vrt = filter_moments_theano(Bh_train,Y_train,p)\n",
    "\n",
    "tic()\n",
    "allLR,allLV,M1,M2,NLL = scan_moments_parallel_theano_surrogate(S,Y,mrt,vrt)\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLR,allLV,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "\n",
    "# compare likelihoods\n",
    "# parallel shallow likelihood as close to filtered likelihood\n",
    "# as it is to the theano implementation\n",
    "# meaning that a shallow filter is as accurate as a deep filter\n",
    "# up to numerical precision errors\n",
    "print(nllt,nlln,NLL)\n",
    "ylim(max(ylim()[0],-100),5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to Numpy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from dstep import filter_moments_dstep_surrogate\n",
    "\n",
    "tic()\n",
    "allLRnd,allLVnd,allM1nd,allM2nd,nllnd = filter_moments_dstep_surrogate(D,stim,Y_train,mrt,vrt,A,beta,C,p[0],\n",
    "    dt          = dt,\n",
    "    oversample  = oversample,\n",
    "    maxrate     = maxrate,\n",
    "    maxvcorr    = maxvcorr,\n",
    "    method      = \"second_order\",\n",
    "    int_method  = \"euler\",\n",
    "    measurement = \"moment\",\n",
    "    reg_cov     = reg_cov,\n",
    "    reg_rate    = reg_rate,\n",
    "    prior       = (iniM1,iniM2))\n",
    "toc()\n",
    "\n",
    "subplot(311)\n",
    "stderrplot(allLRref,allLVref,color=BLACK,lw=0.5)\n",
    "stderrplot(allLRnd,allLVnd,color=RUST,lw=0.5,filled=0)\n",
    "niceaxis()\n",
    "print(nllnd,NLL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute gradients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theano_shallow_gradient = Tfun(inp = [Xst,TY_,MR_,VR_,par], \n",
    "          out = [Tcast(theano.gradient.jacobian(Tcast(_NLL[-1]),Tcast(par)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large   = sqrt(np.finfo('float32').max)\n",
    "\n",
    "def objective(p):\n",
    "    allLR,allLV,M1,M2,NLL = scan_moments_parallel_theano_surrogate(Bh_train,Y,mrt,vrt,p)\n",
    "    if not isfinite(NLL):\n",
    "        NLL = large\n",
    "    return NLL\n",
    "\n",
    "def gradient(p):\n",
    "    g = theano_shallow_gradient(Bh_train,Y,mrt,vrt,p)[0]\n",
    "    return g\n",
    "\n",
    "g1 = numeric_grad(objective,p,1e-4)\n",
    "g2 = gradient(p)\n",
    "print(v2str(g1))\n",
    "print(v2str(g2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = p.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 1\n",
    "\n",
    "def og(p):\n",
    "    o = objective(p)\n",
    "    g = gradient(p)\n",
    "    return o,g\n",
    "\n",
    "try:\n",
    "    #result = minimize_retry(og,result,jac=True,verbose=verbose,simplex_only=False,options={'eps':1e-3})\n",
    "    #result = minimize_retry(objective,result,jac=False,verbose=verbose,simplex_only=False,options={'eps':1e-3})\n",
    "    result = minimize_retry(objective,result,jac=False,verbose=verbose,simplex_only=True)\n",
    "    print(\"Finished optimization\")\n",
    "except KeyboardInterrupt:\n",
    "    print('Optimization paused')\n",
    "    \n",
    "print('x=','['+','.join([np.float128(x).astype(str) for x in result])+']')\n",
    "print(\"Total absolute change from GLM fit is\",sum(abs(result-p0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [-4.47485402448,-6.72860060925,-10.6006414101,16.3551035615,-17.4139653139,19.8456123891,-8.87941524903,-0.53968146647,0.40470884356,0.0081113061503,0.147167177181,0.730789289648,-0.232357798704,0.143245700568,-0.325816468342,0.304508845892,-0.195850447753]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
