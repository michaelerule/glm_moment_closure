{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Load scipy/numpy/matplotlib\n",
    "from   scipy.linalg import expm\n",
    "import matplotlib.pyplot as plt\n",
    "from   pylab import *\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient non-conjugate updates for partially observed high-dimensonal latent Gaussian state-spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a state-space model with states $x \\sim \\mathcal{N}(\\mu,\\Sigma)$, which is partially observed via process $y$ through an observation model that does not admit conjugate (Kalman-Bucy) measurement update.\n",
    "\n",
    "If these non-conjugate updates depend only an a subspace $x_1 \\subset x$, then approximate non-conjugate updates can be computed in this subspace and then their effects on the larger space $x$ propagated exactly in a computationally efficient manner. \n",
    "\n",
    "Let\n",
    "\n",
    "$$\n",
    "x_1 = \\beta^\\top x\n",
    "$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "x_1 \\sim \\mathcal{N}( \\beta^\\top \\mu, \\beta^\\top \\Sigma \\beta)\n",
    "$$\n",
    "\n",
    "Define $x_2$ in terms of the subspace of $x$ that is orthogonal to $x_1$\n",
    "\n",
    "$$\n",
    "\\Pr(x) = \\Pr(x_1,x_2) = \\Pr(x_2|x_1)\\Pr(x_1)\n",
    "$$\n",
    "\n",
    "The restriction that observations $y$ depend only on the space $x_1$ implies that $y$ is independent of $x_2$, conditioned on $x_1$:\n",
    "\n",
    "$$\n",
    "\\Pr(y|x) = \\Pr(y|x_1,x_2) = \\Pr(y|x_1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the full Bayesian measurement update\n",
    "\n",
    "$$\n",
    "\\Pr(x|y) = \\Pr(y|x) \\frac {\\Pr(x)} {\\Pr(y)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be re-phrased in terms of conditional probabilities of $x_2$ given $x_1$, and using the fact that $y$ is independent of $x_2$, conditioned on $x_1$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Pr(x|y) = \\Pr(x_2|x_1) \\Pr(x_1|y) = \\Pr(x_2|x_1) \\left( \\Pr(y|x_1) \\frac {\\Pr(x_1)} {\\Pr(y)} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can compute $\\Pr(x_1|y)$, then we can compute $\\Pr(x|y)$. We may focus then on updating the subspace $x_1$ directly coupled to observations $y$\n",
    "\n",
    "$$\n",
    "\\Pr(x_1|y) = \\Pr(y|x_1) \\frac {\\Pr(x_1)} {\\Pr(y)} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we have an approximate Gaussian posterior for $Q(x_1) \\approx \\Pr(x_1|y)$, computed by Laplace approximation, variational Bayes, moment-matching, or other means. \n",
    "\n",
    "$$\n",
    "\\hat x_1 \\sim \\mathcal{N}( \\hat\\mu_1, \\hat\\Sigma_1 )\n",
    "$$\n",
    "\n",
    "Since $Q(x_1)$ is gaussian, it is straightforward to compute the full joint approximation update as\n",
    "\n",
    "$$\n",
    "Q(x) = \\Pr(x_2|x_1) Q(x_1)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, naive multiplication of the Gaussian distributions is not computationally efficient, as it will solving linear systems of the full dimension of $x$. There are many ways to derive the more efficient update, which involves solving linear systems only as large as $x_1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Kalman filter update\n",
    "\n",
    "Here I present a conceptual approach that makes an explcit connection to the Kalman filter update. The Kalman filter update involves solving a linear system of the same dimensionality as the *measurements*, which is typically much smaller than the full latent state space. This leads to substantial savings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To review, the Kalman filter update assumes a linear observation model with additive Gaussian noise\n",
    "\n",
    "$$\n",
    "z \\sim \\mathcal{N}(\\beta^\\top x,R)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an estimate of the latent state $x \\sim \\mathcal{N}(\\mu,\\Sigma)$, the Kalman update computes a posterior $\\hat x \\sim \\mathcal{N}(\\hat \\mu,\\hat \\Sigma)$ as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "       \\tilde z &= z - \\beta^\\top \\mu\n",
    "    \\\\ S &= R + \\beta^\\top \\Sigma \\beta\n",
    "    \\\\ K &= \\Sigma \\beta S^{-1}\n",
    "    \\\\ \\hat\\mu &= \\mu + K \\tilde z\n",
    "    \\\\ J &= I - K \\beta^\\top\n",
    "    \\\\ \\hat\\Sigma &= J \\Sigma J^\\top + K R K^\\top\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the only matrix inversion, $S^{-1}$, has the dimensionality of $z$ and not $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A surrogate gaussian update\n",
    "\n",
    "We can interpret the Gaussian approximation for $x_1$ given $y$ as providing a surrogate measurement of the projection $\\beta^\\top x$. \n",
    "\n",
    "This is useful not only as a short-hand way of understanding how to do an efficent non-conjugate update, but also because the surrogate updates may be used to accelerate optimization of the parameters of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having estimated\n",
    "\n",
    "$$\n",
    "Q(x_1) = \\mathcal{N}( \\hat\\mu_1, \\hat\\Sigma_1 )\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may solve for a surrogate Gaussian approximation of the *likelihood* $Q(y|x_1)$\n",
    "\n",
    "$$\n",
    "Q(y|x_1) = Q(x_1) \\frac {\\Pr(y)} {\\Pr(x_1)} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now let us present a solution for $Q(y|x_1)$ in terms of the naive formula for dividing two Gaussian distributions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    Q(y|x_1)  &= \\mathcal{N} (\\mu_r, \\Sigma_r )\n",
    "    \\\\ \\Sigma_r &= \\left(\\hat \\Sigma_1^{-1} - \\Sigma_1^{-1} \\right)^{-1}\n",
    "    \\\\ \\mu_r &= \\Sigma_r \\left( \\hat \\Sigma_1^{-1} \\hat \\mu_1 - \\Sigma_1 ^{-1} \\mu_1 \\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We may equate this posterior to the observation model\n",
    "\n",
    "$$\n",
    "z =  \\mu_r\n",
    "$$\n",
    "\n",
    "$$\n",
    "R = \\Sigma_r\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In which case the full model may be updated as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "       \\tilde z &= \\mu_r - \\beta^\\top \\mu\n",
    "    \\\\ S &=  \\Sigma_r + \\beta^\\top \\Sigma \\beta\n",
    "    \\\\ K &= \\Sigma \\beta S^{-1}\n",
    "    \\\\ \\hat\\mu &= \\mu + K \\tilde z\n",
    "    \\\\ J &= I - K \\beta^\\top\n",
    "    \\\\ \\hat\\Sigma &= J \\Sigma J^\\top + K R K^\\top\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, this connection to Kalman filtering is somewhat un-necessary, as the full update may be more directly described in terms of a conditional Gaussian, without the step of computing the surrogate likelihood. \n",
    "\n",
    "The Kalman update conncetion, however, is useful also for one approach to optimization of the parameters of models that include non-conjugate updates. If computing the non-conjugate update is costly, we may convert this update to a conjugate update using the surrogate Gaussian likelihoods. Parameters can be optimized then against this model, the surrograte likelihoods re-computed, and the overall model optimized iteratively via coordinate ascent. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surrogate likelihoods for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we should be able to recover the likelihood by negating the covariance in the Kalman update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "       \\tilde z &= z - \\beta^\\top \\mu\n",
    "    \\\\ S &= R - \\beta^\\top \\Sigma \\beta\n",
    "    \\\\ K &= - \\Sigma \\beta S^{-1}\n",
    "    \\\\ \\hat\\mu &= \\mu + K \\tilde z\n",
    "    \\\\ J &= I - K \\beta^\\top\n",
    "    \\\\ \\hat\\Sigma &= -J \\Sigma J^\\top + K R K^\\top\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be done in the $x_1$ subspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "       \\tilde z &= \\hat\\mu_1 - \\beta^\\top \\mu\n",
    "    \\\\ S &= \\hat\\Sigma_1 - \\beta^\\top \\Sigma \\beta\n",
    "    \\\\ K &= \\Sigma \\beta S^{-1}\n",
    "    \\\\ \\hat\\mu &= \\mu - K \\tilde z\n",
    "    \\\\ J &= I + K \\beta^\\top\n",
    "    \\\\ \\hat\\Sigma &= K \\hat\\Sigma_1 K^\\top - J \\Sigma J^\\top\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "       \\tilde z &= z - \\beta^\\top \\mu\n",
    "    \\\\ S &= R + \\beta^\\top \\Sigma \\beta\n",
    "    \\\\ K &= \\Sigma \\beta S^{-1}\n",
    "    \\\\ \\hat\\mu &= \\mu + K \\tilde z\n",
    "    \\\\ J &= I - K \\beta^\\top\n",
    "    \\\\ \\hat\\Sigma &= J \\Sigma J^\\top + K R K^\\top\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not really all that much better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18714239827e-11 1.56268054052e-12\n",
      "1.58081880919e-13 4.31184254968e-12\n",
      "4.59201357494e-11 4.50718629086e-12\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "I = np.eye(N)\n",
    "\n",
    "# Invent a prior\n",
    "prm = randn(N)\n",
    "prq = randn(N,N)\n",
    "prv = prq.dot(prq.T)\n",
    "\n",
    "# Invent a likelihood / measurement\n",
    "lkm = randn(N)\n",
    "lkq = randn(N,N)\n",
    "lkv = prq.dot(prq.T)\n",
    "\n",
    "def kalman_product(prm,prv,lkm,lkv):\n",
    "    # Kalman update to get postrior\n",
    "    z = lkm - prm\n",
    "    S = lkv + prv\n",
    "    K = prv.dot(pinv(S))\n",
    "    psmk = prm + K.dot(z)\n",
    "    J = I - K\n",
    "    psvk = J.dot(prv).dot(J.T) + K.dot(lkv).dot(K.T)\n",
    "    return psmk,psvk\n",
    "\n",
    "def bayesian_product(prm,prv,lkm,lkv):\n",
    "    # Bayesian update to get posterior\n",
    "    psvb = pinv(pinv(prv)+pinv(lkv))\n",
    "    psmb = psvb.dot(pinv(prv).dot(prm) + pinv(lkv).dot(lkm))\n",
    "    return psmb,psvb\n",
    "\n",
    "# Verif they are the same\n",
    "psmk,psvk = kalman_product(prm,prv,lkm,lkv)\n",
    "psmb,psvb = bayesian_product(prm,prv,lkm,lkv)\n",
    "print(sum(abs(psvk-psvb)),sum(abs(psmk-psmb)))\n",
    "\n",
    "# Verify likelihood recovered by performing update with negative prior covariance\n",
    "rrmk,rrvk = kalman_product(prm,-prv,psmk,psvk)\n",
    "print(sum(abs(rrvk-lkv)),sum(abs(rrmk-lkm)))\n",
    "rrmb,rrvb = bayesian_product(prm,-prv,psmb,psvb)\n",
    "print(sum(abs(rrvb-lkv)),sum(abs(rrmb-lkm)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
